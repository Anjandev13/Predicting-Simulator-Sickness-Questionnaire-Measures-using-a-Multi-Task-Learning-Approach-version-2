{"cells":[{"cell_type":"code","execution_count":147,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1725949169908,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fT_A9oAGAepC"},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":148,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":951,"status":"ok","timestamp":1725949171041,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"TishlaEBAmlN","outputId":"9b66e5f4-255f-4d4b-dae3-1db9d4e6c0dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":149,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1725949171048,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"XeSwJ8oKAt2r"},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":150,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1725949171049,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"BFHyHoFvA5bX"},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":151,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1725949171050,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"QeoIWcudA94b"},"outputs":[],"source":["def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","        arrays_3d.append(array_3d)\n","\n","    return arrays_3d\n"]},{"cell_type":"code","source":["sample_size=60\n","# simulations_train = ['noise','bumps']\n","# simulations_test=['flat']\n","# val_indices = [4, 10, 11, 26, 28, 31, 33, 37] # for flat\n","# train_indices = [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 38, 39, 40, 41] # for flat\n","\n","\n","# simulations_test=['noise']\n","# simulations_train = ['flat','bumps']\n","# val_indices = [7, 15, 17, 19, 28, 31, 32, 42, 44, 48] # for noise\n","# train_indices = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47] # for noise\n","\n","simulations_test=['bumps']\n","simulations_train = ['flat','noise']\n","val_indices = [1, 12, 16, 18, 22, 26, 28, 37, 41] # for speedbumps\n","train_indices = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44] # for speedbumps"],"metadata":{"id":"w90UVk1KeYdC","executionInfo":{"status":"ok","timestamp":1725949171050,"user_tz":300,"elapsed":16,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","execution_count":153,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1725949171050,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fqaeUGUDBCtT"},"outputs":[],"source":["participants = [str(i) for i in range(1, 27)]  # Participants 101 to 123\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":154,"metadata":{"executionInfo":{"elapsed":2890,"status":"ok","timestamp":1725949173926,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"DwS92BItBL4B"},"outputs":[],"source":["arrays_train = construct_3d_array(base_path, participants, simulations_train, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_test = construct_3d_array(base_path, participants, simulations_test, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","execution_count":155,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1725949173928,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"GgAM9zg_BRe8","outputId":"01cb15c2-6a01-463b-ba47-1d30336f1941"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the final concatenated 3D array: (45, 180, 47)\n","Shape of the final concatenated 3D array: (23, 180, 47)\n"]}],"source":["# Concatenate arrays along the first axis\n","input_train = np.concatenate(arrays_train, axis=0)\n","input_test = np.concatenate(arrays_test, axis=0)\n","# Display the shape of the final concatenated 3D array\n","print(f\"Shape of the final concatenated 3D array: {input_train.shape}\")\n","print(f\"Shape of the final concatenated 3D array: {input_test.shape}\")"]},{"cell_type":"code","execution_count":156,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725949173928,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"vPQyeAYKBYaO"},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[:, n_columns].sum(axis=1)\n","    o_val = df.iloc[:, o_columns].sum(axis=1)\n","    d_val = df.iloc[:, d_columns].sum(axis=1)\n","\n","    total_ssq = (n_val+o_val+d_val) * 3.74\n","    return n_val,o_val,d_val"]},{"cell_type":"code","execution_count":157,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1725949173928,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"Xpn0lDt0BfvE"},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          # n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          # total_ssq_values.append([n_val, o_val, d_val])\n","          ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":158,"metadata":{"id":"7k17K0HrCr6-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725949175480,"user_tz":300,"elapsed":1561,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"ff3db6d5-0132-41b6-8ad7-0dbbfeeeaaaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["(45, 16) (23, 16) (45, 1) (23, 1)\n"]}],"source":["output_train=merge_ssq_column(simulations_train,participants)\n","output_train = np.squeeze(output_train)\n","output_test=merge_ssq_column(simulations_test,participants)\n","output_test = np.squeeze(output_test)\n","output_train_total_ssq=merge_total_ssq(simulations_train,participants)\n","output_test_total_ssq=merge_total_ssq(simulations_test,participants)\n","output_train_total_ssq=output_train_total_ssq.reshape(-1, 1)\n","output_test_total_ssq=output_test_total_ssq.reshape(-1, 1)\n","print(output_train.shape,output_test.shape,output_train_total_ssq.shape,output_test_total_ssq.shape)\n","# print(output_train)\n","# print(output_train_total_ssq)\n"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def show_column_distribution(array, name):\n","    plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n","\n","    num_columns = array.shape[1]  # Number of columns in the array\n","    max_value = np.max(array)  # Maximum value across all columns\n","\n","    # Width of each bar\n","    width = 0.8 / num_columns\n","    legend_labels=[]\n","    # Plot the histograms for each column\n","    for i in range(num_columns):\n","        # Calculate the frequency of each value within the range of maximum value for the column\n","        column_counts = np.bincount(array[:, i], minlength=max_value+1)\n","\n","        # Offset for positioning bars of different columns\n","        x_offset = i * width\n","\n","        # Position for each bar\n","        x = np.arange(max_value+1) + x_offset\n","        if i == 0:\n","            plt.bar(x, column_counts, width=width, label=f'Nausea Value')\n","        elif i == 1:\n","            plt.bar(x, column_counts, width=width, label=f'Oculomotor Value')\n","        else:\n","            plt.bar(x, column_counts, width=width, label=f'Disorientation Value')\n","\n","\n","        # Add numerical data alongside the plot\n","        for j, count in enumerate(column_counts):\n","            plt.text(j + x_offset, count + 0.5, str(int(count)), ha='center', va='bottom')\n","\n","\n","\n","    plt.xlabel('Value')  # Label for x-axis\n","    plt.ylabel('Number of data points')  # Label for y-axis\n","    #plt.title(f'Distribution of values for all columns in {name}')  # Title of the plot\n","    plt.xticks(np.arange(max_value+1) + (width * num_columns / 2), range(max_value+1))  # Adjust x-axis ticks\n","    plt.legend()  # Show legend\n","\n","    plt.show()\n"],"metadata":{"id":"DbS4TcoLjrFf","executionInfo":{"status":"ok","timestamp":1725949175481,"user_tz":300,"elapsed":16,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":159,"outputs":[]},{"cell_type":"code","source":["stacked_output = np.vstack((output_train, output_test))\n","# show_column_distribution(stacked_output,\"train distribution\")"],"metadata":{"id":"CtLD379IjyPU","executionInfo":{"status":"ok","timestamp":1725949175482,"user_tz":300,"elapsed":16,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":160,"outputs":[]},{"cell_type":"code","execution_count":161,"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1725949175482,"user_tz":300,"elapsed":15,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"]},{"cell_type":"code","execution_count":162,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1725949175483,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"LyvV6GFDC66F"},"outputs":[],"source":["input_train, input_test= scale_input_data(input_train[:, (60-sample_size):(180-sample_size), :], input_test[:, (60-sample_size):(180-sample_size), :])\n","from keras.utils import to_categorical\n","\n","# Convert the original labels to one-hot encoded format\n","output_train_encoded = to_categorical(output_train, num_classes=4)\n","\n","input_val = input_train[val_indices]\n","input_train = input_train[train_indices]\n","output_val = output_train_encoded[val_indices]\n","output_val_total_ssq = output_train_total_ssq[val_indices]\n","output_train = output_train_encoded[train_indices]\n"]},{"cell_type":"code","source":["print(\"input_train :\", input_train.shape)\n","print(\"output_train :\", output_train.shape)\n","print(\"input_val :\", input_val.shape)\n","print(\"output_val :\", output_val.shape)\n","print(\"input_test :\", input_test.shape)\n","print(\"output_test :\", output_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiz0HsnDf3HB","executionInfo":{"status":"ok","timestamp":1725949175483,"user_tz":300,"elapsed":14,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"bb1c6322-b3bb-4dd3-c75e-4e32d49065de"},"execution_count":163,"outputs":[{"output_type":"stream","name":"stdout","text":["input_train : (36, 120, 47)\n","output_train : (36, 16, 4)\n","input_val : (9, 120, 47)\n","output_val : (9, 16, 4)\n","input_test : (23, 120, 47)\n","output_test : (23, 16)\n"]}]},{"cell_type":"code","execution_count":164,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6ssyYUeDJwI","outputId":"be9172ec-20c9-4f3b-9bf2-c6cbc1710d43","executionInfo":{"status":"ok","timestamp":1725949338177,"user_tz":300,"elapsed":162703,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - dense_750_accuracy: 0.2002 - dense_751_accuracy: 0.8264 - dense_752_accuracy: 0.0579 - dense_753_accuracy: 0.3657 - dense_754_accuracy: 0.3079 - dense_755_accuracy: 0.1343 - dense_756_accuracy: 0.2789 - dense_757_accuracy: 0.5868 - dense_758_accuracy: 0.6238 - dense_759_accuracy: 0.0741 - dense_760_accuracy: 0.5081 - dense_761_accuracy: 0.0579 - dense_762_accuracy: 0.2870 - dense_763_accuracy: 0.2025 - dense_764_accuracy: 0.1157 - dense_765_accuracy: 0.0741 - loss: 22.0901       \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - dense_750_accuracy: 0.5185 - dense_751_accuracy: 0.7685 - dense_752_accuracy: 0.6528 - dense_753_accuracy: 0.4711 - dense_754_accuracy: 0.7106 - dense_755_accuracy: 0.1817 - dense_756_accuracy: 0.2211 - dense_757_accuracy: 0.5185 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.8264 - dense_761_accuracy: 0.6528 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.5579 - dense_764_accuracy: 0.3843 - dense_765_accuracy: 0.8553 - loss: 17.4837 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - dense_750_accuracy: 0.5394 - dense_751_accuracy: 0.7396 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.5475 - dense_754_accuracy: 0.8079 - dense_755_accuracy: 0.7396 - dense_756_accuracy: 0.3079 - dense_757_accuracy: 0.6262 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.8553 - dense_761_accuracy: 0.7708 - dense_762_accuracy: 0.7998 - dense_763_accuracy: 0.9132 - dense_764_accuracy: 0.5394 - dense_765_accuracy: 0.8553 - loss: 13.9205 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_750_accuracy: 0.5289 - dense_751_accuracy: 0.7685 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.6343 - dense_754_accuracy: 0.8287 - dense_755_accuracy: 0.7975 - dense_756_accuracy: 0.4525 - dense_757_accuracy: 0.5972 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7025 - dense_762_accuracy: 0.7789 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5289 - dense_765_accuracy: 0.8553 - loss: 12.5827\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - dense_750_accuracy: 0.5394 - dense_751_accuracy: 0.7894 - dense_752_accuracy: 0.9525 - dense_753_accuracy: 0.5764 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8368 - dense_756_accuracy: 0.5475 - dense_757_accuracy: 0.6551 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7106 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5579 - dense_765_accuracy: 0.8553 - loss: 12.0396 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 4 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - dense_750_accuracy: 0.4028 - dense_751_accuracy: 0.7789 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.6053 - dense_754_accuracy: 0.8079 - dense_755_accuracy: 0.8264 - dense_756_accuracy: 0.5000 - dense_757_accuracy: 0.6921 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7500 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5949 - dense_765_accuracy: 0.8553 - loss: 11.9204\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 5 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - dense_750_accuracy: 0.4606 - dense_751_accuracy: 0.7396 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.6157 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8368 - dense_756_accuracy: 0.5000 - dense_757_accuracy: 0.4815 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7685 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5764 - dense_765_accuracy: 0.8762 - loss: 11.1785 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 6 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - dense_750_accuracy: 0.3264 - dense_751_accuracy: 0.7025 - dense_752_accuracy: 0.9525 - dense_753_accuracy: 0.5475 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8264 - dense_756_accuracy: 0.5185 - dense_757_accuracy: 0.5868 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9236 - dense_761_accuracy: 0.7685 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.3843 - dense_765_accuracy: 0.8553 - loss: 11.2317\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 7 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - dense_750_accuracy: 0.4421 - dense_751_accuracy: 0.6921 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.3657 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8264 - dense_756_accuracy: 0.5289 - dense_757_accuracy: 0.6528 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7789 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.4606 - dense_765_accuracy: 0.8553 - loss: 10.5557\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 8 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - dense_750_accuracy: 0.5185 - dense_751_accuracy: 0.7500 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.5972 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8368 - dense_756_accuracy: 0.5475 - dense_757_accuracy: 0.6736 - dense_758_accuracy: 0.8947 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7789 - dense_762_accuracy: 0.7789 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5972 - dense_765_accuracy: 0.8657 - loss: 10.1789\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 9 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - dense_750_accuracy: 0.4896 - dense_751_accuracy: 0.8079 - dense_752_accuracy: 0.9421 - dense_753_accuracy: 0.5475 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8264 - dense_756_accuracy: 0.4792 - dense_757_accuracy: 0.6343 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9132 - dense_761_accuracy: 0.7894 - dense_762_accuracy: 0.7789 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5475 - dense_765_accuracy: 0.8553 - loss: 10.6031\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n","k: 10 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - dense_750_accuracy: 0.5185 - dense_751_accuracy: 0.7894 - dense_752_accuracy: 0.9525 - dense_753_accuracy: 0.5972 - dense_754_accuracy: 0.7975 - dense_755_accuracy: 0.8264 - dense_756_accuracy: 0.5000 - dense_757_accuracy: 0.6343 - dense_758_accuracy: 0.8843 - dense_759_accuracy: 0.8843 - dense_760_accuracy: 0.9236 - dense_761_accuracy: 0.7685 - dense_762_accuracy: 0.7685 - dense_763_accuracy: 0.9421 - dense_764_accuracy: 0.5868 - dense_765_accuracy: 0.8657 - loss: 10.3621 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 11 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step\n","Test Loss no  0 : 43.699101572696776\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 73ms/step - dense_771_accuracy: 0.4236 - dense_772_accuracy: 0.1817 - dense_773_accuracy: 0.0000e+00 - dense_774_accuracy: 0.0764 - dense_775_accuracy: 0.4236 - dense_776_accuracy: 0.1134 - dense_777_accuracy: 0.4421 - dense_778_accuracy: 0.2500 - dense_779_accuracy: 0.2894 - dense_780_accuracy: 0.1238 - dense_781_accuracy: 0.2870 - dense_782_accuracy: 0.1528 - dense_783_accuracy: 0.7604 - dense_784_accuracy: 0.0185 - dense_785_accuracy: 0.2396 - dense_786_accuracy: 0.0000e+00 - loss: 22.7630\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - dense_771_accuracy: 0.2106 - dense_772_accuracy: 0.2789 - dense_773_accuracy: 0.1528 - dense_774_accuracy: 0.5394 - dense_775_accuracy: 0.2396 - dense_776_accuracy: 0.8079 - dense_777_accuracy: 0.4421 - dense_778_accuracy: 0.5289 - dense_779_accuracy: 0.0949 - dense_780_accuracy: 0.8079 - dense_781_accuracy: 0.9051 - dense_782_accuracy: 0.4792 - dense_783_accuracy: 0.6921 - dense_784_accuracy: 0.5081 - dense_785_accuracy: 0.4815 - dense_786_accuracy: 0.3553 - loss: 19.7071 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_771_accuracy: 0.5000 - dense_772_accuracy: 0.4606 - dense_773_accuracy: 0.7396 - dense_774_accuracy: 0.5185 - dense_775_accuracy: 0.7396 - dense_776_accuracy: 0.8079 - dense_777_accuracy: 0.5475 - dense_778_accuracy: 0.6343 - dense_779_accuracy: 0.6817 - dense_780_accuracy: 0.8947 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7106 - dense_783_accuracy: 0.6343 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.3762 - dense_786_accuracy: 0.6053 - loss: 16.3405\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - dense_771_accuracy: 0.5208 - dense_772_accuracy: 0.5868 - dense_773_accuracy: 0.8947 - dense_774_accuracy: 0.5289 - dense_775_accuracy: 0.8079 - dense_776_accuracy: 0.8472 - dense_777_accuracy: 0.5579 - dense_778_accuracy: 0.6447 - dense_779_accuracy: 0.8843 - dense_780_accuracy: 0.9051 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7604 - dense_783_accuracy: 0.7998 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5185 - dense_786_accuracy: 0.8264 - loss: 13.4554 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_771_accuracy: 0.5000 - dense_772_accuracy: 0.7604 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6157 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.5579 - dense_778_accuracy: 0.6238 - dense_779_accuracy: 0.8843 - dense_780_accuracy: 0.8947 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7500 - dense_783_accuracy: 0.7975 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.3449 - dense_786_accuracy: 0.8657 - loss: 12.1730 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - dense_771_accuracy: 0.5394 - dense_772_accuracy: 0.7500 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.5579 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8368 - dense_777_accuracy: 0.5475 - dense_778_accuracy: 0.6157 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7685 - dense_783_accuracy: 0.7789 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.4711 - dense_786_accuracy: 0.8657 - loss: 11.5236 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - dense_771_accuracy: 0.5475 - dense_772_accuracy: 0.7396 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6528 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8472 - dense_777_accuracy: 0.5579 - dense_778_accuracy: 0.6632 - dense_779_accuracy: 0.8843 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7975 - dense_783_accuracy: 0.7211 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5683 - dense_786_accuracy: 0.8657 - loss: 11.7174 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 6 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - dense_771_accuracy: 0.4421 - dense_772_accuracy: 0.7894 - dense_773_accuracy: 0.9525 - dense_774_accuracy: 0.5787 - dense_775_accuracy: 0.8079 - dense_776_accuracy: 0.8368 - dense_777_accuracy: 0.5394 - dense_778_accuracy: 0.5972 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9236 - dense_782_accuracy: 0.7789 - dense_783_accuracy: 0.7789 - dense_784_accuracy: 0.9525 - dense_785_accuracy: 0.5972 - dense_786_accuracy: 0.8762 - loss: 11.2318\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 7 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - dense_771_accuracy: 0.3368 - dense_772_accuracy: 0.7789 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.5764 - dense_775_accuracy: 0.8287 - dense_776_accuracy: 0.8368 - dense_777_accuracy: 0.3762 - dense_778_accuracy: 0.6366 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9236 - dense_782_accuracy: 0.7894 - dense_783_accuracy: 0.7998 - dense_784_accuracy: 0.9525 - dense_785_accuracy: 0.5683 - dense_786_accuracy: 0.8762 - loss: 10.5953\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 8 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - dense_771_accuracy: 0.5972 - dense_772_accuracy: 0.7685 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.3843 - dense_775_accuracy: 0.7500 - dense_776_accuracy: 0.8368 - dense_777_accuracy: 0.3160 - dense_778_accuracy: 0.4711 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7789 - dense_783_accuracy: 0.7211 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5660 - dense_786_accuracy: 0.8553 - loss: 10.9637\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 9 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - dense_771_accuracy: 0.5185 - dense_772_accuracy: 0.8183 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.5868 - dense_775_accuracy: 0.7396 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.4132 - dense_778_accuracy: 0.4896 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9236 - dense_782_accuracy: 0.7789 - dense_783_accuracy: 0.7211 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5498 - dense_786_accuracy: 0.8553 - loss: 10.9918\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 10 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - dense_771_accuracy: 0.4132 - dense_772_accuracy: 0.7789 - dense_773_accuracy: 0.9525 - dense_774_accuracy: 0.5764 - dense_775_accuracy: 0.7604 - dense_776_accuracy: 0.8472 - dense_777_accuracy: 0.4421 - dense_778_accuracy: 0.5579 - dense_779_accuracy: 0.8843 - dense_780_accuracy: 0.8947 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7396 - dense_783_accuracy: 0.7894 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5394 - dense_786_accuracy: 0.8553 - loss: 10.5467\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 11 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - dense_771_accuracy: 0.6551 - dense_772_accuracy: 0.7685 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6736 - dense_775_accuracy: 0.6817 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.6157 - dense_778_accuracy: 0.5000 - dense_779_accuracy: 0.8843 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7685 - dense_783_accuracy: 0.8079 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5475 - dense_786_accuracy: 0.8553 - loss: 10.1612\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 12 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_771_accuracy: 0.5579 - dense_772_accuracy: 0.7894 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6157 - dense_775_accuracy: 0.8183 - dense_776_accuracy: 0.8472 - dense_777_accuracy: 0.5683 - dense_778_accuracy: 0.6736 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9340 - dense_782_accuracy: 0.7789 - dense_783_accuracy: 0.8079 - dense_784_accuracy: 0.9525 - dense_785_accuracy: 0.6262 - dense_786_accuracy: 0.8762 - loss: 9.9293 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 13 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - dense_771_accuracy: 0.5000 - dense_772_accuracy: 0.8368 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.7025 - dense_775_accuracy: 0.7685 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.5185 - dense_778_accuracy: 0.5949 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8947 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7789 - dense_783_accuracy: 0.7685 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5000 - dense_786_accuracy: 0.8657 - loss: 10.2425 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 14 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - dense_771_accuracy: 0.4711 - dense_772_accuracy: 0.8079 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6528 - dense_775_accuracy: 0.8079 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.5104 - dense_778_accuracy: 0.6053 - dense_779_accuracy: 0.8947 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7894 - dense_783_accuracy: 0.7789 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.6343 - dense_786_accuracy: 0.8553 - loss: 9.6637 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","k: 15 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - dense_771_accuracy: 0.5972 - dense_772_accuracy: 0.7396 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6238 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8576 - dense_777_accuracy: 0.5104 - dense_778_accuracy: 0.5868 - dense_779_accuracy: 0.9132 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7789 - dense_783_accuracy: 0.7685 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5683 - dense_786_accuracy: 0.8264 - loss: 9.4296 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 16 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - dense_771_accuracy: 0.4815 - dense_772_accuracy: 0.8553 - dense_773_accuracy: 0.9132 - dense_774_accuracy: 0.7708 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.5579 - dense_778_accuracy: 0.6736 - dense_779_accuracy: 0.9132 - dense_780_accuracy: 0.8947 - dense_781_accuracy: 0.9421 - dense_782_accuracy: 0.6921 - dense_783_accuracy: 0.7685 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5660 - dense_786_accuracy: 0.8553 - loss: 9.5004 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 17 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_771_accuracy: 0.5475 - dense_772_accuracy: 0.8553 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.7025 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8368 - dense_777_accuracy: 0.5868 - dense_778_accuracy: 0.6528 - dense_779_accuracy: 0.9132 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9421 - dense_782_accuracy: 0.7106 - dense_783_accuracy: 0.7975 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.5868 - dense_786_accuracy: 0.8657 - loss: 9.0820 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 18 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - dense_771_accuracy: 0.4421 - dense_772_accuracy: 0.8264 - dense_773_accuracy: 0.9421 - dense_774_accuracy: 0.6736 - dense_775_accuracy: 0.8079 - dense_776_accuracy: 0.8264 - dense_777_accuracy: 0.5289 - dense_778_accuracy: 0.5949 - dense_779_accuracy: 0.9132 - dense_780_accuracy: 0.8843 - dense_781_accuracy: 0.9421 - dense_782_accuracy: 0.7106 - dense_783_accuracy: 0.7685 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.6157 - dense_786_accuracy: 0.8762 - loss: 9.1719\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 19 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_771_accuracy: 0.5868 - dense_772_accuracy: 0.8079 - dense_773_accuracy: 0.9525 - dense_774_accuracy: 0.6551 - dense_775_accuracy: 0.7975 - dense_776_accuracy: 0.8576 - dense_777_accuracy: 0.5683 - dense_778_accuracy: 0.6157 - dense_779_accuracy: 0.8843 - dense_780_accuracy: 0.8947 - dense_781_accuracy: 0.9132 - dense_782_accuracy: 0.7685 - dense_783_accuracy: 0.7789 - dense_784_accuracy: 0.9421 - dense_785_accuracy: 0.6076 - dense_786_accuracy: 0.8657 - loss: 9.1301\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 20 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n","Test Loss no  1 : 39.3338301123136\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - dense_792_accuracy: 0.5185 - dense_793_accuracy: 0.6343 - dense_794_accuracy: 0.0289 - dense_795_accuracy: 0.5000 - dense_796_accuracy: 0.3368 - dense_797_accuracy: 0.7685 - dense_798_accuracy: 0.1238 - dense_799_accuracy: 0.4317 - dense_800_accuracy: 0.0949 - dense_801_accuracy: 0.6736 - dense_802_accuracy: 0.1319 - dense_803_accuracy: 0.0660 - dense_804_accuracy: 0.7211 - dense_805_accuracy: 0.3657 - dense_806_accuracy: 0.1921 - dense_807_accuracy: 0.0868 - loss: 21.6414\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - dense_792_accuracy: 0.4896 - dense_793_accuracy: 0.7894 - dense_794_accuracy: 0.3924 - dense_795_accuracy: 0.6262 - dense_796_accuracy: 0.7789 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.4630 - dense_799_accuracy: 0.6447 - dense_800_accuracy: 0.8947 - dense_801_accuracy: 0.7685 - dense_802_accuracy: 0.9236 - dense_803_accuracy: 0.7211 - dense_804_accuracy: 0.7396 - dense_805_accuracy: 0.3264 - dense_806_accuracy: 0.1447 - dense_807_accuracy: 0.2870 - loss: 17.6759\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - dense_792_accuracy: 0.5081 - dense_793_accuracy: 0.7789 - dense_794_accuracy: 0.8843 - dense_795_accuracy: 0.5660 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8368 - dense_798_accuracy: 0.5104 - dense_799_accuracy: 0.5660 - dense_800_accuracy: 0.8947 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7500 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.7396 - dense_806_accuracy: 0.4340 - dense_807_accuracy: 0.7315 - loss: 15.1222\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - dense_792_accuracy: 0.5289 - dense_793_accuracy: 0.8079 - dense_794_accuracy: 0.9525 - dense_795_accuracy: 0.6921 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5185 - dense_799_accuracy: 0.6447 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7789 - dense_804_accuracy: 0.7789 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.4317 - dense_807_accuracy: 0.8553 - loss: 12.8061\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - dense_792_accuracy: 0.5185 - dense_793_accuracy: 0.7396 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5764 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5208 - dense_799_accuracy: 0.5764 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7789 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5868 - dense_807_accuracy: 0.8762 - loss: 12.5806\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 4 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - dense_792_accuracy: 0.5868 - dense_793_accuracy: 0.7500 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5868 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8368 - dense_798_accuracy: 0.4711 - dense_799_accuracy: 0.6053 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8947 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7685 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5289 - dense_807_accuracy: 0.8657 - loss: 12.3977\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 5 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - dense_792_accuracy: 0.5104 - dense_793_accuracy: 0.7789 - dense_794_accuracy: 0.9525 - dense_795_accuracy: 0.6632 - dense_796_accuracy: 0.7975 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.3843 - dense_799_accuracy: 0.6343 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7685 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5868 - dense_807_accuracy: 0.8657 - loss: 11.7982 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 6 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - dense_792_accuracy: 0.4711 - dense_793_accuracy: 0.8183 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.6262 - dense_796_accuracy: 0.7894 - dense_797_accuracy: 0.8368 - dense_798_accuracy: 0.3449 - dense_799_accuracy: 0.6447 - dense_800_accuracy: 0.8947 - dense_801_accuracy: 0.8947 - dense_802_accuracy: 0.9236 - dense_803_accuracy: 0.7894 - dense_804_accuracy: 0.7894 - dense_805_accuracy: 0.9525 - dense_806_accuracy: 0.5185 - dense_807_accuracy: 0.8553 - loss: 10.7546 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 7 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_792_accuracy: 0.2500 - dense_793_accuracy: 0.7604 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.4896 - dense_796_accuracy: 0.7500 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.2315 - dense_799_accuracy: 0.6053 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9236 - dense_803_accuracy: 0.7685 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.3449 - dense_807_accuracy: 0.8079 - loss: 11.7215 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 8 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - dense_792_accuracy: 0.3264 - dense_793_accuracy: 0.7396 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.6447 - dense_796_accuracy: 0.6817 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.3843 - dense_799_accuracy: 0.6632 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8947 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7789 - dense_804_accuracy: 0.7604 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.4525 - dense_807_accuracy: 0.8264 - loss: 10.7342 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 9 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_792_accuracy: 0.6447 - dense_793_accuracy: 0.7396 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.4236 - dense_796_accuracy: 0.7396 - dense_797_accuracy: 0.8368 - dense_798_accuracy: 0.5579 - dense_799_accuracy: 0.5081 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7685 - dense_804_accuracy: 0.7396 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.4606 - dense_807_accuracy: 0.8657 - loss: 10.6670 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 10 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - dense_792_accuracy: 0.4606 - dense_793_accuracy: 0.7685 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.6157 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5475 - dense_799_accuracy: 0.5868 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8553 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7789 - dense_804_accuracy: 0.7500 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.4815 - dense_807_accuracy: 0.8657 - loss: 10.5693 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 11 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_792_accuracy: 0.5000 - dense_793_accuracy: 0.7685 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.6447 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5660 - dense_799_accuracy: 0.6736 - dense_800_accuracy: 0.8947 - dense_801_accuracy: 0.8264 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7789 - dense_804_accuracy: 0.7500 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5660 - dense_807_accuracy: 0.8553 - loss: 10.7026\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 12 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_792_accuracy: 0.4421 - dense_793_accuracy: 0.8079 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5683 - dense_796_accuracy: 0.8287 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5683 - dense_799_accuracy: 0.5394 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9236 - dense_803_accuracy: 0.7894 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5289 - dense_807_accuracy: 0.8264 - loss: 10.5443 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 13 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_792_accuracy: 0.5185 - dense_793_accuracy: 0.7685 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5394 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5683 - dense_799_accuracy: 0.6736 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7894 - dense_804_accuracy: 0.7604 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5683 - dense_807_accuracy: 0.8657 - loss: 10.5806\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 14 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - dense_792_accuracy: 0.5185 - dense_793_accuracy: 0.7789 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5683 - dense_796_accuracy: 0.8079 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.4630 - dense_799_accuracy: 0.5949 - dense_800_accuracy: 0.8947 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.6921 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.4421 - dense_807_accuracy: 0.8657 - loss: 10.3089 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 15 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_792_accuracy: 0.5289 - dense_793_accuracy: 0.8264 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.6053 - dense_796_accuracy: 0.7315 - dense_797_accuracy: 0.8368 - dense_798_accuracy: 0.4028 - dense_799_accuracy: 0.7211 - dense_800_accuracy: 0.8947 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9236 - dense_803_accuracy: 0.6736 - dense_804_accuracy: 0.7211 - dense_805_accuracy: 0.9525 - dense_806_accuracy: 0.5104 - dense_807_accuracy: 0.8657 - loss: 9.8407 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 16 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_792_accuracy: 0.5475 - dense_793_accuracy: 0.8264 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5081 - dense_796_accuracy: 0.7315 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.4525 - dense_799_accuracy: 0.5185 - dense_800_accuracy: 0.9051 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.6921 - dense_804_accuracy: 0.7685 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5000 - dense_807_accuracy: 0.8657 - loss: 10.1664 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 17 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - dense_792_accuracy: 0.5764 - dense_793_accuracy: 0.8264 - dense_794_accuracy: 0.9421 - dense_795_accuracy: 0.5289 - dense_796_accuracy: 0.7396 - dense_797_accuracy: 0.8264 - dense_798_accuracy: 0.5972 - dense_799_accuracy: 0.5660 - dense_800_accuracy: 0.8843 - dense_801_accuracy: 0.8843 - dense_802_accuracy: 0.9132 - dense_803_accuracy: 0.7789 - dense_804_accuracy: 0.8264 - dense_805_accuracy: 0.9421 - dense_806_accuracy: 0.5660 - dense_807_accuracy: 0.8368 - loss: 9.8343  \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 18 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n","Test Loss no  2 : 39.93988678654134\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 98ms/step - dense_813_accuracy: 0.3264 - dense_814_accuracy: 0.3472 - dense_815_accuracy: 0.0000e+00 - dense_816_accuracy: 0.5104 - dense_817_accuracy: 0.4630 - dense_818_accuracy: 0.0764 - dense_819_accuracy: 0.2292 - dense_820_accuracy: 0.0868 - dense_821_accuracy: 0.1713 - dense_822_accuracy: 0.1609 - dense_823_accuracy: 0.2477 - dense_824_accuracy: 0.3160 - dense_825_accuracy: 0.2292 - dense_826_accuracy: 0.0475 - dense_827_accuracy: 0.3947 - dense_828_accuracy: 0.5394 - loss: 22.1116\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - dense_813_accuracy: 0.5579 - dense_814_accuracy: 0.5289 - dense_815_accuracy: 0.9132 - dense_816_accuracy: 0.3657 - dense_817_accuracy: 0.0579 - dense_818_accuracy: 0.7396 - dense_819_accuracy: 0.5000 - dense_820_accuracy: 0.5394 - dense_821_accuracy: 0.7685 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.5104 - dense_826_accuracy: 0.7396 - dense_827_accuracy: 0.5764 - dense_828_accuracy: 0.8657 - loss: 17.1571\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - dense_813_accuracy: 0.5370 - dense_814_accuracy: 0.6736 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.4132 - dense_817_accuracy: 0.2500 - dense_818_accuracy: 0.7500 - dense_819_accuracy: 0.5475 - dense_820_accuracy: 0.6238 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.5081 - dense_826_accuracy: 0.8843 - dense_827_accuracy: 0.5764 - dense_828_accuracy: 0.8553 - loss: 14.3527 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dense_813_accuracy: 0.4792 - dense_814_accuracy: 0.7685 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6053 - dense_817_accuracy: 0.7211 - dense_818_accuracy: 0.8079 - dense_819_accuracy: 0.5683 - dense_820_accuracy: 0.5081 - dense_821_accuracy: 0.8553 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7106 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5972 - dense_828_accuracy: 0.8762 - loss: 12.2490 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - dense_813_accuracy: 0.4606 - dense_814_accuracy: 0.7789 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6447 - dense_817_accuracy: 0.8183 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.6447 - dense_820_accuracy: 0.5949 - dense_821_accuracy: 0.8947 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9236 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7500 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5764 - dense_828_accuracy: 0.8657 - loss: 12.3281 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_813_accuracy: 0.5104 - dense_814_accuracy: 0.7894 - dense_815_accuracy: 0.9525 - dense_816_accuracy: 0.6262 - dense_817_accuracy: 0.7975 - dense_818_accuracy: 0.8553 - dense_819_accuracy: 0.4236 - dense_820_accuracy: 0.6632 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7685 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5579 - dense_828_accuracy: 0.8657 - loss: 12.2403 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - dense_813_accuracy: 0.3449 - dense_814_accuracy: 0.7894 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6343 - dense_817_accuracy: 0.8079 - dense_818_accuracy: 0.8368 - dense_819_accuracy: 0.3843 - dense_820_accuracy: 0.6447 - dense_821_accuracy: 0.9051 - dense_822_accuracy: 0.8947 - dense_823_accuracy: 0.9236 - dense_824_accuracy: 0.7894 - dense_825_accuracy: 0.7894 - dense_826_accuracy: 0.9525 - dense_827_accuracy: 0.5289 - dense_828_accuracy: 0.8553 - loss: 11.3868\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 6 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dense_813_accuracy: 0.4606 - dense_814_accuracy: 0.7789 - dense_815_accuracy: 0.9525 - dense_816_accuracy: 0.6053 - dense_817_accuracy: 0.7975 - dense_818_accuracy: 0.8576 - dense_819_accuracy: 0.4317 - dense_820_accuracy: 0.6447 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8947 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7789 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.4421 - dense_828_accuracy: 0.8553 - loss: 10.8522 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 7 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dense_813_accuracy: 0.3947 - dense_814_accuracy: 0.7500 - dense_815_accuracy: 0.9525 - dense_816_accuracy: 0.5104 - dense_817_accuracy: 0.7789 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.3634 - dense_820_accuracy: 0.6053 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8947 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7789 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.3947 - dense_828_accuracy: 0.8553 - loss: 10.8948 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 8 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_813_accuracy: 0.4815 - dense_814_accuracy: 0.7419 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.5104 - dense_817_accuracy: 0.7685 - dense_818_accuracy: 0.8368 - dense_819_accuracy: 0.5000 - dense_820_accuracy: 0.6632 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7685 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.4525 - dense_828_accuracy: 0.8553 - loss: 10.7979 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 9 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_813_accuracy: 0.4421 - dense_814_accuracy: 0.6736 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.3947 - dense_817_accuracy: 0.8079 - dense_818_accuracy: 0.8368 - dense_819_accuracy: 0.5579 - dense_820_accuracy: 0.6632 - dense_821_accuracy: 0.9051 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9236 - dense_824_accuracy: 0.7211 - dense_825_accuracy: 0.7789 - dense_826_accuracy: 0.9525 - dense_827_accuracy: 0.4606 - dense_828_accuracy: 0.8657 - loss: 10.5619 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 10 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_813_accuracy: 0.5660 - dense_814_accuracy: 0.6921 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.5289 - dense_817_accuracy: 0.8183 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.5579 - dense_820_accuracy: 0.6447 - dense_821_accuracy: 0.8947 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9236 - dense_824_accuracy: 0.7396 - dense_825_accuracy: 0.7789 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5949 - dense_828_accuracy: 0.8657 - loss: 10.2531\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 11 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_813_accuracy: 0.5000 - dense_814_accuracy: 0.8264 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6632 - dense_817_accuracy: 0.8079 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.5579 - dense_820_accuracy: 0.6157 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7789 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.6262 - dense_828_accuracy: 0.8657 - loss: 9.9980  \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 12 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - dense_813_accuracy: 0.5394 - dense_814_accuracy: 0.8079 - dense_815_accuracy: 0.9525 - dense_816_accuracy: 0.6157 - dense_817_accuracy: 0.8079 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.5579 - dense_820_accuracy: 0.6447 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7685 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5868 - dense_828_accuracy: 0.8657 - loss: 9.9163\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 13 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - dense_813_accuracy: 0.4711 - dense_814_accuracy: 0.7789 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6053 - dense_817_accuracy: 0.7975 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.5370 - dense_820_accuracy: 0.5660 - dense_821_accuracy: 0.8947 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7685 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5660 - dense_828_accuracy: 0.8553 - loss: 9.8845  \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 14 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - dense_813_accuracy: 0.5764 - dense_814_accuracy: 0.7789 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6262 - dense_817_accuracy: 0.8287 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.5683 - dense_820_accuracy: 0.6736 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9236 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7685 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5868 - dense_828_accuracy: 0.8657 - loss: 9.4707\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 15 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_813_accuracy: 0.5972 - dense_814_accuracy: 0.7789 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.7025 - dense_817_accuracy: 0.8287 - dense_818_accuracy: 0.8368 - dense_819_accuracy: 0.5394 - dense_820_accuracy: 0.6262 - dense_821_accuracy: 0.9051 - dense_822_accuracy: 0.8947 - dense_823_accuracy: 0.9236 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7894 - dense_826_accuracy: 0.9525 - dense_827_accuracy: 0.5475 - dense_828_accuracy: 0.8657 - loss: 9.4325\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 16 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_813_accuracy: 0.4525 - dense_814_accuracy: 0.8472 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6736 - dense_817_accuracy: 0.7685 - dense_818_accuracy: 0.8264 - dense_819_accuracy: 0.5764 - dense_820_accuracy: 0.5764 - dense_821_accuracy: 0.8947 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7685 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5579 - dense_828_accuracy: 0.8553 - loss: 9.6001\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","k: 17 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - dense_813_accuracy: 0.4896 - dense_814_accuracy: 0.8079 - dense_815_accuracy: 0.9525 - dense_816_accuracy: 0.7604 - dense_817_accuracy: 0.7685 - dense_818_accuracy: 0.8472 - dense_819_accuracy: 0.4711 - dense_820_accuracy: 0.6632 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8947 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7789 - dense_825_accuracy: 0.7975 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5579 - dense_828_accuracy: 0.8553 - loss: 9.4190\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n","k: 18 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - dense_813_accuracy: 0.4132 - dense_814_accuracy: 0.8264 - dense_815_accuracy: 0.9421 - dense_816_accuracy: 0.6053 - dense_817_accuracy: 0.7975 - dense_818_accuracy: 0.8368 - dense_819_accuracy: 0.4815 - dense_820_accuracy: 0.6343 - dense_821_accuracy: 0.8843 - dense_822_accuracy: 0.8843 - dense_823_accuracy: 0.9132 - dense_824_accuracy: 0.7685 - dense_825_accuracy: 0.7396 - dense_826_accuracy: 0.9421 - dense_827_accuracy: 0.5000 - dense_828_accuracy: 0.8657 - loss: 9.1437\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 19 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858ms/step\n","Test Loss no  3 : 41.14739064049797\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 71ms/step - dense_834_accuracy: 0.0579 - dense_835_accuracy: 0.0949 - dense_836_accuracy: 0.1238 - dense_837_accuracy: 0.0764 - dense_838_accuracy: 0.1447 - dense_839_accuracy: 0.0475 - dense_840_accuracy: 0.2894 - dense_841_accuracy: 0.6551 - dense_842_accuracy: 0.7396 - dense_843_accuracy: 0.6053 - dense_844_accuracy: 0.3160 - dense_845_accuracy: 0.0000e+00 - dense_846_accuracy: 0.1632 - dense_847_accuracy: 0.0868 - dense_848_accuracy: 0.0764 - dense_849_accuracy: 0.0475 - loss: 23.1362\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_834_accuracy: 0.2315 - dense_835_accuracy: 0.6343 - dense_836_accuracy: 0.2292 - dense_837_accuracy: 0.2025 - dense_838_accuracy: 0.6447 - dense_839_accuracy: 0.5764 - dense_840_accuracy: 0.1736 - dense_841_accuracy: 0.1817 - dense_842_accuracy: 0.8947 - dense_843_accuracy: 0.7789 - dense_844_accuracy: 0.8553 - dense_845_accuracy: 0.0289 - dense_846_accuracy: 0.6157 - dense_847_accuracy: 0.1238 - dense_848_accuracy: 0.5000 - dense_849_accuracy: 0.2396 - loss: 20.1614\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - dense_834_accuracy: 0.3843 - dense_835_accuracy: 0.7685 - dense_836_accuracy: 0.5660 - dense_837_accuracy: 0.3079 - dense_838_accuracy: 0.8079 - dense_839_accuracy: 0.5764 - dense_840_accuracy: 0.2685 - dense_841_accuracy: 0.3843 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.8843 - dense_845_accuracy: 0.0579 - dense_846_accuracy: 0.7789 - dense_847_accuracy: 0.8264 - dense_848_accuracy: 0.4711 - dense_849_accuracy: 0.7975 - loss: 17.6794\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - dense_834_accuracy: 0.5289 - dense_835_accuracy: 0.7789 - dense_836_accuracy: 0.8553 - dense_837_accuracy: 0.3843 - dense_838_accuracy: 0.8079 - dense_839_accuracy: 0.7211 - dense_840_accuracy: 0.1053 - dense_841_accuracy: 0.5868 - dense_842_accuracy: 0.8947 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9236 - dense_845_accuracy: 0.1817 - dense_846_accuracy: 0.7894 - dense_847_accuracy: 0.9525 - dense_848_accuracy: 0.4815 - dense_849_accuracy: 0.8970 - loss: 15.0969\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - dense_834_accuracy: 0.5185 - dense_835_accuracy: 0.7789 - dense_836_accuracy: 0.9815 - dense_837_accuracy: 0.3762 - dense_838_accuracy: 0.8079 - dense_839_accuracy: 0.8079 - dense_840_accuracy: 0.1528 - dense_841_accuracy: 0.6157 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8947 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7106 - dense_846_accuracy: 0.7211 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.5475 - dense_849_accuracy: 0.8657 - loss: 13.1916\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 4 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - dense_834_accuracy: 0.5185 - dense_835_accuracy: 0.7685 - dense_836_accuracy: 0.9132 - dense_837_accuracy: 0.6447 - dense_838_accuracy: 0.7998 - dense_839_accuracy: 0.8079 - dense_840_accuracy: 0.3657 - dense_841_accuracy: 0.6447 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7604 - dense_846_accuracy: 0.7789 - dense_847_accuracy: 0.9132 - dense_848_accuracy: 0.4711 - dense_849_accuracy: 0.8368 - loss: 12.1436\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 5 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_834_accuracy: 0.5289 - dense_835_accuracy: 0.7789 - dense_836_accuracy: 0.9525 - dense_837_accuracy: 0.5289 - dense_838_accuracy: 0.8264 - dense_839_accuracy: 0.8368 - dense_840_accuracy: 0.4051 - dense_841_accuracy: 0.6447 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7500 - dense_846_accuracy: 0.7396 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.4815 - dense_849_accuracy: 0.8553 - loss: 11.7903\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 6 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - dense_834_accuracy: 0.5185 - dense_835_accuracy: 0.7789 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.6157 - dense_838_accuracy: 0.7025 - dense_839_accuracy: 0.8264 - dense_840_accuracy: 0.5475 - dense_841_accuracy: 0.5949 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7685 - dense_846_accuracy: 0.7685 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.4792 - dense_849_accuracy: 0.8553 - loss: 11.7912\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 7 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - dense_834_accuracy: 0.3843 - dense_835_accuracy: 0.7789 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.6447 - dense_838_accuracy: 0.8079 - dense_839_accuracy: 0.8368 - dense_840_accuracy: 0.5289 - dense_841_accuracy: 0.5660 - dense_842_accuracy: 0.8947 - dense_843_accuracy: 0.8947 - dense_844_accuracy: 0.9236 - dense_845_accuracy: 0.7789 - dense_846_accuracy: 0.7789 - dense_847_accuracy: 0.9525 - dense_848_accuracy: 0.5764 - dense_849_accuracy: 0.8553 - loss: 11.0265\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 8 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - dense_834_accuracy: 0.3657 - dense_835_accuracy: 0.7419 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.6157 - dense_838_accuracy: 0.8079 - dense_839_accuracy: 0.8368 - dense_840_accuracy: 0.5000 - dense_841_accuracy: 0.5660 - dense_842_accuracy: 0.8947 - dense_843_accuracy: 0.8947 - dense_844_accuracy: 0.9236 - dense_845_accuracy: 0.7604 - dense_846_accuracy: 0.7789 - dense_847_accuracy: 0.9525 - dense_848_accuracy: 0.5764 - dense_849_accuracy: 0.8553 - loss: 11.2442\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 9 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - dense_834_accuracy: 0.4051 - dense_835_accuracy: 0.7500 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.6157 - dense_838_accuracy: 0.7975 - dense_839_accuracy: 0.8264 - dense_840_accuracy: 0.5683 - dense_841_accuracy: 0.5764 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7685 - dense_846_accuracy: 0.7975 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.5764 - dense_849_accuracy: 0.8657 - loss: 10.5951\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 10 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - dense_834_accuracy: 0.3264 - dense_835_accuracy: 0.7106 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.5000 - dense_838_accuracy: 0.7975 - dense_839_accuracy: 0.7685 - dense_840_accuracy: 0.5208 - dense_841_accuracy: 0.6736 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7685 - dense_846_accuracy: 0.7211 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.5764 - dense_849_accuracy: 0.8762 - loss: 10.8223\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 11 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - dense_834_accuracy: 0.3264 - dense_835_accuracy: 0.7975 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.5475 - dense_838_accuracy: 0.8079 - dense_839_accuracy: 0.8264 - dense_840_accuracy: 0.4815 - dense_841_accuracy: 0.6447 - dense_842_accuracy: 0.8843 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7500 - dense_846_accuracy: 0.7396 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.5289 - dense_849_accuracy: 0.8553 - loss: 10.7271\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 12 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - dense_834_accuracy: 0.5104 - dense_835_accuracy: 0.7025 - dense_836_accuracy: 0.9421 - dense_837_accuracy: 0.5949 - dense_838_accuracy: 0.8368 - dense_839_accuracy: 0.8264 - dense_840_accuracy: 0.4317 - dense_841_accuracy: 0.5764 - dense_842_accuracy: 0.8947 - dense_843_accuracy: 0.8843 - dense_844_accuracy: 0.9132 - dense_845_accuracy: 0.7975 - dense_846_accuracy: 0.7685 - dense_847_accuracy: 0.9421 - dense_848_accuracy: 0.5949 - dense_849_accuracy: 0.8553 - loss: 10.4151\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 13 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step\n","Test Loss no  4 : 41.69795553324137\n","60 ['bumps']\n","average_loss: 41.16363292905821\n"]}],"source":["from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n","from keras.optimizers import Adam\n","import numpy as np\n","import sklearn\n","\n","total_losses = []\n","\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Self attention\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Cross attention\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, enc_outputs)\n","    x = Dropout(dropout)(x)\n","    res = x + res\n","\n","    # Feed forward\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def get_hard_shared_model(input_shape1, input_shape2, output_shape):\n","    # Encoder input\n","    enc_inputs = Input(shape=(input_shape1, input_shape2))\n","\n","    # Encoder\n","    enc_outputs = transformer_encoder(enc_inputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Decoder input\n","    dec_inputs = Input(shape=(output_shape[1], input_shape2))\n","\n","    # Decoder\n","    dec_outputs = transformer_decoder(dec_inputs, enc_outputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Global pooling\n","    x = GlobalAveragePooling1D()(dec_outputs)\n","\n","    # Shared dense layer\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","\n","    # Task-specific output layers\n","    outputs = []\n","    for i in range(output_shape[1]):\n","        task_output = Dense(4, activation='softmax')(x)\n","        outputs.append(task_output)\n","\n","    return Model([enc_inputs, dec_inputs], outputs)\n","\n","for iteration in range(5):\n","    # Reshape inputs\n","    train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","    test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","    val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","    # Create decoder inputs\n","    train_dec_input = np.zeros((train_input_reshaped.shape[0], output_train.shape[1], train_input_reshaped.shape[2]))\n","    val_dec_input = np.zeros((val_input_reshaped.shape[0], output_train.shape[1], val_input_reshaped.shape[2]))\n","    test_dec_input = np.zeros((test_input_reshaped.shape[0], output_test.shape[1], test_input_reshaped.shape[2]))\n","\n","    # Create the hard parameter sharing model\n","    model = get_hard_shared_model(input_train.shape[1], input_train.shape[2], output_train.shape)\n","\n","    # Compile and train the model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[['accuracy'] for _ in range(output_train.shape[1])])\n","    best_val = 1000000\n","    patience = 0\n","    best_model = None\n","\n","    for k in range(200):\n","      # Train the model\n","      model.fit([train_input_reshaped, train_dec_input],\n","                [output_train[:, i] for i in range(output_train.shape[1])],\n","                epochs=1, batch_size=32, verbose=1)\n","\n","      # Predict validation data\n","      pred_val = np.array(model.predict([val_input_reshaped, val_dec_input]))\n","      pred_val = np.transpose(pred_val, (1, 0, 2)).squeeze()\n","      pred_val = np.argmax(pred_val, axis=-1).reshape(pred_val.shape[:-1])\n","      print(\"k:\", k, \"patience:\", patience)\n","\n","      # Evaluate the model\n","      losses = []\n","      for i in range(pred_val.shape[0]):\n","        total_ssq=0\n","        for j in [0,5,6,7,8,14,15]:\n","          total_ssq=np.sum(pred_val[i,j])+total_ssq\n","\n","        for j in [0,1,2,3,4,8,10]:\n","          total_ssq=np.sum(pred_val[i,j])+total_ssq\n","\n","        for j in [4,7,9,10,11,12,13]:\n","          total_ssq=np.sum(pred_val[i,j])+total_ssq\n","        total_ssq=total_ssq*3.74\n","        output_val_ssq= output_val_total_ssq[i,0]\n","        #print(\"total_ssq\",total_ssq)\n","        #print(\"output_val_ssq\",output_val_ssq)\n","        loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","        losses.append(loss)\n","      tmp_val_loss = np.mean(losses)\n","      if tmp_val_loss <= best_val:\n","          best_val = tmp_val_loss\n","          patience = 0\n","          best_model = model\n","      else:\n","          patience +=1\n","          if patience > 10:\n","            break\n","\n","    # Predict test data\n","    pred_test = np.array(best_model.predict([test_input_reshaped, test_dec_input]))\n","    pred_test = np.transpose(pred_test, (1, 0, 2)).squeeze()\n","    pred_test = np.argmax(pred_test, axis=-1).reshape(pred_test.shape[:-1])\n","\n","    # Evaluate the model\n","    pred_total_ssq = []\n","    for i in range(pred_test.shape[0]):\n","        total_ssq = 0\n","        for j in [0, 5, 6, 7, 8, 14, 15]:\n","            total_ssq += np.sum(pred_test[i, j])\n","\n","        for j in [0, 1, 2, 3, 4, 8, 10]:\n","            total_ssq += np.sum(pred_test[i, j])\n","\n","        for j in [4, 7, 9, 10, 11, 12, 13]:\n","            total_ssq += np.sum(pred_test[i, j])\n","\n","        total_ssq *= 3.74\n","        pred_total_ssq.append(total_ssq)\n","    # Overall Test Loss\n","    loss = sklearn.metrics.mean_squared_error(pred_total_ssq, output_test_total_ssq, squared = False)\n","    print(\"Test Loss no \",iteration,\":\" ,loss)\n","    total_losses.append(loss)\n","average_loss = sum(total_losses) / len(total_losses)\n","\n","print(sample_size, simulations_test)\n","print(\"average_loss:\",average_loss)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN2U8ugxfEHAXbzdLUfResn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}