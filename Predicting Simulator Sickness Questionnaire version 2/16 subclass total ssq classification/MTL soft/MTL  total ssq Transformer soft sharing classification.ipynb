{"cells":[{"cell_type":"code","execution_count":135,"metadata":{"executionInfo":{"elapsed":180,"status":"ok","timestamp":1725957320400,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fT_A9oAGAepC"},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":136,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1177,"status":"ok","timestamp":1725957321818,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"TishlaEBAmlN","outputId":"e6ea8ed3-197f-4862-f4f7-984395e5693e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":137,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1725957321819,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"XeSwJ8oKAt2r"},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":138,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725957321819,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"BFHyHoFvA5bX"},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":139,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1725957321819,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"QeoIWcudA94b"},"outputs":[],"source":["def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","        arrays_3d.append(array_3d)\n","\n","    return arrays_3d\n"]},{"cell_type":"code","source":["sample_size=60\n","# simulations_train = ['noise','bumps']\n","# simulations_test=['flat']\n","# val_indices = [4, 10, 11, 26, 28, 31, 33, 37] # for flat\n","# train_indices = [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 38, 39, 40, 41] # for flat\n","\n","\n","# simulations_test=['noise']\n","# simulations_train = ['flat','bumps']\n","# val_indices = [7, 15, 17, 19, 28, 31, 32, 42, 44, 48] # for noise\n","# train_indices = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47] # for noise\n","\n","simulations_test=['bumps']\n","simulations_train = ['flat','noise']\n","val_indices = [1, 12, 16, 18, 22, 26, 28, 37, 41] # for speedbumps\n","train_indices = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44] # for speedbumps"],"metadata":{"id":"w90UVk1KeYdC","executionInfo":{"status":"ok","timestamp":1725957321820,"user_tz":300,"elapsed":11,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":140,"outputs":[]},{"cell_type":"code","execution_count":141,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1725957321820,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fqaeUGUDBCtT"},"outputs":[],"source":["participants = [str(i) for i in range(1, 27)]  # Participants 101 to 123\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":142,"metadata":{"executionInfo":{"elapsed":2274,"status":"ok","timestamp":1725957324085,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"DwS92BItBL4B"},"outputs":[],"source":["arrays_train = construct_3d_array(base_path, participants, simulations_train, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_test = construct_3d_array(base_path, participants, simulations_test, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","execution_count":143,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1725957324087,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"GgAM9zg_BRe8","outputId":"8f51d1a7-0201-486e-bc1c-cc6d3752f40a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the final concatenated 3D array: (45, 180, 47)\n","Shape of the final concatenated 3D array: (23, 180, 47)\n"]}],"source":["# Concatenate arrays along the first axis\n","input_train = np.concatenate(arrays_train, axis=0)\n","input_test = np.concatenate(arrays_test, axis=0)\n","# Display the shape of the final concatenated 3D array\n","print(f\"Shape of the final concatenated 3D array: {input_train.shape}\")\n","print(f\"Shape of the final concatenated 3D array: {input_test.shape}\")"]},{"cell_type":"code","execution_count":144,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1725957324088,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"vPQyeAYKBYaO"},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[:, n_columns].sum(axis=1)\n","    o_val = df.iloc[:, o_columns].sum(axis=1)\n","    d_val = df.iloc[:, d_columns].sum(axis=1)\n","\n","    total_ssq = (n_val+o_val+d_val) * 3.74\n","    return n_val,o_val,d_val"]},{"cell_type":"code","execution_count":145,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725957324088,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"Xpn0lDt0BfvE"},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          # n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          # total_ssq_values.append([n_val, o_val, d_val])\n","          ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":146,"metadata":{"id":"7k17K0HrCr6-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725957325761,"user_tz":300,"elapsed":1684,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"3f641fa7-3485-4371-c72e-763748361ef4"},"outputs":[{"output_type":"stream","name":"stdout","text":["(45, 16) (23, 16) (45, 1) (23, 1)\n"]}],"source":["output_train=merge_ssq_column(simulations_train,participants)\n","output_train = np.squeeze(output_train)\n","output_test=merge_ssq_column(simulations_test,participants)\n","output_test = np.squeeze(output_test)\n","output_train_total_ssq=merge_total_ssq(simulations_train,participants)\n","output_test_total_ssq=merge_total_ssq(simulations_test,participants)\n","output_train_total_ssq=output_train_total_ssq.reshape(-1, 1)\n","output_test_total_ssq=output_test_total_ssq.reshape(-1, 1)\n","print(output_train.shape,output_test.shape,output_train_total_ssq.shape,output_test_total_ssq.shape)\n","# print(output_train)\n","# print(output_train_total_ssq)\n"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def show_column_distribution(array, name):\n","    plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n","\n","    num_columns = array.shape[1]  # Number of columns in the array\n","    max_value = np.max(array)  # Maximum value across all columns\n","\n","    # Width of each bar\n","    width = 0.8 / num_columns\n","    legend_labels=[]\n","    # Plot the histograms for each column\n","    for i in range(num_columns):\n","        # Calculate the frequency of each value within the range of maximum value for the column\n","        column_counts = np.bincount(array[:, i], minlength=max_value+1)\n","\n","        # Offset for positioning bars of different columns\n","        x_offset = i * width\n","\n","        # Position for each bar\n","        x = np.arange(max_value+1) + x_offset\n","        if i == 0:\n","            plt.bar(x, column_counts, width=width, label=f'Nausea Value')\n","        elif i == 1:\n","            plt.bar(x, column_counts, width=width, label=f'Oculomotor Value')\n","        else:\n","            plt.bar(x, column_counts, width=width, label=f'Disorientation Value')\n","\n","\n","        # Add numerical data alongside the plot\n","        for j, count in enumerate(column_counts):\n","            plt.text(j + x_offset, count + 0.5, str(int(count)), ha='center', va='bottom')\n","\n","\n","\n","    plt.xlabel('Value')  # Label for x-axis\n","    plt.ylabel('Number of data points')  # Label for y-axis\n","    #plt.title(f'Distribution of values for all columns in {name}')  # Title of the plot\n","    plt.xticks(np.arange(max_value+1) + (width * num_columns / 2), range(max_value+1))  # Adjust x-axis ticks\n","    plt.legend()  # Show legend\n","\n","    plt.show()\n"],"metadata":{"id":"DbS4TcoLjrFf","executionInfo":{"status":"ok","timestamp":1725957325761,"user_tz":300,"elapsed":10,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":147,"outputs":[]},{"cell_type":"code","source":["stacked_output = np.vstack((output_train, output_test))\n","# show_column_distribution(stacked_output,\"train distribution\")"],"metadata":{"id":"CtLD379IjyPU","executionInfo":{"status":"ok","timestamp":1725957325761,"user_tz":300,"elapsed":9,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":148,"outputs":[]},{"cell_type":"code","execution_count":149,"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1725957325762,"user_tz":300,"elapsed":9,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"]},{"cell_type":"code","execution_count":150,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1725957325762,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"LyvV6GFDC66F"},"outputs":[],"source":["from keras.utils import to_categorical\n","input_train, input_test= scale_input_data(input_train[:, (60-sample_size):(180-sample_size), :], input_test[:, (60-sample_size):(180-sample_size), :])\n","\n","\n","# Convert the original labels to one-hot encoded format\n","output_train_encoded = to_categorical(output_train, num_classes=4)\n","\n","\n","input_val = input_train[val_indices]\n","input_train = input_train[train_indices]\n","output_val = output_train_encoded[val_indices]\n","output_val_total_ssq = output_train_total_ssq[val_indices]\n","output_train = output_train_encoded[train_indices]\n"]},{"cell_type":"code","source":["print(\"input_train :\", input_train.shape)\n","print(\"output_train :\", output_train.shape)\n","print(\"input_val :\", input_val.shape)\n","print(\"output_val :\", output_val.shape)\n","print(\"input_test :\", input_test.shape)\n","print(\"output_test :\", output_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yiz0HsnDf3HB","executionInfo":{"status":"ok","timestamp":1725957326307,"user_tz":300,"elapsed":552,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"42a95579-0640-4b79-af69-1580d4c1ec6f"},"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["input_train : (36, 120, 47)\n","output_train : (36, 16, 4)\n","input_val : (9, 120, 47)\n","output_val : (9, 16, 4)\n","input_test : (23, 120, 47)\n","output_test : (23, 16)\n"]}]},{"cell_type":"code","execution_count":152,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213592,"status":"ok","timestamp":1725957539895,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"E6ssyYUeDJwI","outputId":"d07c6a05-104f-4c70-a13c-64c662c41080"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 123ms/step - dense_644_accuracy: 0.3843 - dense_645_accuracy: 0.7500 - dense_646_accuracy: 0.1134 - dense_647_accuracy: 0.3160 - dense_648_accuracy: 0.4711 - dense_649_accuracy: 0.0579 - dense_650_accuracy: 0.4711 - dense_651_accuracy: 0.1238 - dense_652_accuracy: 0.1921 - dense_653_accuracy: 0.1030 - dense_654_accuracy: 0.0000e+00 - dense_655_accuracy: 0.7396 - dense_656_accuracy: 0.0370 - dense_657_accuracy: 0.8079 - dense_658_accuracy: 0.3264 - dense_659_accuracy: 0.4896 - loss: 22.4824\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_644_accuracy: 0.5185 - dense_645_accuracy: 0.7685 - dense_646_accuracy: 0.8264 - dense_647_accuracy: 0.5868 - dense_648_accuracy: 0.8264 - dense_649_accuracy: 0.3553 - dense_650_accuracy: 0.5660 - dense_651_accuracy: 0.4317 - dense_652_accuracy: 0.6817 - dense_653_accuracy: 0.8947 - dense_654_accuracy: 0.2766 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7500 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.6343 - dense_659_accuracy: 0.8553 - loss: 16.7861\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - dense_644_accuracy: 0.5185 - dense_645_accuracy: 0.7789 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.5949 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5579 - dense_651_accuracy: 0.6528 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.8843 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.6343 - dense_659_accuracy: 0.8657 - loss: 12.0584\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_644_accuracy: 0.5185 - dense_645_accuracy: 0.7685 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.5949 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.6447 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7894 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5764 - dense_659_accuracy: 0.8657 - loss: 11.9059\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - dense_644_accuracy: 0.5185 - dense_645_accuracy: 0.7789 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6053 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5949 - dense_651_accuracy: 0.6343 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8947 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7998 - dense_656_accuracy: 0.7894 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.6343 - dense_659_accuracy: 0.8553 - loss: 12.0590\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_644_accuracy: 0.5289 - dense_645_accuracy: 0.7894 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6053 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8368 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.6343 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9236 - dense_655_accuracy: 0.7685 - dense_656_accuracy: 0.7500 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.4792 - dense_659_accuracy: 0.8553 - loss: 11.4914 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_644_accuracy: 0.4236 - dense_645_accuracy: 0.7894 - dense_646_accuracy: 0.9525 - dense_647_accuracy: 0.6157 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.6157 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7106 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5185 - dense_659_accuracy: 0.8553 - loss: 11.0274 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - dense_644_accuracy: 0.4236 - dense_645_accuracy: 0.6736 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.5104 - dense_648_accuracy: 0.8183 - dense_649_accuracy: 0.8472 - dense_650_accuracy: 0.5683 - dense_651_accuracy: 0.6366 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8947 - dense_654_accuracy: 0.9236 - dense_655_accuracy: 0.4711 - dense_656_accuracy: 0.7789 - dense_657_accuracy: 0.9525 - dense_658_accuracy: 0.5868 - dense_659_accuracy: 0.8657 - loss: 10.1896\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 7, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_644_accuracy: 0.5370 - dense_645_accuracy: 0.6262 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.4525 - dense_648_accuracy: 0.8079 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5579 - dense_651_accuracy: 0.5000 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8947 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7894 - dense_656_accuracy: 0.7789 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5764 - dense_659_accuracy: 0.8553 - loss: 10.3159\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 8, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_644_accuracy: 0.3264 - dense_645_accuracy: 0.7106 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6447 - dense_648_accuracy: 0.8368 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5000 - dense_651_accuracy: 0.5081 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8657 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7789 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5949 - dense_659_accuracy: 0.8657 - loss: 10.5493\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 9, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - dense_644_accuracy: 0.4317 - dense_645_accuracy: 0.7789 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.5000 - dense_648_accuracy: 0.8079 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5579 - dense_651_accuracy: 0.6157 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7894 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5660 - dense_659_accuracy: 0.8553 - loss: 9.8867\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 10, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_644_accuracy: 0.4896 - dense_645_accuracy: 0.7789 - dense_646_accuracy: 0.9525 - dense_647_accuracy: 0.5972 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8472 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.5764 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.9236 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7685 - dense_656_accuracy: 0.7789 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5868 - dense_659_accuracy: 0.8553 - loss: 9.6703\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 11, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - dense_644_accuracy: 0.5289 - dense_645_accuracy: 0.7789 - dense_646_accuracy: 0.9525 - dense_647_accuracy: 0.5764 - dense_648_accuracy: 0.8079 - dense_649_accuracy: 0.8368 - dense_650_accuracy: 0.5289 - dense_651_accuracy: 0.6343 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.6157 - dense_659_accuracy: 0.8553 - loss: 9.4213\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 12, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - dense_644_accuracy: 0.5660 - dense_645_accuracy: 0.7789 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6447 - dense_648_accuracy: 0.8079 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.6343 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7315 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5949 - dense_659_accuracy: 0.8553 - loss: 9.1675\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 13, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - dense_644_accuracy: 0.5660 - dense_645_accuracy: 0.8368 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6447 - dense_648_accuracy: 0.8264 - dense_649_accuracy: 0.8079 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.6343 - dense_652_accuracy: 0.9236 - dense_653_accuracy: 0.8657 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7975 - dense_656_accuracy: 0.7789 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5868 - dense_659_accuracy: 0.8657 - loss: 9.0843\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n","k: 14, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - dense_644_accuracy: 0.5579 - dense_645_accuracy: 0.8368 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6447 - dense_648_accuracy: 0.8472 - dense_649_accuracy: 0.8368 - dense_650_accuracy: 0.5579 - dense_651_accuracy: 0.6551 - dense_652_accuracy: 0.8843 - dense_653_accuracy: 0.8264 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.5868 - dense_659_accuracy: 0.8553 - loss: 8.8053\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 15, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - dense_644_accuracy: 0.5000 - dense_645_accuracy: 0.7500 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.6343 - dense_648_accuracy: 0.8079 - dense_649_accuracy: 0.8472 - dense_650_accuracy: 0.5579 - dense_651_accuracy: 0.6736 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8947 - dense_654_accuracy: 0.9236 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7789 - dense_657_accuracy: 0.9525 - dense_658_accuracy: 0.5868 - dense_659_accuracy: 0.8553 - loss: 8.7111\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 16, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - dense_644_accuracy: 0.5764 - dense_645_accuracy: 0.7894 - dense_646_accuracy: 0.9525 - dense_647_accuracy: 0.6343 - dense_648_accuracy: 0.7975 - dense_649_accuracy: 0.8264 - dense_650_accuracy: 0.5475 - dense_651_accuracy: 0.6343 - dense_652_accuracy: 0.8947 - dense_653_accuracy: 0.8843 - dense_654_accuracy: 0.9132 - dense_655_accuracy: 0.7789 - dense_656_accuracy: 0.7685 - dense_657_accuracy: 0.9421 - dense_658_accuracy: 0.6343 - dense_659_accuracy: 0.8553 - loss: 8.5734\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 17, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - dense_644_accuracy: 0.6053 - dense_645_accuracy: 0.7500 - dense_646_accuracy: 0.9421 - dense_647_accuracy: 0.7396 - dense_648_accuracy: 0.8553 - dense_649_accuracy: 0.8576 - dense_650_accuracy: 0.5787 - dense_651_accuracy: 0.6736 - dense_652_accuracy: 0.9236 - dense_653_accuracy: 0.9236 - dense_654_accuracy: 0.9525 - dense_655_accuracy: 0.8183 - dense_656_accuracy: 0.8368 - dense_657_accuracy: 0.9815 - dense_658_accuracy: 0.6053 - dense_659_accuracy: 0.8762 - loss: 8.4442\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 18, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867ms/step\n","Test Loss iteration 0: 32.257647290148924\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - dense_664_accuracy: 0.2870 - dense_665_accuracy: 0.2002 - dense_666_accuracy: 0.0475 - dense_667_accuracy: 0.3738 - dense_668_accuracy: 0.0579 - dense_669_accuracy: 0.0949 - dense_670_accuracy: 0.2211 - dense_671_accuracy: 0.6632 - dense_672_accuracy: 0.7396 - dense_673_accuracy: 0.1632 - dense_674_accuracy: 0.0868 - dense_675_accuracy: 0.0949 - dense_676_accuracy: 0.3553 - dense_677_accuracy: 0.2188 - dense_678_accuracy: 0.1157 - dense_679_accuracy: 0.7685 - loss: 23.2954\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - dense_664_accuracy: 0.3843 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.4213 - dense_667_accuracy: 0.5949 - dense_668_accuracy: 0.3657 - dense_669_accuracy: 0.7975 - dense_670_accuracy: 0.4525 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.4213 - dense_674_accuracy: 0.7396 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.4421 - dense_679_accuracy: 0.8866 - loss: 17.3664\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - dense_664_accuracy: 0.5660 - dense_665_accuracy: 0.7789 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6157 - dense_668_accuracy: 0.8079 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.2500 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9236 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5370 - dense_679_accuracy: 0.8553 - loss: 12.9280\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_664_accuracy: 0.5289 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.5949 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5764 - dense_679_accuracy: 0.8553 - loss: 11.5300\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_664_accuracy: 0.5185 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6053 - dense_668_accuracy: 0.8183 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.6447 - dense_672_accuracy: 0.8947 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5868 - dense_679_accuracy: 0.8657 - loss: 12.1478 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - dense_664_accuracy: 0.5394 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6447 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5498 - dense_671_accuracy: 0.6157 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.7894 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5764 - dense_679_accuracy: 0.8657 - loss: 12.2534\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_664_accuracy: 0.5185 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.5868 - dense_668_accuracy: 0.8079 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.3553 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7894 - dense_676_accuracy: 0.7894 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5289 - dense_679_accuracy: 0.8657 - loss: 11.0741 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 6, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - dense_664_accuracy: 0.3553 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.4051 - dense_668_accuracy: 0.8079 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.2789 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.7396 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.4421 - dense_679_accuracy: 0.8553 - loss: 11.0974\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 7, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - dense_664_accuracy: 0.3472 - dense_665_accuracy: 0.7789 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.5185 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5475 - dense_671_accuracy: 0.2789 - dense_672_accuracy: 0.8947 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.4606 - dense_679_accuracy: 0.8553 - loss: 10.7138\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 8, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_664_accuracy: 0.3657 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6921 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.8079 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5475 - dense_679_accuracy: 0.8657 - loss: 9.9546\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 9, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - dense_664_accuracy: 0.4896 - dense_665_accuracy: 0.7894 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6528 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5475 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8947 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.6053 - dense_679_accuracy: 0.8553 - loss: 10.1395\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 10, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - dense_664_accuracy: 0.4132 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.5972 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5475 - dense_671_accuracy: 0.6238 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5764 - dense_679_accuracy: 0.8553 - loss: 10.3000 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 11, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - dense_664_accuracy: 0.5683 - dense_665_accuracy: 0.7604 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.5787 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.9051 - dense_674_accuracy: 0.9236 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7894 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5868 - dense_679_accuracy: 0.8553 - loss: 9.9890 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 12, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - dense_664_accuracy: 0.5289 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6817 - dense_668_accuracy: 0.8079 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5394 - dense_671_accuracy: 0.6447 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5972 - dense_679_accuracy: 0.8657 - loss: 9.2972\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 13, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - dense_664_accuracy: 0.4896 - dense_665_accuracy: 0.7789 - dense_666_accuracy: 0.9525 - dense_667_accuracy: 0.5579 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.4132 - dense_671_accuracy: 0.6343 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.8947 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5289 - dense_679_accuracy: 0.8657 - loss: 9.7059\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 14, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dense_664_accuracy: 0.5579 - dense_665_accuracy: 0.7685 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.7315 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5185 - dense_671_accuracy: 0.6238 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7685 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5289 - dense_679_accuracy: 0.8553 - loss: 9.1756 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 15, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_664_accuracy: 0.6076 - dense_665_accuracy: 0.7789 - dense_666_accuracy: 0.9525 - dense_667_accuracy: 0.6736 - dense_668_accuracy: 0.8183 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.6551 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5972 - dense_679_accuracy: 0.8553 - loss: 9.0162\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 16, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - dense_664_accuracy: 0.5764 - dense_665_accuracy: 0.7789 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.6053 - dense_668_accuracy: 0.8079 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.6551 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7894 - dense_676_accuracy: 0.7894 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5764 - dense_679_accuracy: 0.8657 - loss: 9.2970 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 17, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - dense_664_accuracy: 0.6343 - dense_665_accuracy: 0.7789 - dense_666_accuracy: 0.9525 - dense_667_accuracy: 0.6817 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5475 - dense_671_accuracy: 0.6447 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.9051 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7975 - dense_676_accuracy: 0.8183 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5764 - dense_679_accuracy: 0.8553 - loss: 8.9448\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 18, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - dense_664_accuracy: 0.5764 - dense_665_accuracy: 0.8264 - dense_666_accuracy: 0.9236 - dense_667_accuracy: 0.7106 - dense_668_accuracy: 0.8183 - dense_669_accuracy: 0.8472 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.7025 - dense_672_accuracy: 0.9051 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9236 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7211 - dense_677_accuracy: 0.9525 - dense_678_accuracy: 0.6343 - dense_679_accuracy: 0.8657 - loss: 8.3444\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 19, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - dense_664_accuracy: 0.7211 - dense_665_accuracy: 0.8657 - dense_666_accuracy: 0.8657 - dense_667_accuracy: 0.7975 - dense_668_accuracy: 0.8287 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.5660 - dense_672_accuracy: 0.9236 - dense_673_accuracy: 0.8553 - dense_674_accuracy: 0.9421 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.5764 - dense_679_accuracy: 0.8762 - loss: 8.2556\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 20, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - dense_664_accuracy: 0.7211 - dense_665_accuracy: 0.8947 - dense_666_accuracy: 0.9815 - dense_667_accuracy: 0.7975 - dense_668_accuracy: 0.8264 - dense_669_accuracy: 0.8762 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.6447 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8553 - dense_674_accuracy: 0.8947 - dense_675_accuracy: 0.7789 - dense_676_accuracy: 0.8368 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.6551 - dense_679_accuracy: 0.8553 - loss: 8.2335\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 21, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - dense_664_accuracy: 0.6053 - dense_665_accuracy: 0.8843 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8657 - dense_668_accuracy: 0.8264 - dense_669_accuracy: 0.8843 - dense_670_accuracy: 0.6447 - dense_671_accuracy: 0.6447 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.8947 - dense_675_accuracy: 0.7975 - dense_676_accuracy: 0.8079 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.6157 - dense_679_accuracy: 0.7975 - loss: 7.9009\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n","k: 22, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - dense_664_accuracy: 0.5868 - dense_665_accuracy: 0.8553 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.7500 - dense_668_accuracy: 0.7975 - dense_669_accuracy: 0.8762 - dense_670_accuracy: 0.5868 - dense_671_accuracy: 0.7789 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9421 - dense_675_accuracy: 0.7975 - dense_676_accuracy: 0.8553 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.5000 - dense_679_accuracy: 0.8843 - loss: 7.6051\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n","k: 23, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - dense_664_accuracy: 0.6632 - dense_665_accuracy: 0.8079 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.8264 - dense_668_accuracy: 0.8368 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.6053 - dense_671_accuracy: 0.7025 - dense_672_accuracy: 0.8947 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.8183 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5868 - dense_679_accuracy: 0.8553 - loss: 7.6309\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 24, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - dense_664_accuracy: 0.7396 - dense_665_accuracy: 0.8368 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.7975 - dense_668_accuracy: 0.8264 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.7315 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.9132 - dense_675_accuracy: 0.7975 - dense_676_accuracy: 0.7975 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.5949 - dense_679_accuracy: 0.8553 - loss: 7.3890\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 25, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - dense_664_accuracy: 0.7396 - dense_665_accuracy: 0.8657 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.7975 - dense_668_accuracy: 0.8264 - dense_669_accuracy: 0.8264 - dense_670_accuracy: 0.6632 - dense_671_accuracy: 0.7211 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.8264 - dense_677_accuracy: 0.9421 - dense_678_accuracy: 0.6528 - dense_679_accuracy: 0.8553 - loss: 7.0881\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n","k: 26, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_664_accuracy: 0.7604 - dense_665_accuracy: 0.8264 - dense_666_accuracy: 0.9525 - dense_667_accuracy: 0.8657 - dense_668_accuracy: 0.8264 - dense_669_accuracy: 0.8368 - dense_670_accuracy: 0.6053 - dense_671_accuracy: 0.7211 - dense_672_accuracy: 0.8843 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8553 - dense_676_accuracy: 0.8553 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7025 - dense_679_accuracy: 0.8368 - loss: 6.8522 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 27, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_664_accuracy: 0.7396 - dense_665_accuracy: 0.8553 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.8657 - dense_668_accuracy: 0.8947 - dense_669_accuracy: 0.8553 - dense_670_accuracy: 0.5579 - dense_671_accuracy: 0.7685 - dense_672_accuracy: 0.9132 - dense_673_accuracy: 0.8657 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8079 - dense_676_accuracy: 0.8657 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7025 - dense_679_accuracy: 0.8657 - loss: 6.7401 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 28, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_664_accuracy: 0.7500 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 0.9421 - dense_667_accuracy: 0.8553 - dense_668_accuracy: 0.8947 - dense_669_accuracy: 0.8553 - dense_670_accuracy: 0.6551 - dense_671_accuracy: 0.7211 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 1.0000 - dense_675_accuracy: 0.8657 - dense_676_accuracy: 0.8079 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.6157 - dense_679_accuracy: 0.8866 - loss: 6.4637 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 29, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - dense_664_accuracy: 0.7500 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.9051 - dense_668_accuracy: 0.8843 - dense_669_accuracy: 0.8843 - dense_670_accuracy: 0.5289 - dense_671_accuracy: 0.7500 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 1.0000 - dense_675_accuracy: 0.8762 - dense_676_accuracy: 0.8079 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.6921 - dense_679_accuracy: 0.8553 - loss: 6.4223 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 30, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_664_accuracy: 0.7396 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8657 - dense_668_accuracy: 0.8843 - dense_669_accuracy: 0.8553 - dense_670_accuracy: 0.5764 - dense_671_accuracy: 0.7685 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8553 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8264 - dense_676_accuracy: 0.8368 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7025 - dense_679_accuracy: 0.8553 - loss: 6.4641\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 31, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_664_accuracy: 0.7685 - dense_665_accuracy: 0.9051 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8843 - dense_668_accuracy: 0.8947 - dense_669_accuracy: 0.8553 - dense_670_accuracy: 0.6053 - dense_671_accuracy: 0.7789 - dense_672_accuracy: 0.9525 - dense_673_accuracy: 0.8264 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8368 - dense_676_accuracy: 0.8843 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7106 - dense_679_accuracy: 0.8553 - loss: 6.0351 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 32, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_664_accuracy: 0.6817 - dense_665_accuracy: 0.8553 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.9236 - dense_668_accuracy: 0.8553 - dense_669_accuracy: 0.8843 - dense_670_accuracy: 0.6343 - dense_671_accuracy: 0.7894 - dense_672_accuracy: 0.9132 - dense_673_accuracy: 0.9236 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8947 - dense_676_accuracy: 0.7789 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.6447 - dense_679_accuracy: 0.8553 - loss: 5.8191 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 33, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dense_664_accuracy: 0.7211 - dense_665_accuracy: 0.8553 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8843 - dense_668_accuracy: 0.8657 - dense_669_accuracy: 0.8657 - dense_670_accuracy: 0.6632 - dense_671_accuracy: 0.7998 - dense_672_accuracy: 0.9132 - dense_673_accuracy: 0.9236 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.7685 - dense_676_accuracy: 0.8264 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7500 - dense_679_accuracy: 0.8843 - loss: 5.7371 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 34, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - dense_664_accuracy: 0.8079 - dense_665_accuracy: 0.8553 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8843 - dense_668_accuracy: 0.8843 - dense_669_accuracy: 0.8843 - dense_670_accuracy: 0.5972 - dense_671_accuracy: 0.7789 - dense_672_accuracy: 0.9132 - dense_673_accuracy: 0.8368 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8553 - dense_676_accuracy: 0.9421 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.6817 - dense_679_accuracy: 0.8947 - loss: 5.5587\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 35, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - dense_664_accuracy: 0.8079 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.9421 - dense_668_accuracy: 0.8553 - dense_669_accuracy: 0.8843 - dense_670_accuracy: 0.6551 - dense_671_accuracy: 0.7604 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8947 - dense_676_accuracy: 0.8553 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7106 - dense_679_accuracy: 0.9132 - loss: 5.2253\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 36, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_664_accuracy: 0.7789 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8368 - dense_668_accuracy: 0.8553 - dense_669_accuracy: 0.9132 - dense_670_accuracy: 0.6736 - dense_671_accuracy: 0.8553 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8553 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8762 - dense_676_accuracy: 0.9132 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.7396 - dense_679_accuracy: 0.9132 - loss: 5.2414\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 37, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - dense_664_accuracy: 0.7708 - dense_665_accuracy: 0.8947 - dense_666_accuracy: 0.9815 - dense_667_accuracy: 0.8843 - dense_668_accuracy: 0.8553 - dense_669_accuracy: 0.9236 - dense_670_accuracy: 0.6053 - dense_671_accuracy: 0.7894 - dense_672_accuracy: 0.9132 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 1.0000 - dense_675_accuracy: 0.8553 - dense_676_accuracy: 0.8843 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.7315 - dense_679_accuracy: 0.9132 - loss: 4.9965\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 38, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - dense_664_accuracy: 0.7500 - dense_665_accuracy: 0.9236 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.9711 - dense_668_accuracy: 0.9051 - dense_669_accuracy: 0.8843 - dense_670_accuracy: 0.6921 - dense_671_accuracy: 0.7975 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8657 - dense_676_accuracy: 0.9132 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.8079 - dense_679_accuracy: 0.9236 - loss: 4.7430\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 39, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - dense_664_accuracy: 0.8079 - dense_665_accuracy: 0.8843 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.8843 - dense_668_accuracy: 0.8264 - dense_669_accuracy: 0.9421 - dense_670_accuracy: 0.6921 - dense_671_accuracy: 0.8368 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8657 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8657 - dense_676_accuracy: 0.8843 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7106 - dense_679_accuracy: 0.9132 - loss: 4.6553\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 40, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - dense_664_accuracy: 0.8368 - dense_665_accuracy: 0.9236 - dense_666_accuracy: 0.9525 - dense_667_accuracy: 0.8843 - dense_668_accuracy: 0.8947 - dense_669_accuracy: 0.9132 - dense_670_accuracy: 0.7500 - dense_671_accuracy: 0.7975 - dense_672_accuracy: 0.9525 - dense_673_accuracy: 0.9132 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8553 - dense_676_accuracy: 0.8947 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.8079 - dense_679_accuracy: 0.9132 - loss: 4.5767\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n","k: 41, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - dense_664_accuracy: 0.8183 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 0.9711 - dense_667_accuracy: 0.9525 - dense_668_accuracy: 0.8843 - dense_669_accuracy: 0.9236 - dense_670_accuracy: 0.6632 - dense_671_accuracy: 0.8079 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8947 - dense_674_accuracy: 1.0000 - dense_675_accuracy: 0.8657 - dense_676_accuracy: 0.8472 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.7604 - dense_679_accuracy: 0.9132 - loss: 4.5636\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n","k: 42, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - dense_664_accuracy: 0.8368 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 1.0000 - dense_667_accuracy: 0.9711 - dense_668_accuracy: 0.8843 - dense_669_accuracy: 0.9815 - dense_670_accuracy: 0.6921 - dense_671_accuracy: 0.8264 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.8843 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8183 - dense_676_accuracy: 0.8553 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.7975 - dense_679_accuracy: 0.8264 - loss: 4.2983\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 43, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - dense_664_accuracy: 0.7975 - dense_665_accuracy: 0.9132 - dense_666_accuracy: 1.0000 - dense_667_accuracy: 0.9421 - dense_668_accuracy: 0.8553 - dense_669_accuracy: 0.9132 - dense_670_accuracy: 0.6736 - dense_671_accuracy: 0.8368 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.9132 - dense_674_accuracy: 0.9711 - dense_675_accuracy: 0.8553 - dense_676_accuracy: 0.9132 - dense_677_accuracy: 0.9711 - dense_678_accuracy: 0.8079 - dense_679_accuracy: 0.9132 - loss: 4.3961\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 44, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - dense_664_accuracy: 0.8368 - dense_665_accuracy: 0.9421 - dense_666_accuracy: 1.0000 - dense_667_accuracy: 0.9132 - dense_668_accuracy: 0.8843 - dense_669_accuracy: 0.9132 - dense_670_accuracy: 0.6343 - dense_671_accuracy: 0.8264 - dense_672_accuracy: 0.9421 - dense_673_accuracy: 0.9711 - dense_674_accuracy: 0.9815 - dense_675_accuracy: 0.8264 - dense_676_accuracy: 0.8843 - dense_677_accuracy: 1.0000 - dense_678_accuracy: 0.7975 - dense_679_accuracy: 0.8843 - loss: 4.2100\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 45, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712ms/step\n","Test Loss iteration 1: 25.015856189016706\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 107ms/step - dense_684_accuracy: 0.2685 - dense_685_accuracy: 0.1134 - dense_686_accuracy: 0.2106 - dense_687_accuracy: 0.4815 - dense_688_accuracy: 0.3160 - dense_689_accuracy: 0.4132 - dense_690_accuracy: 0.3264 - dense_691_accuracy: 0.2396 - dense_692_accuracy: 0.2002 - dense_693_accuracy: 0.0185 - dense_694_accuracy: 0.0764 - dense_695_accuracy: 0.6921 - dense_696_accuracy: 0.1343 - dense_697_accuracy: 0.0000e+00 - dense_698_accuracy: 0.3553 - dense_699_accuracy: 0.4792 - loss: 22.4262\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_684_accuracy: 0.5000 - dense_685_accuracy: 0.7789 - dense_686_accuracy: 0.8843 - dense_687_accuracy: 0.3368 - dense_688_accuracy: 0.8079 - dense_689_accuracy: 0.8264 - dense_690_accuracy: 0.5475 - dense_691_accuracy: 0.5868 - dense_692_accuracy: 0.8553 - dense_693_accuracy: 0.3843 - dense_694_accuracy: 0.4792 - dense_695_accuracy: 0.7894 - dense_696_accuracy: 0.6157 - dense_697_accuracy: 0.7685 - dense_698_accuracy: 0.5289 - dense_699_accuracy: 0.8553 - loss: 16.2789 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - dense_684_accuracy: 0.4132 - dense_685_accuracy: 0.7789 - dense_686_accuracy: 0.9525 - dense_687_accuracy: 0.4421 - dense_688_accuracy: 0.7975 - dense_689_accuracy: 0.8472 - dense_690_accuracy: 0.5683 - dense_691_accuracy: 0.6053 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8947 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7685 - dense_696_accuracy: 0.7789 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.6551 - dense_699_accuracy: 0.8657 - loss: 12.3123 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_684_accuracy: 0.5289 - dense_685_accuracy: 0.8079 - dense_686_accuracy: 0.9525 - dense_687_accuracy: 0.5764 - dense_688_accuracy: 0.7975 - dense_689_accuracy: 0.8264 - dense_690_accuracy: 0.5475 - dense_691_accuracy: 0.6343 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8843 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7685 - dense_696_accuracy: 0.7685 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.3762 - dense_699_accuracy: 0.8553 - loss: 11.3165\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - dense_684_accuracy: 0.5185 - dense_685_accuracy: 0.7894 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.6053 - dense_688_accuracy: 0.7975 - dense_689_accuracy: 0.8368 - dense_690_accuracy: 0.5475 - dense_691_accuracy: 0.6238 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8843 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7685 - dense_696_accuracy: 0.7685 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.4317 - dense_699_accuracy: 0.8553 - loss: 11.3518 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - dense_684_accuracy: 0.4630 - dense_685_accuracy: 0.7211 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.6157 - dense_688_accuracy: 0.8079 - dense_689_accuracy: 0.8368 - dense_690_accuracy: 0.4525 - dense_691_accuracy: 0.6447 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8843 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7685 - dense_696_accuracy: 0.7685 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.5868 - dense_699_accuracy: 0.8553 - loss: 11.2918\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - dense_684_accuracy: 0.4711 - dense_685_accuracy: 0.7604 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.6157 - dense_688_accuracy: 0.8183 - dense_689_accuracy: 0.8472 - dense_690_accuracy: 0.6076 - dense_691_accuracy: 0.6551 - dense_692_accuracy: 0.8947 - dense_693_accuracy: 0.8947 - dense_694_accuracy: 0.9236 - dense_695_accuracy: 0.7894 - dense_696_accuracy: 0.7789 - dense_697_accuracy: 0.9525 - dense_698_accuracy: 0.5579 - dense_699_accuracy: 0.8553 - loss: 10.1861\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_684_accuracy: 0.3553 - dense_685_accuracy: 0.7106 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.5394 - dense_688_accuracy: 0.7315 - dense_689_accuracy: 0.8264 - dense_690_accuracy: 0.5289 - dense_691_accuracy: 0.5208 - dense_692_accuracy: 0.8947 - dense_693_accuracy: 0.8843 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7685 - dense_696_accuracy: 0.7685 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.5104 - dense_699_accuracy: 0.8368 - loss: 10.6882 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 7, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - dense_684_accuracy: 0.5208 - dense_685_accuracy: 0.7396 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.4421 - dense_688_accuracy: 0.7685 - dense_689_accuracy: 0.8368 - dense_690_accuracy: 0.5104 - dense_691_accuracy: 0.2975 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8843 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7685 - dense_696_accuracy: 0.7685 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.5764 - dense_699_accuracy: 0.8553 - loss: 10.6978\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 8, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_684_accuracy: 0.5579 - dense_685_accuracy: 0.7789 - dense_686_accuracy: 0.9525 - dense_687_accuracy: 0.3657 - dense_688_accuracy: 0.7975 - dense_689_accuracy: 0.8368 - dense_690_accuracy: 0.5660 - dense_691_accuracy: 0.5868 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.9051 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7894 - dense_696_accuracy: 0.7894 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.5868 - dense_699_accuracy: 0.8553 - loss: 10.0590\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 9, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_684_accuracy: 0.5289 - dense_685_accuracy: 0.7685 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.5972 - dense_688_accuracy: 0.8079 - dense_689_accuracy: 0.8264 - dense_690_accuracy: 0.5475 - dense_691_accuracy: 0.6343 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8947 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7789 - dense_696_accuracy: 0.7685 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.5660 - dense_699_accuracy: 0.8553 - loss: 9.9985  \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 10, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - dense_684_accuracy: 0.4028 - dense_685_accuracy: 0.7685 - dense_686_accuracy: 0.9421 - dense_687_accuracy: 0.5370 - dense_688_accuracy: 0.7975 - dense_689_accuracy: 0.8264 - dense_690_accuracy: 0.5579 - dense_691_accuracy: 0.6343 - dense_692_accuracy: 0.8843 - dense_693_accuracy: 0.8843 - dense_694_accuracy: 0.9132 - dense_695_accuracy: 0.7894 - dense_696_accuracy: 0.7789 - dense_697_accuracy: 0.9421 - dense_698_accuracy: 0.5868 - dense_699_accuracy: 0.8657 - loss: 10.0440 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 11, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 679ms/step\n","Test Loss iteration 2: 43.699101572696776\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 81ms/step - dense_704_accuracy: 0.0579 - dense_705_accuracy: 0.2685 - dense_706_accuracy: 0.0000e+00 - dense_707_accuracy: 0.3843 - dense_708_accuracy: 0.1736 - dense_709_accuracy: 0.1238 - dense_710_accuracy: 0.5104 - dense_711_accuracy: 0.0868 - dense_712_accuracy: 0.0660 - dense_713_accuracy: 0.8368 - dense_714_accuracy: 0.2025 - dense_715_accuracy: 0.0845 - dense_716_accuracy: 0.6343 - dense_717_accuracy: 0.1898 - dense_718_accuracy: 0.1528 - dense_719_accuracy: 0.7894 - loss: 22.5510\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 663ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dense_704_accuracy: 0.4421 - dense_705_accuracy: 0.7685 - dense_706_accuracy: 0.8553 - dense_707_accuracy: 0.6053 - dense_708_accuracy: 0.7025 - dense_709_accuracy: 0.7685 - dense_710_accuracy: 0.3449 - dense_711_accuracy: 0.3738 - dense_712_accuracy: 0.8264 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.7685 - dense_715_accuracy: 0.8079 - dense_716_accuracy: 0.7685 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5660 - dense_719_accuracy: 0.8553 - loss: 17.1118 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - dense_704_accuracy: 0.6262 - dense_705_accuracy: 0.7789 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.6157 - dense_708_accuracy: 0.7894 - dense_709_accuracy: 0.8472 - dense_710_accuracy: 0.5475 - dense_711_accuracy: 0.6447 - dense_712_accuracy: 0.9051 - dense_713_accuracy: 0.9051 - dense_714_accuracy: 0.9236 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7789 - dense_717_accuracy: 0.9525 - dense_718_accuracy: 0.5868 - dense_719_accuracy: 0.8553 - loss: 12.2573 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_704_accuracy: 0.3657 - dense_705_accuracy: 0.7894 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.6343 - dense_708_accuracy: 0.8183 - dense_709_accuracy: 0.8368 - dense_710_accuracy: 0.5579 - dense_711_accuracy: 0.6343 - dense_712_accuracy: 0.9051 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9236 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7789 - dense_717_accuracy: 0.9525 - dense_718_accuracy: 0.5868 - dense_719_accuracy: 0.8762 - loss: 10.9485\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - dense_704_accuracy: 0.3947 - dense_705_accuracy: 0.7789 - dense_706_accuracy: 0.9525 - dense_707_accuracy: 0.5000 - dense_708_accuracy: 0.7975 - dense_709_accuracy: 0.8368 - dense_710_accuracy: 0.5579 - dense_711_accuracy: 0.6447 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7685 - dense_716_accuracy: 0.7685 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5972 - dense_719_accuracy: 0.8657 - loss: 11.0689\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 4, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_704_accuracy: 0.3657 - dense_705_accuracy: 0.7419 - dense_706_accuracy: 0.9525 - dense_707_accuracy: 0.4028 - dense_708_accuracy: 0.8079 - dense_709_accuracy: 0.8472 - dense_710_accuracy: 0.5104 - dense_711_accuracy: 0.6447 - dense_712_accuracy: 0.8947 - dense_713_accuracy: 0.8947 - dense_714_accuracy: 0.9340 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7894 - dense_717_accuracy: 0.9525 - dense_718_accuracy: 0.5972 - dense_719_accuracy: 0.8657 - loss: 10.4044\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 5, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - dense_704_accuracy: 0.5185 - dense_705_accuracy: 0.7500 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.5000 - dense_708_accuracy: 0.8183 - dense_709_accuracy: 0.8264 - dense_710_accuracy: 0.5868 - dense_711_accuracy: 0.6447 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7604 - dense_716_accuracy: 0.7789 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.4421 - dense_719_accuracy: 0.8553 - loss: 10.5582\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 6, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - dense_704_accuracy: 0.4421 - dense_705_accuracy: 0.6817 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.4711 - dense_708_accuracy: 0.7685 - dense_709_accuracy: 0.8264 - dense_710_accuracy: 0.5185 - dense_711_accuracy: 0.5683 - dense_712_accuracy: 0.9132 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7708 - dense_716_accuracy: 0.7894 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.6053 - dense_719_accuracy: 0.8657 - loss: 10.5868\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 7, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_704_accuracy: 0.5394 - dense_705_accuracy: 0.7419 - dense_706_accuracy: 0.9525 - dense_707_accuracy: 0.6157 - dense_708_accuracy: 0.8079 - dense_709_accuracy: 0.8472 - dense_710_accuracy: 0.5868 - dense_711_accuracy: 0.5394 - dense_712_accuracy: 0.8947 - dense_713_accuracy: 0.8947 - dense_714_accuracy: 0.9236 - dense_715_accuracy: 0.7604 - dense_716_accuracy: 0.8079 - dense_717_accuracy: 0.9525 - dense_718_accuracy: 0.5972 - dense_719_accuracy: 0.8762 - loss: 10.2910\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 8, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - dense_704_accuracy: 0.5394 - dense_705_accuracy: 0.7789 - dense_706_accuracy: 0.9525 - dense_707_accuracy: 0.6551 - dense_708_accuracy: 0.8079 - dense_709_accuracy: 0.8264 - dense_710_accuracy: 0.5081 - dense_711_accuracy: 0.5764 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.8947 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7500 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5972 - dense_719_accuracy: 0.8553 - loss: 10.3618 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 9, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - dense_704_accuracy: 0.4919 - dense_705_accuracy: 0.7789 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.5868 - dense_708_accuracy: 0.8079 - dense_709_accuracy: 0.8264 - dense_710_accuracy: 0.5185 - dense_711_accuracy: 0.6817 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7396 - dense_716_accuracy: 0.7685 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5764 - dense_719_accuracy: 0.8553 - loss: 10.0608 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 10, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - dense_704_accuracy: 0.3843 - dense_705_accuracy: 0.7500 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.6157 - dense_708_accuracy: 0.8079 - dense_709_accuracy: 0.8264 - dense_710_accuracy: 0.5475 - dense_711_accuracy: 0.6343 - dense_712_accuracy: 0.9051 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7685 - dense_716_accuracy: 0.7685 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5949 - dense_719_accuracy: 0.8553 - loss: 10.2574\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 11, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - dense_704_accuracy: 0.3657 - dense_705_accuracy: 0.7894 - dense_706_accuracy: 0.9525 - dense_707_accuracy: 0.7211 - dense_708_accuracy: 0.7975 - dense_709_accuracy: 0.8368 - dense_710_accuracy: 0.5370 - dense_711_accuracy: 0.6053 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.8947 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7789 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5764 - dense_719_accuracy: 0.8553 - loss: 9.9301\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 12, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - dense_704_accuracy: 0.4236 - dense_705_accuracy: 0.7789 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.5660 - dense_708_accuracy: 0.7975 - dense_709_accuracy: 0.8264 - dense_710_accuracy: 0.5475 - dense_711_accuracy: 0.6157 - dense_712_accuracy: 0.8947 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7894 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5764 - dense_719_accuracy: 0.8657 - loss: 9.5574\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 13, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - dense_704_accuracy: 0.4815 - dense_705_accuracy: 0.7685 - dense_706_accuracy: 0.9421 - dense_707_accuracy: 0.5185 - dense_708_accuracy: 0.8183 - dense_709_accuracy: 0.8368 - dense_710_accuracy: 0.5787 - dense_711_accuracy: 0.6551 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.8843 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7789 - dense_716_accuracy: 0.7789 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5972 - dense_719_accuracy: 0.8657 - loss: 9.6167\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 14, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - dense_704_accuracy: 0.5868 - dense_705_accuracy: 0.8553 - dense_706_accuracy: 0.9525 - dense_707_accuracy: 0.5764 - dense_708_accuracy: 0.7975 - dense_709_accuracy: 0.8472 - dense_710_accuracy: 0.5579 - dense_711_accuracy: 0.6343 - dense_712_accuracy: 0.8843 - dense_713_accuracy: 0.9051 - dense_714_accuracy: 0.9132 - dense_715_accuracy: 0.7685 - dense_716_accuracy: 0.7789 - dense_717_accuracy: 0.9421 - dense_718_accuracy: 0.5868 - dense_719_accuracy: 0.8553 - loss: 9.4754\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 15, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772ms/step\n","Test Loss iteration 3: 39.626508036041166\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - dense_724_accuracy: 0.3472 - dense_725_accuracy: 0.1424 - dense_726_accuracy: 0.5370 - dense_727_accuracy: 0.1528 - dense_728_accuracy: 0.1736 - dense_729_accuracy: 0.3449 - dense_730_accuracy: 0.2685 - dense_731_accuracy: 0.0949 - dense_732_accuracy: 0.1898 - dense_733_accuracy: 0.1713 - dense_734_accuracy: 0.0579 - dense_735_accuracy: 0.1424 - dense_736_accuracy: 0.1319 - dense_737_accuracy: 0.0845 - dense_738_accuracy: 0.1817 - dense_739_accuracy: 0.0764 - loss: 23.2660\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - dense_724_accuracy: 0.5370 - dense_725_accuracy: 0.7396 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6343 - dense_728_accuracy: 0.7789 - dense_729_accuracy: 0.7975 - dense_730_accuracy: 0.5370 - dense_731_accuracy: 0.5949 - dense_732_accuracy: 0.8947 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.1238 - dense_735_accuracy: 0.7685 - dense_736_accuracy: 0.7685 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5081 - dense_739_accuracy: 0.7396 - loss: 15.8520\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - dense_724_accuracy: 0.5104 - dense_725_accuracy: 0.7685 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6343 - dense_728_accuracy: 0.7975 - dense_729_accuracy: 0.8264 - dense_730_accuracy: 0.5579 - dense_731_accuracy: 0.6343 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8947 - dense_734_accuracy: 0.5660 - dense_735_accuracy: 0.7894 - dense_736_accuracy: 0.7894 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5764 - dense_739_accuracy: 0.8657 - loss: 12.8188\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - dense_724_accuracy: 0.5185 - dense_725_accuracy: 0.7789 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6053 - dense_728_accuracy: 0.8183 - dense_729_accuracy: 0.8368 - dense_730_accuracy: 0.5475 - dense_731_accuracy: 0.6447 - dense_732_accuracy: 0.9051 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9236 - dense_735_accuracy: 0.7894 - dense_736_accuracy: 0.7894 - dense_737_accuracy: 0.9525 - dense_738_accuracy: 0.5868 - dense_739_accuracy: 0.8657 - loss: 11.5130\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - dense_724_accuracy: 0.4421 - dense_725_accuracy: 0.7685 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6053 - dense_728_accuracy: 0.8079 - dense_729_accuracy: 0.8264 - dense_730_accuracy: 0.5475 - dense_731_accuracy: 0.6343 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.7894 - dense_736_accuracy: 0.7685 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5660 - dense_739_accuracy: 0.8553 - loss: 11.5143\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - dense_724_accuracy: 0.5289 - dense_725_accuracy: 0.7685 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6053 - dense_728_accuracy: 0.8079 - dense_729_accuracy: 0.8368 - dense_730_accuracy: 0.5787 - dense_731_accuracy: 0.6157 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.7685 - dense_736_accuracy: 0.7685 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5868 - dense_739_accuracy: 0.8657 - loss: 10.4565\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - dense_724_accuracy: 0.5579 - dense_725_accuracy: 0.7789 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.5972 - dense_728_accuracy: 0.8079 - dense_729_accuracy: 0.8264 - dense_730_accuracy: 0.4606 - dense_731_accuracy: 0.5764 - dense_732_accuracy: 0.8947 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.6736 - dense_736_accuracy: 0.7789 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5764 - dense_739_accuracy: 0.8553 - loss: 10.2476\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - dense_724_accuracy: 0.5104 - dense_725_accuracy: 0.7685 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.5949 - dense_728_accuracy: 0.7975 - dense_729_accuracy: 0.8264 - dense_730_accuracy: 0.2789 - dense_731_accuracy: 0.6238 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.7685 - dense_736_accuracy: 0.7789 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5579 - dense_739_accuracy: 0.8762 - loss: 10.1725\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 7, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - dense_724_accuracy: 0.5394 - dense_725_accuracy: 0.7789 - dense_726_accuracy: 0.9525 - dense_727_accuracy: 0.6157 - dense_728_accuracy: 0.8079 - dense_729_accuracy: 0.8368 - dense_730_accuracy: 0.2685 - dense_731_accuracy: 0.6551 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8947 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.7789 - dense_736_accuracy: 0.7998 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5394 - dense_739_accuracy: 0.8553 - loss: 9.9451\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 8, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - dense_724_accuracy: 0.4525 - dense_725_accuracy: 0.7685 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6343 - dense_728_accuracy: 0.8079 - dense_729_accuracy: 0.8264 - dense_730_accuracy: 0.4421 - dense_731_accuracy: 0.6262 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.7789 - dense_736_accuracy: 0.7894 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.5683 - dense_739_accuracy: 0.8553 - loss: 9.8938\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 9, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - dense_724_accuracy: 0.5104 - dense_725_accuracy: 0.7894 - dense_726_accuracy: 0.9525 - dense_727_accuracy: 0.6840 - dense_728_accuracy: 0.8079 - dense_729_accuracy: 0.8472 - dense_730_accuracy: 0.5579 - dense_731_accuracy: 0.6840 - dense_732_accuracy: 0.8947 - dense_733_accuracy: 0.9051 - dense_734_accuracy: 0.9236 - dense_735_accuracy: 0.7894 - dense_736_accuracy: 0.7789 - dense_737_accuracy: 0.9525 - dense_738_accuracy: 0.4711 - dense_739_accuracy: 0.8553 - loss: 9.2121\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 10, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_724_accuracy: 0.5000 - dense_725_accuracy: 0.8264 - dense_726_accuracy: 0.9421 - dense_727_accuracy: 0.6053 - dense_728_accuracy: 0.7975 - dense_729_accuracy: 0.8472 - dense_730_accuracy: 0.5683 - dense_731_accuracy: 0.6551 - dense_732_accuracy: 0.8843 - dense_733_accuracy: 0.8843 - dense_734_accuracy: 0.9132 - dense_735_accuracy: 0.7685 - dense_736_accuracy: 0.8368 - dense_737_accuracy: 0.9421 - dense_738_accuracy: 0.3762 - dense_739_accuracy: 0.8553 - loss: 9.6643\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 11, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699ms/step\n","Test Loss iteration 4: 32.82763099161649\n","60 ['bumps']\n","average_loss: 34.685348815904014\n"]}],"source":["import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, LSTM\n","from keras.optimizers import Adam\n","import numpy as np\n","import sklearn\n","\n","total_losses = []\n","\n","# Transformer Encoder\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","# Transformer Decoder\n","def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Self attention\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Cross attention\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, enc_outputs)\n","    x = Dropout(dropout)(x)\n","    res = x + res\n","\n","    # Feed forward\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","# Soft Parameter Sharing Regularizer\n","def soft_parameter_sharing_regularizer(model, alpha=0.01):\n","    lstm_layers = [layer for layer in model.layers if isinstance(layer, LSTM)]\n","    if not lstm_layers:\n","        return 0.0\n","\n","    weights = [tf.convert_to_tensor(layer.weights[0]) for layer in lstm_layers]\n","\n","    shared_weights = tf.reduce_mean(tf.stack(weights), axis=0)\n","    return alpha * tf.reduce_sum([tf.reduce_sum(tf.square(w - shared_weights)) for w in weights])\n","\n","# Custom Loss Function\n","def custom_loss(y_true, y_pred, model):\n","    cce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n","    reg_loss = soft_parameter_sharing_regularizer(model)\n","    return cce + reg_loss\n","\n","# Model Definition\n","def get_soft_shared_model(input_shape1, input_shape2, output_shape):\n","    # Encoder input\n","    enc_inputs = Input(shape=(input_shape1, input_shape2))\n","\n","    # Encoder\n","    enc_outputs = transformer_encoder(enc_inputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Decoder input\n","    dec_inputs = Input(shape=(output_shape[1], input_shape2))\n","\n","    # Decoder\n","    dec_outputs = transformer_decoder(dec_inputs, enc_outputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Global pooling\n","    x = GlobalAveragePooling1D()(dec_outputs)\n","\n","    # Task-specific layers\n","    task_outputs = []\n","    task_layers = []\n","    for i in range(output_shape[1]):\n","        task_layer = Dense(256, activation='relu', name=f'task_layer_{i}')\n","        task_layers.append(task_layer)\n","        task_x = task_layer(x)\n","        task_x = Dropout(0.2)(task_x)\n","        output = Dense(4, activation='softmax')(task_x)\n","        task_outputs.append(output)\n","\n","    model = Model([enc_inputs, dec_inputs], task_outputs)\n","\n","    return model\n","\n","# Training and Evaluation Loop\n","for iteration in range(5):\n","    # Reshape inputs\n","    train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","    test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","    val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","    # Create decoder inputs\n","    train_dec_input = np.zeros((train_input_reshaped.shape[0], output_train.shape[1], train_input_reshaped.shape[2]))\n","    val_dec_input = np.zeros((val_input_reshaped.shape[0], output_train.shape[1], val_input_reshaped.shape[2]))\n","    test_dec_input = np.zeros((test_input_reshaped.shape[0], output_test.shape[1], test_input_reshaped.shape[2]))\n","\n","    # Create the soft parameter sharing model\n","    model = get_soft_shared_model(input_train.shape[1], input_train.shape[2], output_train.shape)\n","\n","    # Compile the model with the custom loss function\n","    model.compile(optimizer=Adam(learning_rate=0.001),\n","                  loss=lambda y_true, y_pred: custom_loss(y_true, y_pred, model),\n","                  metrics=[['accuracy'] for _ in range(output_train.shape[1])])\n","\n","    best_val = 1000000\n","    patience = 0\n","    best_model = None\n","\n","    for k in range(200):\n","            model.fit([train_input_reshaped, train_dec_input],\n","                [output_train[:, i] for i in range(output_train.shape[1])],\n","                epochs=1, batch_size=32, verbose=1)\n","            pred_val = np.array(model.predict([val_input_reshaped, val_dec_input]))\n","            pred_val = np.transpose(pred_val.squeeze(), (1, 0, 2))\n","            pred_val = np.argmax(pred_val, axis=-1).reshape(pred_val.shape[:-1])\n","\n","            print(f\"k: {k}, patience: {patience}\")\n","\n","            # Evaluate the model based on SSQ for validation data\n","            losses = []\n","            for i in range(pred_val.shape[0]):\n","                total_ssq = 0\n","                for j in [0, 5, 6, 7, 8, 14, 15]:\n","                    total_ssq += np.sum(pred_val[i, j])\n","\n","                for j in [0, 1, 2, 3, 4, 8, 10]:\n","                    total_ssq += np.sum(pred_val[i, j])\n","\n","                for j in [4, 7, 9, 10, 11, 12, 13]:\n","                    total_ssq += np.sum(pred_val[i, j])\n","\n","                total_ssq *= 3.74\n","                output_val_ssq = output_val_total_ssq[i, 0]\n","                loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","                losses.append(loss)\n","\n","            tmp_val_loss = np.mean(losses)\n","            if tmp_val_loss <= best_val:\n","                best_val = tmp_val_loss\n","                patience = 0\n","                best_model = model\n","            else:\n","                patience += 1\n","                if patience > 10:\n","                    break\n","\n","    # Predict and evaluate test data using the best model\n","\n","    pred_test = np.array(best_model.predict([test_input_reshaped, test_dec_input]))\n","    pred_test = np.transpose(pred_test.squeeze(), (1, 0, 2))\n","    pred_test = np.argmax(pred_test, axis=-1).reshape(pred_test.shape[:-1])\n","\n","    pred_total_ssq = []\n","    for i in range(pred_test.shape[0]):\n","        total_ssq = 0\n","        for j in [0, 5, 6, 7, 8, 14, 15]:\n","            total_ssq += np.sum(pred_test[i, j])\n","\n","        for j in [0, 1, 2, 3, 4, 8, 10]:\n","            total_ssq += np.sum(pred_test[i, j])\n","\n","        for j in [4, 7, 9, 10, 11, 12, 13]:\n","            total_ssq += np.sum(pred_test[i, j])\n","\n","        total_ssq *= 3.74\n","        pred_total_ssq.append(total_ssq)\n","\n","    # Overall Test Loss\n","    loss = sklearn.metrics.mean_squared_error(pred_total_ssq, output_test_total_ssq, squared=False)\n","    print(f\"Test Loss iteration {iteration}: {loss}\")\n","    total_losses.append(loss)\n","\n","# Calculate and print the average loss\n","average_loss = sum(total_losses) / len(total_losses)\n","\n","print(sample_size, simulations_test)\n","print(\"average_loss:\", average_loss)\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcZKdui21d+xu/hG/ak8Jd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}