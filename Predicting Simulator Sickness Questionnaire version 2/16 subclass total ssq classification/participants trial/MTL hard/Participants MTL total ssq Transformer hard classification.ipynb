{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":249,"status":"ok","timestamp":1726040431709,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fT_A9oAGAepC"},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":815,"status":"ok","timestamp":1726040432708,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"TishlaEBAmlN","outputId":"628b4ca0-8b69-460c-ab6e-312f42a299f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726040432708,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"XeSwJ8oKAt2r"},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726040432708,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"BFHyHoFvA5bX"},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1726040432708,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"QeoIWcudA94b"},"outputs":[],"source":["def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","        arrays_3d.append(array_3d)\n","\n","    return arrays_3d\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726040432708,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fqaeUGUDBCtT"},"outputs":[],"source":["sample_size=30\n","simulations = ['flat','noise','bumps']\n","participants = [str(i) for i in range(1, 27)]  # Participants 101 to 127\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726040432709,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"vPQyeAYKBYaO"},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[0, n_columns].sum()\n","    o_val = df.iloc[0, o_columns].sum()\n","    d_val = df.iloc[0, d_columns].sum()\n","\n","    return n_val, o_val, d_val"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726040432709,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"Xpn0lDt0BfvE"},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          # n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          # total_ssq_values.append([n_val, o_val, d_val])\n","          ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"7k17K0HrCr6-","executionInfo":{"status":"ok","timestamp":1726040435826,"user_tz":300,"elapsed":3122,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["participants_group_1 = [1,3,4,11,25]\n","participants_group_2 = [2,7,8,9,17]\n","participants_group_3 = [10,12,13,22,23]\n","participants_group_4 = [5,14,18,20,21]\n","participants_group_5 = [6,15,16,19,24,26]\n","\n","arrays_group_1 = construct_3d_array(base_path, participants_group_1, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_2 = construct_3d_array(base_path, participants_group_2, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_3 = construct_3d_array(base_path, participants_group_3, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_4 = construct_3d_array(base_path, participants_group_4, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_5 = construct_3d_array(base_path, participants_group_5, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","source":["# Concatenate arrays along the first axis\n","input_group_1 = np.concatenate(arrays_group_1, axis=0)\n","input_group_2 = np.concatenate(arrays_group_2, axis=0)\n","input_group_3 = np.concatenate(arrays_group_3, axis=0)\n","input_group_4 = np.concatenate(arrays_group_4, axis=0)\n","input_group_5 = np.concatenate(arrays_group_5, axis=0)\n"],"metadata":{"id":"bt-7nB84mtwe","executionInfo":{"status":"ok","timestamp":1726040435826,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["output_group_1=merge_ssq_column(simulations,participants_group_1)\n","output_group_2=merge_ssq_column(simulations,participants_group_2)\n","output_group_3=merge_ssq_column(simulations,participants_group_3)\n","output_group_4=merge_ssq_column(simulations,participants_group_4)\n","output_group_5=merge_ssq_column(simulations,participants_group_5)\n","\n","output_group_1 = np.squeeze(output_group_1)\n","output_group_2 = np.squeeze(output_group_2)\n","output_group_3 = np.squeeze(output_group_3)\n","output_group_4 = np.squeeze(output_group_4)\n","output_group_5 = np.squeeze(output_group_5)\n","\n","\n","output_total_ssq_group_1=merge_total_ssq(simulations,participants_group_1)\n","output_total_ssq_group_2=merge_total_ssq(simulations,participants_group_2)\n","output_total_ssq_group_3=merge_total_ssq(simulations,participants_group_3)\n","output_total_ssq_group_4=merge_total_ssq(simulations,participants_group_4)\n","output_total_ssq_group_5=merge_total_ssq(simulations,participants_group_5)\n","\n","output_total_ssq_group_1=output_total_ssq_group_1.reshape(-1, 1)\n","output_total_ssq_group_2=output_total_ssq_group_2.reshape(-1, 1)\n","output_total_ssq_group_3=output_total_ssq_group_3.reshape(-1, 1)\n","output_total_ssq_group_4=output_total_ssq_group_4.reshape(-1, 1)\n","output_total_ssq_group_5=output_total_ssq_group_5.reshape(-1, 1)\n","\n"],"metadata":{"id":"2xrL7s_Vm5iI","executionInfo":{"status":"ok","timestamp":1726040438177,"user_tz":300,"elapsed":2355,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1726040438178,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":217684,"status":"ok","timestamp":1726040655857,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"E6ssyYUeDJwI","outputId":"c4d6d77d-bb88-4640-8f8b-d3c3bcaf0267"},"outputs":[{"output_type":"stream","name":"stdout","text":["global_indices [[], [], [], [], []]\n","Iteration 1\n","global_indices [[], [], [], [], []]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (13, 120, 47)\n","output_val : (13, 16, 4)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - dense_110_accuracy: 0.1926 - dense_111_accuracy: 0.1672 - dense_112_accuracy: 0.4281 - dense_113_accuracy: 0.2043 - dense_114_accuracy: 0.0429 - dense_115_accuracy: 0.7378 - dense_116_accuracy: 0.3422 - dense_117_accuracy: 0.0963 - dense_118_accuracy: 0.3318 - dense_119_accuracy: 0.3968 - dense_120_accuracy: 0.1834 - dense_121_accuracy: 0.1496 - dense_122_accuracy: 0.1659 - dense_123_accuracy: 0.1939 - dense_124_accuracy: 0.5290 - dense_125_accuracy: 0.1184 - loss: 22.2288\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - dense_110_accuracy: 0.2785 - dense_111_accuracy: 0.7274 - dense_112_accuracy: 0.6265 - dense_113_accuracy: 0.6415 - dense_114_accuracy: 0.1555 - dense_115_accuracy: 0.7807 - dense_116_accuracy: 0.4385 - dense_117_accuracy: 0.2947 - dense_118_accuracy: 0.5986 - dense_119_accuracy: 0.8399 - dense_120_accuracy: 0.8504 - dense_121_accuracy: 0.4606 - dense_122_accuracy: 0.4548 - dense_123_accuracy: 0.7378 - dense_124_accuracy: 0.5290 - dense_125_accuracy: 0.8504 - loss: 18.4469\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - dense_110_accuracy: 0.4327 - dense_111_accuracy: 0.7541 - dense_112_accuracy: 0.8666 - dense_113_accuracy: 0.6148 - dense_114_accuracy: 0.5348 - dense_115_accuracy: 0.7807 - dense_116_accuracy: 0.5348 - dense_117_accuracy: 0.6845 - dense_118_accuracy: 0.7970 - dense_119_accuracy: 0.8608 - dense_120_accuracy: 0.7703 - dense_121_accuracy: 0.6949 - dense_122_accuracy: 0.6474 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5452 - dense_125_accuracy: 0.8399 - loss: 15.5953\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - dense_110_accuracy: 0.4223 - dense_111_accuracy: 0.7912 - dense_112_accuracy: 0.9675 - dense_113_accuracy: 0.6578 - dense_114_accuracy: 0.6786 - dense_115_accuracy: 0.7912 - dense_116_accuracy: 0.5882 - dense_117_accuracy: 0.6682 - dense_118_accuracy: 0.8016 - dense_119_accuracy: 0.8608 - dense_120_accuracy: 0.8874 - dense_121_accuracy: 0.7053 - dense_122_accuracy: 0.7053 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5556 - dense_125_accuracy: 0.8608 - loss: 13.4387\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - dense_110_accuracy: 0.3481 - dense_111_accuracy: 0.7807 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.6578 - dense_114_accuracy: 0.6682 - dense_115_accuracy: 0.7912 - dense_116_accuracy: 0.6311 - dense_117_accuracy: 0.6474 - dense_118_accuracy: 0.7807 - dense_119_accuracy: 0.8504 - dense_120_accuracy: 0.9037 - dense_121_accuracy: 0.7170 - dense_122_accuracy: 0.7007 - dense_123_accuracy: 0.8237 - dense_124_accuracy: 0.5244 - dense_125_accuracy: 0.8504 - loss: 13.6269\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n","k: 4 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - dense_110_accuracy: 0.5081 - dense_111_accuracy: 0.8074 - dense_112_accuracy: 0.9466 - dense_113_accuracy: 0.5615 - dense_114_accuracy: 0.7007 - dense_115_accuracy: 0.7807 - dense_116_accuracy: 0.6253 - dense_117_accuracy: 0.6415 - dense_118_accuracy: 0.7703 - dense_119_accuracy: 0.8133 - dense_120_accuracy: 0.8933 - dense_121_accuracy: 0.7274 - dense_122_accuracy: 0.6903 - dense_123_accuracy: 0.8237 - dense_124_accuracy: 0.6311 - dense_125_accuracy: 0.8504 - loss: 12.7990\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","k: 5 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - dense_110_accuracy: 0.5081 - dense_111_accuracy: 0.8074 - dense_112_accuracy: 0.9675 - dense_113_accuracy: 0.6148 - dense_114_accuracy: 0.6949 - dense_115_accuracy: 0.7378 - dense_116_accuracy: 0.5777 - dense_117_accuracy: 0.6578 - dense_118_accuracy: 0.7807 - dense_119_accuracy: 0.8445 - dense_120_accuracy: 0.9037 - dense_121_accuracy: 0.7378 - dense_122_accuracy: 0.7215 - dense_123_accuracy: 0.8237 - dense_124_accuracy: 0.4385 - dense_125_accuracy: 0.8608 - loss: 12.2385\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","k: 6 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - dense_110_accuracy: 0.5348 - dense_111_accuracy: 0.7970 - dense_112_accuracy: 0.9466 - dense_113_accuracy: 0.7007 - dense_114_accuracy: 0.7111 - dense_115_accuracy: 0.7703 - dense_116_accuracy: 0.6786 - dense_117_accuracy: 0.6311 - dense_118_accuracy: 0.8074 - dense_119_accuracy: 0.8504 - dense_120_accuracy: 0.8933 - dense_121_accuracy: 0.7274 - dense_122_accuracy: 0.7007 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.4606 - dense_125_accuracy: 0.8504 - loss: 12.3277\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 7 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - dense_110_accuracy: 0.5290 - dense_111_accuracy: 0.8074 - dense_112_accuracy: 0.9466 - dense_113_accuracy: 0.6578 - dense_114_accuracy: 0.7111 - dense_115_accuracy: 0.7807 - dense_116_accuracy: 0.6044 - dense_117_accuracy: 0.6415 - dense_118_accuracy: 0.7912 - dense_119_accuracy: 0.8399 - dense_120_accuracy: 0.9037 - dense_121_accuracy: 0.7274 - dense_122_accuracy: 0.6845 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5244 - dense_125_accuracy: 0.8504 - loss: 11.9413\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","k: 8 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_110_accuracy: 0.5719 - dense_111_accuracy: 0.8074 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.6090 - dense_114_accuracy: 0.6845 - dense_115_accuracy: 0.8016 - dense_116_accuracy: 0.6148 - dense_117_accuracy: 0.6519 - dense_118_accuracy: 0.7807 - dense_119_accuracy: 0.8608 - dense_120_accuracy: 0.9037 - dense_121_accuracy: 0.7007 - dense_122_accuracy: 0.7111 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5556 - dense_125_accuracy: 0.8504 - loss: 11.3142\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 9 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - dense_110_accuracy: 0.5823 - dense_111_accuracy: 0.8074 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.7645 - dense_114_accuracy: 0.7645 - dense_115_accuracy: 0.7703 - dense_116_accuracy: 0.6044 - dense_117_accuracy: 0.6578 - dense_118_accuracy: 0.7970 - dense_119_accuracy: 0.8712 - dense_120_accuracy: 0.9200 - dense_121_accuracy: 0.7541 - dense_122_accuracy: 0.6845 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5556 - dense_125_accuracy: 0.8504 - loss: 10.9506\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 10 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - dense_110_accuracy: 0.5719 - dense_111_accuracy: 0.7970 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.7170 - dense_114_accuracy: 0.7703 - dense_115_accuracy: 0.8016 - dense_116_accuracy: 0.6357 - dense_117_accuracy: 0.6949 - dense_118_accuracy: 0.8399 - dense_119_accuracy: 0.8504 - dense_120_accuracy: 0.9304 - dense_121_accuracy: 0.7436 - dense_122_accuracy: 0.7111 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5348 - dense_125_accuracy: 0.8399 - loss: 10.1461\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 11 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - dense_110_accuracy: 0.5615 - dense_111_accuracy: 0.8237 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.6682 - dense_114_accuracy: 0.7645 - dense_115_accuracy: 0.7703 - dense_116_accuracy: 0.5940 - dense_117_accuracy: 0.5940 - dense_118_accuracy: 0.8608 - dense_119_accuracy: 0.8608 - dense_120_accuracy: 0.9304 - dense_121_accuracy: 0.7541 - dense_122_accuracy: 0.6740 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5407 - dense_125_accuracy: 0.8770 - loss: 10.5321\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 12 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_110_accuracy: 0.4919 - dense_111_accuracy: 0.8178 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.7215 - dense_114_accuracy: 0.7691 - dense_115_accuracy: 0.8549 - dense_116_accuracy: 0.6090 - dense_117_accuracy: 0.7157 - dense_118_accuracy: 0.8445 - dense_119_accuracy: 0.8608 - dense_120_accuracy: 0.9408 - dense_121_accuracy: 0.8016 - dense_122_accuracy: 0.7645 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.5394 - dense_125_accuracy: 0.8770 - loss: 10.0140\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 13 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - dense_110_accuracy: 0.5569 - dense_111_accuracy: 0.8399 - dense_112_accuracy: 0.9200 - dense_113_accuracy: 0.7007 - dense_114_accuracy: 0.7970 - dense_115_accuracy: 0.8133 - dense_116_accuracy: 0.6148 - dense_117_accuracy: 0.6532 - dense_118_accuracy: 0.7970 - dense_119_accuracy: 0.8399 - dense_120_accuracy: 0.8933 - dense_121_accuracy: 0.7703 - dense_122_accuracy: 0.7599 - dense_123_accuracy: 0.8133 - dense_124_accuracy: 0.3747 - dense_125_accuracy: 0.8770 - loss: 10.4188\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 14 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - dense_110_accuracy: 0.5882 - dense_111_accuracy: 0.8504 - dense_112_accuracy: 0.9733 - dense_113_accuracy: 0.6148 - dense_114_accuracy: 0.7274 - dense_115_accuracy: 0.8608 - dense_116_accuracy: 0.6090 - dense_117_accuracy: 0.6682 - dense_118_accuracy: 0.8237 - dense_119_accuracy: 0.8178 - dense_120_accuracy: 0.9304 - dense_121_accuracy: 0.7645 - dense_122_accuracy: 0.7853 - dense_123_accuracy: 0.8341 - dense_124_accuracy: 0.3956 - dense_125_accuracy: 0.8874 - loss: 9.9760\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 15 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - dense_110_accuracy: 0.5719 - dense_111_accuracy: 0.8178 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.7807 - dense_114_accuracy: 0.7749 - dense_115_accuracy: 0.8341 - dense_116_accuracy: 0.6044 - dense_117_accuracy: 0.6578 - dense_118_accuracy: 0.8445 - dense_119_accuracy: 0.8445 - dense_120_accuracy: 0.9571 - dense_121_accuracy: 0.7645 - dense_122_accuracy: 0.7912 - dense_123_accuracy: 0.8712 - dense_124_accuracy: 0.5452 - dense_125_accuracy: 0.8933 - loss: 9.3125\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 16 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - dense_110_accuracy: 0.6253 - dense_111_accuracy: 0.8445 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.6845 - dense_114_accuracy: 0.7482 - dense_115_accuracy: 0.8237 - dense_116_accuracy: 0.6578 - dense_117_accuracy: 0.7053 - dense_118_accuracy: 0.8608 - dense_119_accuracy: 0.8341 - dense_120_accuracy: 0.9571 - dense_121_accuracy: 0.8016 - dense_122_accuracy: 0.7215 - dense_123_accuracy: 0.8874 - dense_124_accuracy: 0.5986 - dense_125_accuracy: 0.8770 - loss: 9.1445\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 17 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - dense_110_accuracy: 0.6740 - dense_111_accuracy: 0.8608 - dense_112_accuracy: 0.9675 - dense_113_accuracy: 0.7007 - dense_114_accuracy: 0.6799 - dense_115_accuracy: 0.8504 - dense_116_accuracy: 0.5940 - dense_117_accuracy: 0.6682 - dense_118_accuracy: 0.8133 - dense_119_accuracy: 0.8445 - dense_120_accuracy: 0.9304 - dense_121_accuracy: 0.7749 - dense_122_accuracy: 0.8074 - dense_123_accuracy: 0.8504 - dense_124_accuracy: 0.4873 - dense_125_accuracy: 0.8504 - loss: 9.1679\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 18 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - dense_110_accuracy: 0.6532 - dense_111_accuracy: 0.8712 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.8341 - dense_114_accuracy: 0.7970 - dense_115_accuracy: 0.8237 - dense_116_accuracy: 0.6369 - dense_117_accuracy: 0.5836 - dense_118_accuracy: 0.8608 - dense_119_accuracy: 0.8504 - dense_120_accuracy: 0.9466 - dense_121_accuracy: 0.6903 - dense_122_accuracy: 0.7599 - dense_123_accuracy: 0.8979 - dense_124_accuracy: 0.4919 - dense_125_accuracy: 0.8979 - loss: 8.9317\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 19 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - dense_110_accuracy: 0.5986 - dense_111_accuracy: 0.8770 - dense_112_accuracy: 0.9571 - dense_113_accuracy: 0.7645 - dense_114_accuracy: 0.7703 - dense_115_accuracy: 0.8608 - dense_116_accuracy: 0.6578 - dense_117_accuracy: 0.7215 - dense_118_accuracy: 0.8399 - dense_119_accuracy: 0.8608 - dense_120_accuracy: 0.9304 - dense_121_accuracy: 0.7599 - dense_122_accuracy: 0.7007 - dense_123_accuracy: 0.8504 - dense_124_accuracy: 0.5882 - dense_125_accuracy: 0.9141 - loss: 8.7966\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 20 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n","Test Loss no  0 : 32.65049682404761\n","Iteration 2\n","global_indices [[7, 0, 10], [9, 3, 6], [4, 11, 2], [6, 5], [9, 0, 2]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (13, 120, 47)\n","output_val : (13, 16, 4)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - dense_131_accuracy: 0.2889 - dense_132_accuracy: 0.2355 - dense_133_accuracy: 0.1672 - dense_134_accuracy: 0.4977 - dense_135_accuracy: 0.3631 - dense_136_accuracy: 0.1822 - dense_137_accuracy: 0.3318 - dense_138_accuracy: 0.3526 - dense_139_accuracy: 0.0000e+00 - dense_140_accuracy: 0.0650 - dense_141_accuracy: 0.0917 - dense_142_accuracy: 0.6636 - dense_143_accuracy: 0.3585 - dense_144_accuracy: 0.7436 - dense_145_accuracy: 0.1347 - dense_146_accuracy: 0.7170 - loss: 22.0701\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - dense_131_accuracy: 0.3422 - dense_132_accuracy: 0.3793 - dense_133_accuracy: 0.8666 - dense_134_accuracy: 0.5348 - dense_135_accuracy: 0.5244 - dense_136_accuracy: 0.3585 - dense_137_accuracy: 0.5407 - dense_138_accuracy: 0.2622 - dense_139_accuracy: 0.0163 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.4756 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.4977 - dense_144_accuracy: 0.8237 - dense_145_accuracy: 0.2459 - dense_146_accuracy: 0.8237 - loss: 19.1002\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - dense_131_accuracy: 0.2785 - dense_132_accuracy: 0.5765 - dense_133_accuracy: 0.8608 - dense_134_accuracy: 0.5556 - dense_135_accuracy: 0.8120 - dense_136_accuracy: 0.6474 - dense_137_accuracy: 0.5882 - dense_138_accuracy: 0.3526 - dense_139_accuracy: 0.2193 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.6949 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.7215 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.2889 - dense_146_accuracy: 0.8608 - loss: 16.4667\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - dense_131_accuracy: 0.3585 - dense_132_accuracy: 0.6682 - dense_133_accuracy: 0.8770 - dense_134_accuracy: 0.5615 - dense_135_accuracy: 0.7807 - dense_136_accuracy: 0.7541 - dense_137_accuracy: 0.5673 - dense_138_accuracy: 0.5719 - dense_139_accuracy: 0.5940 - dense_140_accuracy: 0.8504 - dense_141_accuracy: 0.9037 - dense_142_accuracy: 0.8341 - dense_143_accuracy: 0.7111 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.3852 - dense_146_accuracy: 0.8504 - loss: 14.5868\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - dense_131_accuracy: 0.4118 - dense_132_accuracy: 0.6682 - dense_133_accuracy: 0.9037 - dense_134_accuracy: 0.4919 - dense_135_accuracy: 0.8016 - dense_136_accuracy: 0.7703 - dense_137_accuracy: 0.5882 - dense_138_accuracy: 0.5777 - dense_139_accuracy: 0.7274 - dense_140_accuracy: 0.8666 - dense_141_accuracy: 0.9037 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.6903 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.5185 - dense_146_accuracy: 0.8504 - loss: 13.3794\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - dense_131_accuracy: 0.4919 - dense_132_accuracy: 0.6519 - dense_133_accuracy: 0.9037 - dense_134_accuracy: 0.3526 - dense_135_accuracy: 0.7807 - dense_136_accuracy: 0.7645 - dense_137_accuracy: 0.5986 - dense_138_accuracy: 0.6044 - dense_139_accuracy: 0.7970 - dense_140_accuracy: 0.8874 - dense_141_accuracy: 0.8770 - dense_142_accuracy: 0.8074 - dense_143_accuracy: 0.7215 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.5615 - dense_146_accuracy: 0.8608 - loss: 12.7915\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - dense_131_accuracy: 0.4014 - dense_132_accuracy: 0.6148 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.3956 - dense_135_accuracy: 0.7912 - dense_136_accuracy: 0.7807 - dense_137_accuracy: 0.6253 - dense_138_accuracy: 0.5777 - dense_139_accuracy: 0.8178 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.8874 - dense_142_accuracy: 0.8341 - dense_143_accuracy: 0.7111 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.5615 - dense_146_accuracy: 0.8712 - loss: 12.8600\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 6 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - dense_131_accuracy: 0.3318 - dense_132_accuracy: 0.6311 - dense_133_accuracy: 0.9141 - dense_134_accuracy: 0.5081 - dense_135_accuracy: 0.7970 - dense_136_accuracy: 0.7807 - dense_137_accuracy: 0.5407 - dense_138_accuracy: 0.5940 - dense_139_accuracy: 0.8074 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.8933 - dense_142_accuracy: 0.7970 - dense_143_accuracy: 0.7599 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.5348 - dense_146_accuracy: 0.8399 - loss: 12.0308\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 7 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - dense_131_accuracy: 0.4281 - dense_132_accuracy: 0.6786 - dense_133_accuracy: 0.9037 - dense_134_accuracy: 0.5615 - dense_135_accuracy: 0.7807 - dense_136_accuracy: 0.7807 - dense_137_accuracy: 0.5615 - dense_138_accuracy: 0.5986 - dense_139_accuracy: 0.7970 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.8933 - dense_142_accuracy: 0.7970 - dense_143_accuracy: 0.6799 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.5290 - dense_146_accuracy: 0.8399 - loss: 11.7566\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 8 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - dense_131_accuracy: 0.3910 - dense_132_accuracy: 0.6740 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.6044 - dense_135_accuracy: 0.7703 - dense_136_accuracy: 0.7599 - dense_137_accuracy: 0.5777 - dense_138_accuracy: 0.5998 - dense_139_accuracy: 0.8074 - dense_140_accuracy: 0.8666 - dense_141_accuracy: 0.9037 - dense_142_accuracy: 0.8341 - dense_143_accuracy: 0.6799 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.5569 - dense_146_accuracy: 0.8399 - loss: 11.9652\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n","k: 9 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - dense_131_accuracy: 0.3422 - dense_132_accuracy: 0.6578 - dense_133_accuracy: 0.9037 - dense_134_accuracy: 0.6148 - dense_135_accuracy: 0.8074 - dense_136_accuracy: 0.7912 - dense_137_accuracy: 0.5719 - dense_138_accuracy: 0.6519 - dense_139_accuracy: 0.8074 - dense_140_accuracy: 0.8874 - dense_141_accuracy: 0.9037 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.7807 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.5452 - dense_146_accuracy: 0.8608 - loss: 10.9692\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n","k: 10 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - dense_131_accuracy: 0.4977 - dense_132_accuracy: 0.7007 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.5882 - dense_135_accuracy: 0.7807 - dense_136_accuracy: 0.8074 - dense_137_accuracy: 0.6207 - dense_138_accuracy: 0.6519 - dense_139_accuracy: 0.7866 - dense_140_accuracy: 0.8979 - dense_141_accuracy: 0.9200 - dense_142_accuracy: 0.8341 - dense_143_accuracy: 0.7482 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.6311 - dense_146_accuracy: 0.8504 - loss: 10.5842\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n","k: 11 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - dense_131_accuracy: 0.5777 - dense_132_accuracy: 0.7378 - dense_133_accuracy: 0.8874 - dense_134_accuracy: 0.6578 - dense_135_accuracy: 0.8074 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.5836 - dense_138_accuracy: 0.5777 - dense_139_accuracy: 0.8283 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9466 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.7111 - dense_144_accuracy: 0.8712 - dense_145_accuracy: 0.6207 - dense_146_accuracy: 0.8504 - loss: 10.7922\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n","k: 12 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - dense_131_accuracy: 0.5927 - dense_132_accuracy: 0.7749 - dense_133_accuracy: 0.8608 - dense_134_accuracy: 0.5777 - dense_135_accuracy: 0.8341 - dense_136_accuracy: 0.8283 - dense_137_accuracy: 0.5719 - dense_138_accuracy: 0.6090 - dense_139_accuracy: 0.8074 - dense_140_accuracy: 0.8874 - dense_141_accuracy: 0.9304 - dense_142_accuracy: 0.8445 - dense_143_accuracy: 0.8016 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.6148 - dense_146_accuracy: 0.8712 - loss: 9.8513\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n","k: 13 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - dense_131_accuracy: 0.4060 - dense_132_accuracy: 0.6903 - dense_133_accuracy: 0.8666 - dense_134_accuracy: 0.7053 - dense_135_accuracy: 0.7970 - dense_136_accuracy: 0.7970 - dense_137_accuracy: 0.5882 - dense_138_accuracy: 0.5777 - dense_139_accuracy: 0.8504 - dense_140_accuracy: 0.8608 - dense_141_accuracy: 0.9037 - dense_142_accuracy: 0.8445 - dense_143_accuracy: 0.7912 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.5673 - dense_146_accuracy: 0.8504 - loss: 10.0168\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 14 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - dense_131_accuracy: 0.5290 - dense_132_accuracy: 0.7274 - dense_133_accuracy: 0.9037 - dense_134_accuracy: 0.6845 - dense_135_accuracy: 0.7970 - dense_136_accuracy: 0.8712 - dense_137_accuracy: 0.5777 - dense_138_accuracy: 0.6253 - dense_139_accuracy: 0.7912 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9200 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.8074 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.6044 - dense_146_accuracy: 0.8608 - loss: 9.4571\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 15 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - dense_131_accuracy: 0.4606 - dense_132_accuracy: 0.7436 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.6474 - dense_135_accuracy: 0.8341 - dense_136_accuracy: 0.7970 - dense_137_accuracy: 0.6103 - dense_138_accuracy: 0.5836 - dense_139_accuracy: 0.8816 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9466 - dense_142_accuracy: 0.8237 - dense_143_accuracy: 0.7703 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.6845 - dense_146_accuracy: 0.8666 - loss: 9.8256\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 16 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - dense_131_accuracy: 0.5986 - dense_132_accuracy: 0.7111 - dense_133_accuracy: 0.8979 - dense_134_accuracy: 0.6949 - dense_135_accuracy: 0.7970 - dense_136_accuracy: 0.8387 - dense_137_accuracy: 0.5986 - dense_138_accuracy: 0.7320 - dense_139_accuracy: 0.8712 - dense_140_accuracy: 0.8874 - dense_141_accuracy: 0.9571 - dense_142_accuracy: 0.8341 - dense_143_accuracy: 0.7807 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.7111 - dense_146_accuracy: 0.8504 - loss: 8.8114\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 17 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - dense_131_accuracy: 0.5244 - dense_132_accuracy: 0.7274 - dense_133_accuracy: 0.8608 - dense_134_accuracy: 0.6682 - dense_135_accuracy: 0.8178 - dense_136_accuracy: 0.8074 - dense_137_accuracy: 0.6044 - dense_138_accuracy: 0.7007 - dense_139_accuracy: 0.8074 - dense_140_accuracy: 0.8874 - dense_141_accuracy: 0.9466 - dense_142_accuracy: 0.8770 - dense_143_accuracy: 0.8178 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.7215 - dense_146_accuracy: 0.9037 - loss: 9.0528\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 18 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - dense_131_accuracy: 0.5719 - dense_132_accuracy: 0.7482 - dense_133_accuracy: 0.9141 - dense_134_accuracy: 0.7541 - dense_135_accuracy: 0.8178 - dense_136_accuracy: 0.8283 - dense_137_accuracy: 0.6682 - dense_138_accuracy: 0.6845 - dense_139_accuracy: 0.8178 - dense_140_accuracy: 0.8445 - dense_141_accuracy: 0.9571 - dense_142_accuracy: 0.8770 - dense_143_accuracy: 0.8504 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.7157 - dense_146_accuracy: 0.9037 - loss: 8.4804\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 19 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_131_accuracy: 0.5986 - dense_132_accuracy: 0.7170 - dense_133_accuracy: 0.8770 - dense_134_accuracy: 0.7274 - dense_135_accuracy: 0.8237 - dense_136_accuracy: 0.8283 - dense_137_accuracy: 0.5940 - dense_138_accuracy: 0.7053 - dense_139_accuracy: 0.8504 - dense_140_accuracy: 0.8608 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.8504 - dense_143_accuracy: 0.8237 - dense_144_accuracy: 0.8399 - dense_145_accuracy: 0.6845 - dense_146_accuracy: 0.8933 - loss: 8.5092\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 20 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - dense_131_accuracy: 0.4860 - dense_132_accuracy: 0.8237 - dense_133_accuracy: 0.8770 - dense_134_accuracy: 0.6949 - dense_135_accuracy: 0.8341 - dense_136_accuracy: 0.8237 - dense_137_accuracy: 0.6311 - dense_138_accuracy: 0.6845 - dense_139_accuracy: 0.8237 - dense_140_accuracy: 0.9037 - dense_141_accuracy: 0.9571 - dense_142_accuracy: 0.8770 - dense_143_accuracy: 0.8178 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.6949 - dense_146_accuracy: 0.9037 - loss: 8.2390\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 21 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - dense_131_accuracy: 0.5452 - dense_132_accuracy: 0.7007 - dense_133_accuracy: 0.8770 - dense_134_accuracy: 0.7274 - dense_135_accuracy: 0.8608 - dense_136_accuracy: 0.8341 - dense_137_accuracy: 0.6474 - dense_138_accuracy: 0.6845 - dense_139_accuracy: 0.8341 - dense_140_accuracy: 0.8666 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.8504 - dense_143_accuracy: 0.8399 - dense_144_accuracy: 0.8712 - dense_145_accuracy: 0.6519 - dense_146_accuracy: 0.9037 - loss: 8.2548\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 22 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - dense_131_accuracy: 0.5615 - dense_132_accuracy: 0.7807 - dense_133_accuracy: 0.8504 - dense_134_accuracy: 0.7274 - dense_135_accuracy: 0.8074 - dense_136_accuracy: 0.8341 - dense_137_accuracy: 0.6578 - dense_138_accuracy: 0.7378 - dense_139_accuracy: 0.8933 - dense_140_accuracy: 0.8237 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.8712 - dense_143_accuracy: 0.8770 - dense_144_accuracy: 0.8608 - dense_145_accuracy: 0.6903 - dense_146_accuracy: 0.9037 - loss: 7.8957\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 23 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_131_accuracy: 0.6415 - dense_132_accuracy: 0.7807 - dense_133_accuracy: 0.9141 - dense_134_accuracy: 0.7170 - dense_135_accuracy: 0.8341 - dense_136_accuracy: 0.7912 - dense_137_accuracy: 0.6207 - dense_138_accuracy: 0.7645 - dense_139_accuracy: 0.8608 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9571 - dense_142_accuracy: 0.8666 - dense_143_accuracy: 0.8504 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.7645 - dense_146_accuracy: 0.8933 - loss: 7.6235\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 24 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_131_accuracy: 0.5940 - dense_132_accuracy: 0.7170 - dense_133_accuracy: 0.8874 - dense_134_accuracy: 0.7703 - dense_135_accuracy: 0.8712 - dense_136_accuracy: 0.8445 - dense_137_accuracy: 0.7007 - dense_138_accuracy: 0.6845 - dense_139_accuracy: 0.8504 - dense_140_accuracy: 0.8608 - dense_141_accuracy: 0.9837 - dense_142_accuracy: 0.8874 - dense_143_accuracy: 0.8874 - dense_144_accuracy: 0.8504 - dense_145_accuracy: 0.7645 - dense_146_accuracy: 0.9037 - loss: 7.5740\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 25 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - dense_131_accuracy: 0.6207 - dense_132_accuracy: 0.7703 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.6903 - dense_135_accuracy: 0.8133 - dense_136_accuracy: 0.8712 - dense_137_accuracy: 0.6845 - dense_138_accuracy: 0.7274 - dense_139_accuracy: 0.8504 - dense_140_accuracy: 0.8666 - dense_141_accuracy: 0.9837 - dense_142_accuracy: 0.8399 - dense_143_accuracy: 0.8399 - dense_144_accuracy: 0.8666 - dense_145_accuracy: 0.7378 - dense_146_accuracy: 0.8933 - loss: 7.4707\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 26 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - dense_131_accuracy: 0.5673 - dense_132_accuracy: 0.7066 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.7703 - dense_135_accuracy: 0.8237 - dense_136_accuracy: 0.8874 - dense_137_accuracy: 0.7170 - dense_138_accuracy: 0.7378 - dense_139_accuracy: 0.8608 - dense_140_accuracy: 0.8133 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.8666 - dense_143_accuracy: 0.8399 - dense_144_accuracy: 0.8874 - dense_145_accuracy: 0.6949 - dense_146_accuracy: 0.9037 - loss: 7.4507\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n","k: 27 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - dense_131_accuracy: 0.6090 - dense_132_accuracy: 0.8504 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.8074 - dense_135_accuracy: 0.8979 - dense_136_accuracy: 0.9245 - dense_137_accuracy: 0.7274 - dense_138_accuracy: 0.8178 - dense_139_accuracy: 0.8504 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.8666 - dense_143_accuracy: 0.8874 - dense_144_accuracy: 0.9304 - dense_145_accuracy: 0.8283 - dense_146_accuracy: 0.9037 - loss: 6.3418\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n","k: 28 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - dense_131_accuracy: 0.6415 - dense_132_accuracy: 0.7970 - dense_133_accuracy: 0.9304 - dense_134_accuracy: 0.7807 - dense_135_accuracy: 0.8504 - dense_136_accuracy: 0.8874 - dense_137_accuracy: 0.7541 - dense_138_accuracy: 0.7007 - dense_139_accuracy: 0.8712 - dense_140_accuracy: 0.9037 - dense_141_accuracy: 0.9304 - dense_142_accuracy: 0.8666 - dense_143_accuracy: 0.8399 - dense_144_accuracy: 0.8666 - dense_145_accuracy: 0.7170 - dense_146_accuracy: 0.8933 - loss: 6.7165\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 29 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - dense_131_accuracy: 0.5986 - dense_132_accuracy: 0.8237 - dense_133_accuracy: 0.9304 - dense_134_accuracy: 0.8341 - dense_135_accuracy: 0.8770 - dense_136_accuracy: 0.8399 - dense_137_accuracy: 0.7703 - dense_138_accuracy: 0.7482 - dense_139_accuracy: 0.8770 - dense_140_accuracy: 0.9200 - dense_141_accuracy: 0.9466 - dense_142_accuracy: 0.8874 - dense_143_accuracy: 0.8445 - dense_144_accuracy: 0.9037 - dense_145_accuracy: 0.6578 - dense_146_accuracy: 0.9037 - loss: 6.6238\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n","k: 30 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - dense_131_accuracy: 0.6682 - dense_132_accuracy: 0.7599 - dense_133_accuracy: 0.8666 - dense_134_accuracy: 0.7482 - dense_135_accuracy: 0.8504 - dense_136_accuracy: 0.8666 - dense_137_accuracy: 0.8178 - dense_138_accuracy: 0.7274 - dense_139_accuracy: 0.9037 - dense_140_accuracy: 0.9304 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9141 - dense_143_accuracy: 0.8712 - dense_144_accuracy: 0.9200 - dense_145_accuracy: 0.7274 - dense_146_accuracy: 0.9304 - loss: 6.1228\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 31 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - dense_131_accuracy: 0.6786 - dense_132_accuracy: 0.8504 - dense_133_accuracy: 0.9304 - dense_134_accuracy: 0.7703 - dense_135_accuracy: 0.8504 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.7703 - dense_138_accuracy: 0.7378 - dense_139_accuracy: 0.8237 - dense_140_accuracy: 0.9141 - dense_141_accuracy: 1.0000 - dense_142_accuracy: 0.8770 - dense_143_accuracy: 0.8341 - dense_144_accuracy: 0.9200 - dense_145_accuracy: 0.7645 - dense_146_accuracy: 0.9304 - loss: 6.3335\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 32 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - dense_131_accuracy: 0.7111 - dense_132_accuracy: 0.8237 - dense_133_accuracy: 0.8666 - dense_134_accuracy: 0.7378 - dense_135_accuracy: 0.8666 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.7912 - dense_138_accuracy: 0.7912 - dense_139_accuracy: 0.8770 - dense_140_accuracy: 0.8666 - dense_141_accuracy: 0.9837 - dense_142_accuracy: 0.8933 - dense_143_accuracy: 0.8341 - dense_144_accuracy: 0.9200 - dense_145_accuracy: 0.8074 - dense_146_accuracy: 0.9037 - loss: 6.0580\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 33 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - dense_131_accuracy: 0.6207 - dense_132_accuracy: 0.8770 - dense_133_accuracy: 0.9304 - dense_134_accuracy: 0.7866 - dense_135_accuracy: 0.8608 - dense_136_accuracy: 0.9141 - dense_137_accuracy: 0.7645 - dense_138_accuracy: 0.7436 - dense_139_accuracy: 0.9037 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9037 - dense_143_accuracy: 0.8608 - dense_144_accuracy: 0.9037 - dense_145_accuracy: 0.7378 - dense_146_accuracy: 0.9200 - loss: 5.8595\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 34 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - dense_131_accuracy: 0.7436 - dense_132_accuracy: 0.8074 - dense_133_accuracy: 0.9200 - dense_134_accuracy: 0.8399 - dense_135_accuracy: 0.8712 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.7749 - dense_138_accuracy: 0.8074 - dense_139_accuracy: 0.9037 - dense_140_accuracy: 0.8933 - dense_141_accuracy: 1.0000 - dense_142_accuracy: 0.8770 - dense_143_accuracy: 0.9466 - dense_144_accuracy: 0.9304 - dense_145_accuracy: 0.7703 - dense_146_accuracy: 0.9200 - loss: 5.5186\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 35 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_131_accuracy: 0.5940 - dense_132_accuracy: 0.7436 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.7970 - dense_135_accuracy: 0.8608 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.8608 - dense_138_accuracy: 0.6369 - dense_139_accuracy: 0.9304 - dense_140_accuracy: 0.8770 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9466 - dense_143_accuracy: 0.8504 - dense_144_accuracy: 0.8933 - dense_145_accuracy: 0.7970 - dense_146_accuracy: 0.9200 - loss: 5.8768\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 36 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - dense_131_accuracy: 0.6519 - dense_132_accuracy: 0.8399 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.8979 - dense_135_accuracy: 0.8666 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.7749 - dense_138_accuracy: 0.8445 - dense_139_accuracy: 0.9304 - dense_140_accuracy: 0.9200 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9200 - dense_143_accuracy: 0.8504 - dense_144_accuracy: 0.9200 - dense_145_accuracy: 0.8770 - dense_146_accuracy: 0.9675 - loss: 5.0426\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 37 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - dense_131_accuracy: 0.6740 - dense_132_accuracy: 0.8237 - dense_133_accuracy: 0.8933 - dense_134_accuracy: 0.7703 - dense_135_accuracy: 0.8933 - dense_136_accuracy: 0.9141 - dense_137_accuracy: 0.8770 - dense_138_accuracy: 0.8237 - dense_139_accuracy: 0.8770 - dense_140_accuracy: 0.9466 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.8933 - dense_143_accuracy: 0.8666 - dense_144_accuracy: 0.9466 - dense_145_accuracy: 0.8770 - dense_146_accuracy: 0.9200 - loss: 5.0723\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 38 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - dense_131_accuracy: 0.8712 - dense_132_accuracy: 0.7912 - dense_133_accuracy: 0.9675 - dense_134_accuracy: 0.9037 - dense_135_accuracy: 0.8504 - dense_136_accuracy: 0.8666 - dense_137_accuracy: 0.8178 - dense_138_accuracy: 0.8445 - dense_139_accuracy: 0.8874 - dense_140_accuracy: 0.9408 - dense_141_accuracy: 0.9571 - dense_142_accuracy: 0.9037 - dense_143_accuracy: 0.8770 - dense_144_accuracy: 0.9571 - dense_145_accuracy: 0.8237 - dense_146_accuracy: 0.9466 - loss: 4.5868\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 39 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - dense_131_accuracy: 0.7170 - dense_132_accuracy: 0.8074 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.8874 - dense_135_accuracy: 0.9304 - dense_136_accuracy: 0.8770 - dense_137_accuracy: 0.8016 - dense_138_accuracy: 0.8074 - dense_139_accuracy: 0.9304 - dense_140_accuracy: 0.9037 - dense_141_accuracy: 0.9466 - dense_142_accuracy: 0.8933 - dense_143_accuracy: 0.9141 - dense_144_accuracy: 0.9733 - dense_145_accuracy: 0.8770 - dense_146_accuracy: 0.9200 - loss: 5.1085\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 40 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - dense_131_accuracy: 0.7111 - dense_132_accuracy: 0.7436 - dense_133_accuracy: 0.9200 - dense_134_accuracy: 0.9037 - dense_135_accuracy: 0.9037 - dense_136_accuracy: 0.8933 - dense_137_accuracy: 0.8341 - dense_138_accuracy: 0.8504 - dense_139_accuracy: 0.8770 - dense_140_accuracy: 0.9571 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9037 - dense_143_accuracy: 0.8712 - dense_144_accuracy: 0.9200 - dense_145_accuracy: 0.7866 - dense_146_accuracy: 0.8666 - loss: 4.9510\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 41 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - dense_131_accuracy: 0.6682 - dense_132_accuracy: 0.9037 - dense_133_accuracy: 0.9733 - dense_134_accuracy: 0.8770 - dense_135_accuracy: 0.9037 - dense_136_accuracy: 0.8341 - dense_137_accuracy: 0.8074 - dense_138_accuracy: 0.7807 - dense_139_accuracy: 0.8237 - dense_140_accuracy: 0.9733 - dense_141_accuracy: 0.9837 - dense_142_accuracy: 0.9037 - dense_143_accuracy: 0.9571 - dense_144_accuracy: 0.9837 - dense_145_accuracy: 0.8816 - dense_146_accuracy: 0.9466 - loss: 4.5062\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 42 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - dense_131_accuracy: 0.7970 - dense_132_accuracy: 0.8933 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.9408 - dense_135_accuracy: 0.8770 - dense_136_accuracy: 0.9141 - dense_137_accuracy: 0.8341 - dense_138_accuracy: 0.8178 - dense_139_accuracy: 0.8933 - dense_140_accuracy: 0.9466 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9141 - dense_143_accuracy: 0.8816 - dense_144_accuracy: 0.9571 - dense_145_accuracy: 0.8933 - dense_146_accuracy: 0.9571 - loss: 4.1985\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 43 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 167ms/step - dense_131_accuracy: 0.8237 - dense_132_accuracy: 0.8933 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.8666 - dense_135_accuracy: 0.8874 - dense_136_accuracy: 0.9200 - dense_137_accuracy: 0.8341 - dense_138_accuracy: 0.9037 - dense_139_accuracy: 0.9037 - dense_140_accuracy: 0.9200 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9304 - dense_143_accuracy: 0.9141 - dense_144_accuracy: 0.9200 - dense_145_accuracy: 0.7970 - dense_146_accuracy: 0.9571 - loss: 4.1048\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n","k: 44 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - dense_131_accuracy: 0.6311 - dense_132_accuracy: 0.8504 - dense_133_accuracy: 0.9675 - dense_134_accuracy: 0.9037 - dense_135_accuracy: 0.8874 - dense_136_accuracy: 0.8608 - dense_137_accuracy: 0.8445 - dense_138_accuracy: 0.8874 - dense_139_accuracy: 0.9037 - dense_140_accuracy: 0.9733 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9733 - dense_143_accuracy: 0.8666 - dense_144_accuracy: 0.9304 - dense_145_accuracy: 0.7541 - dense_146_accuracy: 0.9466 - loss: 4.2248\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n","k: 45 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - dense_131_accuracy: 0.8933 - dense_132_accuracy: 0.9141 - dense_133_accuracy: 0.9571 - dense_134_accuracy: 0.9571 - dense_135_accuracy: 0.9037 - dense_136_accuracy: 0.9037 - dense_137_accuracy: 0.8133 - dense_138_accuracy: 0.9141 - dense_139_accuracy: 0.8608 - dense_140_accuracy: 0.9466 - dense_141_accuracy: 1.0000 - dense_142_accuracy: 0.8933 - dense_143_accuracy: 0.8504 - dense_144_accuracy: 0.9733 - dense_145_accuracy: 0.8666 - dense_146_accuracy: 0.9733 - loss: 3.9349\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n","k: 46 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - dense_131_accuracy: 0.8237 - dense_132_accuracy: 0.8504 - dense_133_accuracy: 0.9466 - dense_134_accuracy: 0.9037 - dense_135_accuracy: 0.9037 - dense_136_accuracy: 0.8933 - dense_137_accuracy: 0.8874 - dense_138_accuracy: 0.9245 - dense_139_accuracy: 0.9200 - dense_140_accuracy: 0.9037 - dense_141_accuracy: 1.0000 - dense_142_accuracy: 0.9466 - dense_143_accuracy: 0.9037 - dense_144_accuracy: 1.0000 - dense_145_accuracy: 0.8074 - dense_146_accuracy: 0.9571 - loss: 3.6946\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n","k: 47 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - dense_131_accuracy: 0.8445 - dense_132_accuracy: 0.8770 - dense_133_accuracy: 1.0000 - dense_134_accuracy: 0.8608 - dense_135_accuracy: 0.9037 - dense_136_accuracy: 0.9037 - dense_137_accuracy: 0.8666 - dense_138_accuracy: 0.8979 - dense_139_accuracy: 0.8933 - dense_140_accuracy: 0.9837 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9733 - dense_143_accuracy: 0.9571 - dense_144_accuracy: 0.9733 - dense_145_accuracy: 0.8770 - dense_146_accuracy: 0.9837 - loss: 3.4525\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 48 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - dense_131_accuracy: 0.8237 - dense_132_accuracy: 0.9037 - dense_133_accuracy: 1.0000 - dense_134_accuracy: 0.9037 - dense_135_accuracy: 0.9466 - dense_136_accuracy: 0.9037 - dense_137_accuracy: 0.9350 - dense_138_accuracy: 0.8770 - dense_139_accuracy: 0.8504 - dense_140_accuracy: 0.9466 - dense_141_accuracy: 0.9733 - dense_142_accuracy: 0.9304 - dense_143_accuracy: 0.9466 - dense_144_accuracy: 0.9733 - dense_145_accuracy: 0.8399 - dense_146_accuracy: 0.9733 - loss: 3.4906\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 49 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n","Test Loss no  1 : 32.81836680884654\n","Iteration 3\n","global_indices [[7, 0, 10, 9, 12, 5], [9, 3, 6, 12, 5, 13], [4, 11, 2, 7, 8, 1], [6, 5, 2, 8], [9, 0, 2, 15, 7, 6]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (13, 120, 47)\n","output_val : (13, 16, 4)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 109ms/step - dense_152_accuracy: 0.1230 - dense_153_accuracy: 0.1763 - dense_154_accuracy: 0.0163 - dense_155_accuracy: 0.4489 - dense_156_accuracy: 0.5452 - dense_157_accuracy: 0.0696 - dense_158_accuracy: 0.3689 - dense_159_accuracy: 0.5081 - dense_160_accuracy: 0.2785 - dense_161_accuracy: 0.2739 - dense_162_accuracy: 0.0429 - dense_163_accuracy: 0.1822 - dense_164_accuracy: 0.3422 - dense_165_accuracy: 0.1776 - dense_166_accuracy: 0.1717 - dense_167_accuracy: 0.2193 - loss: 23.0184\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - dense_152_accuracy: 0.2726 - dense_153_accuracy: 0.3097 - dense_154_accuracy: 0.6369 - dense_155_accuracy: 0.5882 - dense_156_accuracy: 0.6532 - dense_157_accuracy: 0.0800 - dense_158_accuracy: 0.4710 - dense_159_accuracy: 0.5569 - dense_160_accuracy: 0.4339 - dense_161_accuracy: 0.8666 - dense_162_accuracy: 0.8399 - dense_163_accuracy: 0.3318 - dense_164_accuracy: 0.2830 - dense_165_accuracy: 0.3051 - dense_166_accuracy: 0.4014 - dense_167_accuracy: 0.3910 - loss: 19.9999\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - dense_152_accuracy: 0.4489 - dense_153_accuracy: 0.3318 - dense_154_accuracy: 0.8666 - dense_155_accuracy: 0.5940 - dense_156_accuracy: 0.6740 - dense_157_accuracy: 0.0800 - dense_158_accuracy: 0.4606 - dense_159_accuracy: 0.5569 - dense_160_accuracy: 0.6740 - dense_161_accuracy: 0.8666 - dense_162_accuracy: 0.8504 - dense_163_accuracy: 0.5777 - dense_164_accuracy: 0.4014 - dense_165_accuracy: 0.7066 - dense_166_accuracy: 0.5511 - dense_167_accuracy: 0.7970 - loss: 17.3879\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - dense_152_accuracy: 0.5290 - dense_153_accuracy: 0.4977 - dense_154_accuracy: 0.9304 - dense_155_accuracy: 0.6207 - dense_156_accuracy: 0.6845 - dense_157_accuracy: 0.0859 - dense_158_accuracy: 0.5882 - dense_159_accuracy: 0.5777 - dense_160_accuracy: 0.7912 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8874 - dense_163_accuracy: 0.6949 - dense_164_accuracy: 0.6578 - dense_165_accuracy: 0.8608 - dense_166_accuracy: 0.5511 - dense_167_accuracy: 0.9037 - loss: 14.9479\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - dense_152_accuracy: 0.5185 - dense_153_accuracy: 0.7111 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.6415 - dense_156_accuracy: 0.6845 - dense_157_accuracy: 0.4606 - dense_158_accuracy: 0.5882 - dense_159_accuracy: 0.5777 - dense_160_accuracy: 0.7807 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8770 - dense_163_accuracy: 0.6636 - dense_164_accuracy: 0.6474 - dense_165_accuracy: 0.8608 - dense_166_accuracy: 0.5940 - dense_167_accuracy: 0.8933 - loss: 13.3068\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 4 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - dense_152_accuracy: 0.4223 - dense_153_accuracy: 0.6682 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.6311 - dense_156_accuracy: 0.6740 - dense_157_accuracy: 0.7541 - dense_158_accuracy: 0.5986 - dense_159_accuracy: 0.5882 - dense_160_accuracy: 0.7970 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8874 - dense_163_accuracy: 0.6740 - dense_164_accuracy: 0.7111 - dense_165_accuracy: 0.8504 - dense_166_accuracy: 0.6148 - dense_167_accuracy: 0.9037 - loss: 13.0803\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 5 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - dense_152_accuracy: 0.4652 - dense_153_accuracy: 0.6415 - dense_154_accuracy: 0.9304 - dense_155_accuracy: 0.6207 - dense_156_accuracy: 0.6949 - dense_157_accuracy: 0.8237 - dense_158_accuracy: 0.4873 - dense_159_accuracy: 0.5777 - dense_160_accuracy: 0.8074 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8770 - dense_163_accuracy: 0.7111 - dense_164_accuracy: 0.6949 - dense_165_accuracy: 0.8504 - dense_166_accuracy: 0.5882 - dense_167_accuracy: 0.9141 - loss: 12.4976\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n","k: 6 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - dense_152_accuracy: 0.4756 - dense_153_accuracy: 0.6357 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.5777 - dense_156_accuracy: 0.6845 - dense_157_accuracy: 0.8341 - dense_158_accuracy: 0.5615 - dense_159_accuracy: 0.5081 - dense_160_accuracy: 0.8074 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8979 - dense_163_accuracy: 0.7215 - dense_164_accuracy: 0.5615 - dense_165_accuracy: 0.8608 - dense_166_accuracy: 0.5348 - dense_167_accuracy: 0.9037 - loss: 11.8945\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 7 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_152_accuracy: 0.4977 - dense_153_accuracy: 0.6740 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.5348 - dense_156_accuracy: 0.5348 - dense_157_accuracy: 0.8237 - dense_158_accuracy: 0.5615 - dense_159_accuracy: 0.4281 - dense_160_accuracy: 0.7970 - dense_161_accuracy: 0.8874 - dense_162_accuracy: 0.8770 - dense_163_accuracy: 0.7111 - dense_164_accuracy: 0.6253 - dense_165_accuracy: 0.8608 - dense_166_accuracy: 0.4919 - dense_167_accuracy: 0.9037 - loss: 12.1770\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 8 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - dense_152_accuracy: 0.6682 - dense_153_accuracy: 0.7645 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.6415 - dense_156_accuracy: 0.6519 - dense_157_accuracy: 0.8237 - dense_158_accuracy: 0.5244 - dense_159_accuracy: 0.6044 - dense_160_accuracy: 0.7807 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8712 - dense_163_accuracy: 0.6578 - dense_164_accuracy: 0.5940 - dense_165_accuracy: 0.8608 - dense_166_accuracy: 0.5244 - dense_167_accuracy: 0.8933 - loss: 11.6957\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 9 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - dense_152_accuracy: 0.5556 - dense_153_accuracy: 0.6103 - dense_154_accuracy: 0.9304 - dense_155_accuracy: 0.6415 - dense_156_accuracy: 0.6311 - dense_157_accuracy: 0.8445 - dense_158_accuracy: 0.6148 - dense_159_accuracy: 0.5615 - dense_160_accuracy: 0.8074 - dense_161_accuracy: 0.8874 - dense_162_accuracy: 0.8666 - dense_163_accuracy: 0.6207 - dense_164_accuracy: 0.6740 - dense_165_accuracy: 0.8399 - dense_166_accuracy: 0.6311 - dense_167_accuracy: 0.9037 - loss: 11.3703\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","k: 10 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - dense_152_accuracy: 0.5452 - dense_153_accuracy: 0.7541 - dense_154_accuracy: 0.9304 - dense_155_accuracy: 0.7007 - dense_156_accuracy: 0.7482 - dense_157_accuracy: 0.8237 - dense_158_accuracy: 0.6148 - dense_159_accuracy: 0.5986 - dense_160_accuracy: 0.7970 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8770 - dense_163_accuracy: 0.7320 - dense_164_accuracy: 0.7157 - dense_165_accuracy: 0.8504 - dense_166_accuracy: 0.5023 - dense_167_accuracy: 0.9245 - loss: 10.6921\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 11 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - dense_152_accuracy: 0.6148 - dense_153_accuracy: 0.7703 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.6519 - dense_156_accuracy: 0.7111 - dense_157_accuracy: 0.8341 - dense_158_accuracy: 0.6090 - dense_159_accuracy: 0.6311 - dense_160_accuracy: 0.8178 - dense_161_accuracy: 0.8608 - dense_162_accuracy: 0.8979 - dense_163_accuracy: 0.7111 - dense_164_accuracy: 0.6949 - dense_165_accuracy: 0.8608 - dense_166_accuracy: 0.6474 - dense_167_accuracy: 0.9141 - loss: 10.3671\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 12 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - dense_152_accuracy: 0.6682 - dense_153_accuracy: 0.8016 - dense_154_accuracy: 0.9200 - dense_155_accuracy: 0.7378 - dense_156_accuracy: 0.7320 - dense_157_accuracy: 0.8133 - dense_158_accuracy: 0.5615 - dense_159_accuracy: 0.5882 - dense_160_accuracy: 0.8237 - dense_161_accuracy: 0.8770 - dense_162_accuracy: 0.8770 - dense_163_accuracy: 0.6740 - dense_164_accuracy: 0.6623 - dense_165_accuracy: 0.8399 - dense_166_accuracy: 0.5882 - dense_167_accuracy: 0.8933 - loss: 10.6227\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 13 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n","Test Loss no  2 : 54.98472359275282\n","Iteration 4\n","global_indices [[7, 0, 10, 9, 12, 5, 1, 13, 4], [9, 3, 6, 12, 5, 13, 2, 0, 4], [4, 11, 2, 7, 8, 1, 0, 12, 9], [6, 5, 2, 8, 0, 3], [9, 0, 2, 15, 7, 6, 12, 13, 4]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (14, 120, 47)\n","output_val : (14, 16, 4)\n","input_test : (13, 120, 47)\n","output_test : (13, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 189ms/step - dense_173_accuracy: 0.1496 - dense_174_accuracy: 0.6740 - dense_175_accuracy: 0.2785 - dense_176_accuracy: 0.5348 - dense_177_accuracy: 0.3481 - dense_178_accuracy: 0.3643 - dense_179_accuracy: 0.5615 - dense_180_accuracy: 0.3747 - dense_181_accuracy: 0.4873 - dense_182_accuracy: 0.8283 - dense_183_accuracy: 0.2726 - dense_184_accuracy: 0.3422 - dense_185_accuracy: 0.2472 - dense_186_accuracy: 0.7866 - dense_187_accuracy: 0.3526 - dense_188_accuracy: 0.0696 - loss: 20.7982\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - dense_173_accuracy: 0.0963 - dense_174_accuracy: 0.8283 - dense_175_accuracy: 0.8874 - dense_176_accuracy: 0.5986 - dense_177_accuracy: 0.1717 - dense_178_accuracy: 0.8178 - dense_179_accuracy: 0.4385 - dense_180_accuracy: 0.3956 - dense_181_accuracy: 0.8653 - dense_182_accuracy: 0.8445 - dense_183_accuracy: 0.6148 - dense_184_accuracy: 0.7378 - dense_185_accuracy: 0.7378 - dense_186_accuracy: 0.9245 - dense_187_accuracy: 0.1822 - dense_188_accuracy: 0.1288 - loss: 17.3649\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - dense_173_accuracy: 0.1230 - dense_174_accuracy: 0.8074 - dense_175_accuracy: 0.9037 - dense_176_accuracy: 0.5673 - dense_177_accuracy: 0.5140 - dense_178_accuracy: 0.7436 - dense_179_accuracy: 0.4977 - dense_180_accuracy: 0.5615 - dense_181_accuracy: 0.7807 - dense_182_accuracy: 0.8237 - dense_183_accuracy: 0.8504 - dense_184_accuracy: 0.7645 - dense_185_accuracy: 0.7111 - dense_186_accuracy: 0.9141 - dense_187_accuracy: 0.2889 - dense_188_accuracy: 0.5569 - loss: 15.4275\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - dense_173_accuracy: 0.3481 - dense_174_accuracy: 0.7970 - dense_175_accuracy: 0.9141 - dense_176_accuracy: 0.5940 - dense_177_accuracy: 0.8074 - dense_178_accuracy: 0.7970 - dense_179_accuracy: 0.4919 - dense_180_accuracy: 0.5940 - dense_181_accuracy: 0.8178 - dense_182_accuracy: 0.8445 - dense_183_accuracy: 0.8770 - dense_184_accuracy: 0.7645 - dense_185_accuracy: 0.7274 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.5302 - dense_188_accuracy: 0.8133 - loss: 13.2244\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - dense_173_accuracy: 0.4548 - dense_174_accuracy: 0.8178 - dense_175_accuracy: 0.9245 - dense_176_accuracy: 0.5719 - dense_177_accuracy: 0.8178 - dense_178_accuracy: 0.8283 - dense_179_accuracy: 0.4548 - dense_180_accuracy: 0.5986 - dense_181_accuracy: 0.8341 - dense_182_accuracy: 0.8549 - dense_183_accuracy: 0.9408 - dense_184_accuracy: 0.7749 - dense_185_accuracy: 0.7586 - dense_186_accuracy: 0.9141 - dense_187_accuracy: 0.5452 - dense_188_accuracy: 0.8770 - loss: 12.7395\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 4 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - dense_173_accuracy: 0.3422 - dense_174_accuracy: 0.8074 - dense_175_accuracy: 0.9141 - dense_176_accuracy: 0.4919 - dense_177_accuracy: 0.8445 - dense_178_accuracy: 0.8074 - dense_179_accuracy: 0.4756 - dense_180_accuracy: 0.5777 - dense_181_accuracy: 0.8549 - dense_182_accuracy: 0.8341 - dense_183_accuracy: 0.9408 - dense_184_accuracy: 0.8178 - dense_185_accuracy: 0.7482 - dense_186_accuracy: 0.9245 - dense_187_accuracy: 0.6090 - dense_188_accuracy: 0.9083 - loss: 11.8685\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 5 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - dense_173_accuracy: 0.4060 - dense_174_accuracy: 0.8445 - dense_175_accuracy: 0.9245 - dense_176_accuracy: 0.5452 - dense_177_accuracy: 0.8341 - dense_178_accuracy: 0.8178 - dense_179_accuracy: 0.5185 - dense_180_accuracy: 0.5556 - dense_181_accuracy: 0.8341 - dense_182_accuracy: 0.8549 - dense_183_accuracy: 0.9408 - dense_184_accuracy: 0.7482 - dense_185_accuracy: 0.7482 - dense_186_accuracy: 0.9141 - dense_187_accuracy: 0.5290 - dense_188_accuracy: 0.8874 - loss: 10.9374\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 6 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - dense_173_accuracy: 0.4385 - dense_174_accuracy: 0.7866 - dense_175_accuracy: 0.9141 - dense_176_accuracy: 0.6044 - dense_177_accuracy: 0.8237 - dense_178_accuracy: 0.7970 - dense_179_accuracy: 0.4548 - dense_180_accuracy: 0.4919 - dense_181_accuracy: 0.8237 - dense_182_accuracy: 0.8237 - dense_183_accuracy: 0.9200 - dense_184_accuracy: 0.6949 - dense_185_accuracy: 0.6740 - dense_186_accuracy: 0.8933 - dense_187_accuracy: 0.5615 - dense_188_accuracy: 0.8666 - loss: 12.3225\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 7 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - dense_173_accuracy: 0.3956 - dense_174_accuracy: 0.7970 - dense_175_accuracy: 0.8933 - dense_176_accuracy: 0.6148 - dense_177_accuracy: 0.8237 - dense_178_accuracy: 0.7703 - dense_179_accuracy: 0.5185 - dense_180_accuracy: 0.4014 - dense_181_accuracy: 0.8237 - dense_182_accuracy: 0.7541 - dense_183_accuracy: 0.9304 - dense_184_accuracy: 0.7541 - dense_185_accuracy: 0.7541 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.5348 - dense_188_accuracy: 0.8770 - loss: 12.1437\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 8 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_173_accuracy: 0.4281 - dense_174_accuracy: 0.7970 - dense_175_accuracy: 0.8933 - dense_176_accuracy: 0.6311 - dense_177_accuracy: 0.8341 - dense_178_accuracy: 0.8074 - dense_179_accuracy: 0.5185 - dense_180_accuracy: 0.4710 - dense_181_accuracy: 0.8341 - dense_182_accuracy: 0.8504 - dense_183_accuracy: 0.9304 - dense_184_accuracy: 0.7274 - dense_185_accuracy: 0.7007 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.6253 - dense_188_accuracy: 0.8874 - loss: 10.9675\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 9 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_173_accuracy: 0.5348 - dense_174_accuracy: 0.8074 - dense_175_accuracy: 0.9037 - dense_176_accuracy: 0.6311 - dense_177_accuracy: 0.8237 - dense_178_accuracy: 0.8074 - dense_179_accuracy: 0.5719 - dense_180_accuracy: 0.5615 - dense_181_accuracy: 0.8237 - dense_182_accuracy: 0.7703 - dense_183_accuracy: 0.9304 - dense_184_accuracy: 0.7170 - dense_185_accuracy: 0.7274 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.5615 - dense_188_accuracy: 0.8874 - loss: 10.9989\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 10 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - dense_173_accuracy: 0.5407 - dense_174_accuracy: 0.7866 - dense_175_accuracy: 0.8933 - dense_176_accuracy: 0.5348 - dense_177_accuracy: 0.8237 - dense_178_accuracy: 0.8074 - dense_179_accuracy: 0.5081 - dense_180_accuracy: 0.5511 - dense_181_accuracy: 0.8237 - dense_182_accuracy: 0.8133 - dense_183_accuracy: 0.9200 - dense_184_accuracy: 0.7332 - dense_185_accuracy: 0.7274 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.6148 - dense_188_accuracy: 0.8770 - loss: 10.9719\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 11 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - dense_173_accuracy: 0.5661 - dense_174_accuracy: 0.8178 - dense_175_accuracy: 0.9141 - dense_176_accuracy: 0.5244 - dense_177_accuracy: 0.8341 - dense_178_accuracy: 0.7970 - dense_179_accuracy: 0.4815 - dense_180_accuracy: 0.5777 - dense_181_accuracy: 0.8341 - dense_182_accuracy: 0.8445 - dense_183_accuracy: 0.9304 - dense_184_accuracy: 0.7541 - dense_185_accuracy: 0.6903 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.4548 - dense_188_accuracy: 0.8770 - loss: 10.5925\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 12 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - dense_173_accuracy: 0.5081 - dense_174_accuracy: 0.8237 - dense_175_accuracy: 0.9037 - dense_176_accuracy: 0.5777 - dense_177_accuracy: 0.8341 - dense_178_accuracy: 0.8178 - dense_179_accuracy: 0.5511 - dense_180_accuracy: 0.5986 - dense_181_accuracy: 0.8237 - dense_182_accuracy: 0.8237 - dense_183_accuracy: 0.9304 - dense_184_accuracy: 0.7703 - dense_185_accuracy: 0.7274 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.6786 - dense_188_accuracy: 0.8666 - loss: 10.3078\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n","k: 13 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - dense_173_accuracy: 0.5023 - dense_174_accuracy: 0.8608 - dense_175_accuracy: 0.9037 - dense_176_accuracy: 0.6578 - dense_177_accuracy: 0.8133 - dense_178_accuracy: 0.7970 - dense_179_accuracy: 0.3481 - dense_180_accuracy: 0.5673 - dense_181_accuracy: 0.8237 - dense_182_accuracy: 0.8237 - dense_183_accuracy: 0.9200 - dense_184_accuracy: 0.7170 - dense_185_accuracy: 0.7274 - dense_186_accuracy: 0.9037 - dense_187_accuracy: 0.5673 - dense_188_accuracy: 0.8770 - loss: 10.5852\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n","k: 14 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779ms/step\n","Test Loss no  3 : 34.08880709603622\n","Iteration 5\n","global_indices [[7, 0, 10, 9, 12, 5, 1, 13, 4, 2, 11, 8], [9, 3, 6, 12, 5, 13, 2, 0, 4, 1, 10, 11], [4, 11, 2, 7, 8, 1, 0, 12, 9, 5, 10], [6, 5, 2, 8, 0, 3, 10, 4], [9, 0, 2, 15, 7, 6, 12, 13, 4, 3, 10, 1]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (14, 120, 47)\n","output_val : (14, 16, 4)\n","input_test : (13, 120, 47)\n","output_test : (13, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - dense_194_accuracy: 0.1067 - dense_195_accuracy: 0.2518 - dense_196_accuracy: 0.0163 - dense_197_accuracy: 0.4860 - dense_198_accuracy: 0.1230 - dense_199_accuracy: 0.0429 - dense_200_accuracy: 0.2193 - dense_201_accuracy: 0.1984 - dense_202_accuracy: 0.6253 - dense_203_accuracy: 0.5127 - dense_204_accuracy: 0.4931 - dense_205_accuracy: 0.0963 - dense_206_accuracy: 0.3585 - dense_207_accuracy: 0.8666 - dense_208_accuracy: 0.2030 - dense_209_accuracy: 0.1822 - loss: 22.3185\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - dense_194_accuracy: 0.1763 - dense_195_accuracy: 0.6474 - dense_196_accuracy: 0.3214 - dense_197_accuracy: 0.4327 - dense_198_accuracy: 0.5244 - dense_199_accuracy: 0.3318 - dense_200_accuracy: 0.2459 - dense_201_accuracy: 0.2459 - dense_202_accuracy: 0.8074 - dense_203_accuracy: 0.4502 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.2251 - dense_206_accuracy: 0.7215 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.2564 - dense_209_accuracy: 0.7170 - loss: 18.4421\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - dense_194_accuracy: 0.2401 - dense_195_accuracy: 0.7599 - dense_196_accuracy: 0.8399 - dense_197_accuracy: 0.5407 - dense_198_accuracy: 0.7599 - dense_199_accuracy: 0.5081 - dense_200_accuracy: 0.4919 - dense_201_accuracy: 0.5244 - dense_202_accuracy: 0.7703 - dense_203_accuracy: 0.8133 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7066 - dense_206_accuracy: 0.6474 - dense_207_accuracy: 0.8933 - dense_208_accuracy: 0.3051 - dense_209_accuracy: 0.8770 - loss: 15.5074\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - dense_194_accuracy: 0.3051 - dense_195_accuracy: 0.7703 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.5348 - dense_198_accuracy: 0.7703 - dense_199_accuracy: 0.7274 - dense_200_accuracy: 0.5140 - dense_201_accuracy: 0.5081 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8712 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.7007 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.4710 - dense_209_accuracy: 0.8770 - loss: 13.3075\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_194_accuracy: 0.4698 - dense_195_accuracy: 0.7912 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.6090 - dense_198_accuracy: 0.7703 - dense_199_accuracy: 0.7912 - dense_200_accuracy: 0.5777 - dense_201_accuracy: 0.6519 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8608 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.6578 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5986 - dense_209_accuracy: 0.8666 - loss: 12.9164\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - dense_194_accuracy: 0.5348 - dense_195_accuracy: 0.7807 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.5777 - dense_198_accuracy: 0.7807 - dense_199_accuracy: 0.7866 - dense_200_accuracy: 0.5615 - dense_201_accuracy: 0.6415 - dense_202_accuracy: 0.7703 - dense_203_accuracy: 0.8399 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.7215 - dense_207_accuracy: 0.8933 - dense_208_accuracy: 0.5777 - dense_209_accuracy: 0.8874 - loss: 12.9570\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - dense_194_accuracy: 0.5185 - dense_195_accuracy: 0.7703 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.5407 - dense_198_accuracy: 0.7807 - dense_199_accuracy: 0.7970 - dense_200_accuracy: 0.6148 - dense_201_accuracy: 0.6415 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8399 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.8016 - dense_206_accuracy: 0.7482 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5882 - dense_209_accuracy: 0.8874 - loss: 12.0187\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n","k: 6 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - dense_194_accuracy: 0.4964 - dense_195_accuracy: 0.7749 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.6253 - dense_198_accuracy: 0.8016 - dense_199_accuracy: 0.8341 - dense_200_accuracy: 0.6461 - dense_201_accuracy: 0.5823 - dense_202_accuracy: 0.7912 - dense_203_accuracy: 0.8608 - dense_204_accuracy: 0.9141 - dense_205_accuracy: 0.8016 - dense_206_accuracy: 0.6949 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5452 - dense_209_accuracy: 0.8874 - loss: 11.3133\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n","k: 7 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - dense_194_accuracy: 0.5452 - dense_195_accuracy: 0.7912 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.4060 - dense_198_accuracy: 0.7703 - dense_199_accuracy: 0.7807 - dense_200_accuracy: 0.5940 - dense_201_accuracy: 0.5940 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8504 - dense_204_accuracy: 0.9141 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.6103 - dense_207_accuracy: 0.9141 - dense_208_accuracy: 0.5673 - dense_209_accuracy: 0.8666 - loss: 11.6496\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n","k: 8 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - dense_194_accuracy: 0.5452 - dense_195_accuracy: 0.7807 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.5511 - dense_198_accuracy: 0.7703 - dense_199_accuracy: 0.7866 - dense_200_accuracy: 0.6148 - dense_201_accuracy: 0.4548 - dense_202_accuracy: 0.7703 - dense_203_accuracy: 0.8608 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7599 - dense_206_accuracy: 0.6903 - dense_207_accuracy: 0.8933 - dense_208_accuracy: 0.5615 - dense_209_accuracy: 0.8666 - loss: 11.3028\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n","k: 9 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - dense_194_accuracy: 0.4177 - dense_195_accuracy: 0.7703 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.5556 - dense_198_accuracy: 0.7703 - dense_199_accuracy: 0.8074 - dense_200_accuracy: 0.6044 - dense_201_accuracy: 0.4977 - dense_202_accuracy: 0.7599 - dense_203_accuracy: 0.8608 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.7007 - dense_207_accuracy: 0.8933 - dense_208_accuracy: 0.5185 - dense_209_accuracy: 0.8770 - loss: 10.8782\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 10 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - dense_194_accuracy: 0.4756 - dense_195_accuracy: 0.7703 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.6311 - dense_198_accuracy: 0.7807 - dense_199_accuracy: 0.7866 - dense_200_accuracy: 0.5940 - dense_201_accuracy: 0.5244 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8712 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7807 - dense_206_accuracy: 0.7007 - dense_207_accuracy: 0.8933 - dense_208_accuracy: 0.4815 - dense_209_accuracy: 0.8666 - loss: 11.6125\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n","k: 11 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - dense_194_accuracy: 0.3852 - dense_195_accuracy: 0.7703 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.7645 - dense_198_accuracy: 0.7912 - dense_199_accuracy: 0.8074 - dense_200_accuracy: 0.6519 - dense_201_accuracy: 0.5244 - dense_202_accuracy: 0.8016 - dense_203_accuracy: 0.8608 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7436 - dense_206_accuracy: 0.6903 - dense_207_accuracy: 0.9141 - dense_208_accuracy: 0.6044 - dense_209_accuracy: 0.8770 - loss: 10.4224\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 12 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - dense_194_accuracy: 0.4815 - dense_195_accuracy: 0.7970 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.6903 - dense_198_accuracy: 0.8074 - dense_199_accuracy: 0.7970 - dense_200_accuracy: 0.6103 - dense_201_accuracy: 0.6103 - dense_202_accuracy: 0.7912 - dense_203_accuracy: 0.8504 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.6740 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5615 - dense_209_accuracy: 0.8770 - loss: 10.2460\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 13 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - dense_194_accuracy: 0.5556 - dense_195_accuracy: 0.8445 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.8074 - dense_198_accuracy: 0.7320 - dense_199_accuracy: 0.8074 - dense_200_accuracy: 0.6519 - dense_201_accuracy: 0.6786 - dense_202_accuracy: 0.7703 - dense_203_accuracy: 0.8504 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.7482 - dense_207_accuracy: 0.8933 - dense_208_accuracy: 0.5719 - dense_209_accuracy: 0.8874 - loss: 9.9959\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 14 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - dense_194_accuracy: 0.5290 - dense_195_accuracy: 0.8549 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.7541 - dense_198_accuracy: 0.7912 - dense_199_accuracy: 0.7970 - dense_200_accuracy: 0.5986 - dense_201_accuracy: 0.6519 - dense_202_accuracy: 0.7436 - dense_203_accuracy: 0.8504 - dense_204_accuracy: 0.9141 - dense_205_accuracy: 0.8016 - dense_206_accuracy: 0.7215 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5290 - dense_209_accuracy: 0.8933 - loss: 9.6622\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 15 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - dense_194_accuracy: 0.5615 - dense_195_accuracy: 0.8074 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.7645 - dense_198_accuracy: 0.7807 - dense_199_accuracy: 0.7970 - dense_200_accuracy: 0.5882 - dense_201_accuracy: 0.6311 - dense_202_accuracy: 0.7436 - dense_203_accuracy: 0.8608 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7912 - dense_206_accuracy: 0.6949 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5185 - dense_209_accuracy: 0.8770 - loss: 9.9025\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 16 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - dense_194_accuracy: 0.5940 - dense_195_accuracy: 0.8133 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.7912 - dense_198_accuracy: 0.7599 - dense_199_accuracy: 0.8074 - dense_200_accuracy: 0.5511 - dense_201_accuracy: 0.6207 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8504 - dense_204_accuracy: 0.8933 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.6740 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5348 - dense_209_accuracy: 0.8770 - loss: 9.8067\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 17 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - dense_194_accuracy: 0.5940 - dense_195_accuracy: 0.8133 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.7170 - dense_198_accuracy: 0.7866 - dense_199_accuracy: 0.8178 - dense_200_accuracy: 0.5986 - dense_201_accuracy: 0.6474 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8399 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7703 - dense_206_accuracy: 0.7274 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.4815 - dense_209_accuracy: 0.8979 - loss: 9.1299\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 18 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - dense_194_accuracy: 0.6845 - dense_195_accuracy: 0.8874 - dense_196_accuracy: 0.9304 - dense_197_accuracy: 0.7007 - dense_198_accuracy: 0.8074 - dense_199_accuracy: 0.8445 - dense_200_accuracy: 0.6786 - dense_201_accuracy: 0.6148 - dense_202_accuracy: 0.7970 - dense_203_accuracy: 0.8504 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7645 - dense_206_accuracy: 0.7541 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5348 - dense_209_accuracy: 0.9141 - loss: 8.9226\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 19 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - dense_194_accuracy: 0.5244 - dense_195_accuracy: 0.8666 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.7599 - dense_198_accuracy: 0.8341 - dense_199_accuracy: 0.7970 - dense_200_accuracy: 0.6148 - dense_201_accuracy: 0.6415 - dense_202_accuracy: 0.7807 - dense_203_accuracy: 0.8399 - dense_204_accuracy: 0.9304 - dense_205_accuracy: 0.7912 - dense_206_accuracy: 0.7645 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5081 - dense_209_accuracy: 0.9408 - loss: 9.2142\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 20 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - dense_194_accuracy: 0.5081 - dense_195_accuracy: 0.8445 - dense_196_accuracy: 0.9200 - dense_197_accuracy: 0.7807 - dense_198_accuracy: 0.8133 - dense_199_accuracy: 0.8178 - dense_200_accuracy: 0.6103 - dense_201_accuracy: 0.6740 - dense_202_accuracy: 0.8074 - dense_203_accuracy: 0.8399 - dense_204_accuracy: 0.9037 - dense_205_accuracy: 0.7599 - dense_206_accuracy: 0.7703 - dense_207_accuracy: 0.9037 - dense_208_accuracy: 0.5882 - dense_209_accuracy: 0.8666 - loss: 9.0856\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 21 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n","Test Loss no  4 : 42.37679372196351\n","average_loss: 39.38383760872934\n"]}],"source":["from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n","from keras.optimizers import Adam\n","import numpy as np\n","import sklearn\n","from keras.utils import to_categorical\n","\n","total_losses = []\n","\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Self attention\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Cross attention\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, enc_outputs)\n","    x = Dropout(dropout)(x)\n","    res = x + res\n","\n","    # Feed forward\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def get_hard_shared_model(input_shape1, input_shape2, output_shape):\n","    # Encoder input\n","    enc_inputs = Input(shape=(input_shape1, input_shape2))\n","\n","    # Encoder\n","    enc_outputs = transformer_encoder(enc_inputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Decoder input\n","    dec_inputs = Input(shape=(output_shape[1], input_shape2))\n","\n","    # Decoder\n","    dec_outputs = transformer_decoder(dec_inputs, enc_outputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Global pooling\n","    x = GlobalAveragePooling1D()(dec_outputs)\n","\n","    # Shared dense layer\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","\n","    # Task-specific output layers\n","    outputs = []\n","    for i in range(output_shape[1]):\n","        task_output = Dense(4, activation='softmax')(x)\n","        outputs.append(task_output)\n","\n","    return Model([enc_inputs, dec_inputs], outputs)\n","\n","input_groups = [input_group_1, input_group_2, input_group_3, input_group_4, input_group_5]\n","output_groups = [output_group_1, output_group_2, output_group_3, output_group_4, output_group_5]\n","ssq_groups = [output_total_ssq_group_1, output_total_ssq_group_2, output_total_ssq_group_3, output_total_ssq_group_4, output_total_ssq_group_5]\n","\n","\n","# Specify the number of samples to select for each group in each iteration\n","samples_per_iteration = [\n","    [3, 3, 3, 3, 2],  # For input_group_1\n","    [3, 3, 3, 3, 2],  # For input_group_2\n","    [3, 3, 3, 2, 2],  # For input_group_3\n","    [2, 2, 2, 2, 3],  # For input_group_4\n","    [3, 3, 3, 3, 4]   # For input_group_5\n","]\n","\n","# Initialize a list of global indices arrays, one for each group\n","global_indices = [[] for _ in range(len(input_groups))]\n","print(\"global_indices\",global_indices)\n","\n","# Outer loop to repeat the sampling process for 5 iterations\n","for iteration in range(5):\n","  X_train, X_val, X_test = [], [], []\n","  y_train, y_val, y_test = [], [], []\n","  ssq_train, ssq_val, ssq_test = [], [], []\n","  print(f\"Iteration {iteration + 1}\")\n","  print(\"global_indices\",global_indices)\n","  # Loop over each group\n","  for i, (input_group, output_group, ssq_group) in enumerate(zip(input_groups, output_groups, ssq_groups)):\n","      num_samples = samples_per_iteration[i][iteration]  # Number of samples to select for the current group and iteration\n","\n","      # Create a set of available indices that haven't been selected yet for the current group\n","      available_indices = list(set(range(len(input_group))) - set(global_indices[i]))\n","\n","      # Check if there are fewer available indices than needed\n","      if len(available_indices) < num_samples:\n","          print(f\"Not enough indices left in group {i + 1} to select {num_samples} new samples.\")\n","          num_samples = len(available_indices)  # Adjust to take whatever is left\n","\n","      # Select the required number of samples from the available indices for the current group\n","      selected_indices = np.random.choice(available_indices, num_samples, replace=False)\n","      global_indices[i].extend(selected_indices)  # Add these indices to the group's global list\n","\n","      # Remove these selected samples from the input, output, and SSQ groups\n","      X_test_temp = input_group[selected_indices]\n","      y_test_temp = output_group[selected_indices]\n","      ssq_test_temp = ssq_group[selected_indices]\n","\n","      X_temp = np.delete(input_group, selected_indices, axis=0)\n","      y_temp = np.delete(output_group, selected_indices, axis=0)\n","      ssq_temp = np.delete(ssq_group, selected_indices, axis=0)\n","\n","      # Split the remaining data into a training set (60%) and a validation set (40%)\n","      X_train_temp, X_val_temp, y_train_temp, y_val_temp, ssq_train_temp, ssq_val_temp = train_test_split(\n","          X_temp, y_temp, ssq_temp, test_size=0.2)\n","\n","      # Append the results to the corresponding lists\n","      X_train.append(X_train_temp)\n","      X_val.append(X_val_temp)\n","      X_test.append(X_test_temp)\n","\n","      y_train.append(y_train_temp)\n","      y_val.append(y_val_temp)\n","      y_test.append(y_test_temp)\n","\n","      ssq_train.append(ssq_train_temp)\n","      ssq_val.append(ssq_val_temp)\n","      ssq_test.append(ssq_test_temp)\n","\n","  # After the loop, concatenate the data for all groups if needed\n","  input_train = np.concatenate(X_train, axis=0)\n","  input_val = np.concatenate(X_val, axis=0)\n","  input_test = np.concatenate(X_test, axis=0)\n","\n","  output_train = np.concatenate(y_train, axis=0)\n","  output_val = np.concatenate(y_val, axis=0)\n","  output_test = np.concatenate(y_test, axis=0)\n","\n","  ssq_val = np.concatenate(ssq_val, axis=0)\n","  output_test_total_ssq = np.concatenate(ssq_test, axis=0)\n","\n","\n","  #  this section for scaling both train and validation set simultaniously\n","  # Step 1: Combine the training and validation sets\n","  combined_input = np.concatenate([input_train, input_val], axis=0)\n","  combined_output = np.concatenate([output_train, output_val], axis=0)\n","\n","  # Step 2: Scale the combined input data\n","  # Assuming scale_input_data scales the data based on the combined dataset\n","  combined_input, input_test = scale_input_data(\n","      combined_input[:, (60-sample_size):(180-sample_size), :],\n","      input_test[:, (60-sample_size):(180-sample_size), :]\n","  )\n","\n","  # Convert the original labels to one-hot encoded format\n","  output_train_encoded = to_categorical(combined_output, num_classes=4)\n","\n","  # Step 4: Split the combined data back into training and validation sets\n","  # Use the original shapes of input_train and input_val to slice the combined arrays\n","  input_train = combined_input[:input_train.shape[0], :, :]\n","  input_val = combined_input[input_train.shape[0]:, :, :]\n","\n","  output_train = output_train_encoded[:output_train.shape[0], :]\n","  output_val = output_train_encoded[output_train.shape[0]:, :]\n","\n","\n","\n","  print(\"input_train :\", input_train.shape)\n","  print(\"output_train :\", output_train.shape)\n","  print(\"input_val :\", input_val.shape)\n","  print(\"output_val :\", output_val.shape)\n","  print(\"input_test :\", input_test.shape)\n","  print(\"output_test :\", output_test.shape)\n","\n","\n","  # Reshape inputs\n","  train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","  test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","  val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","  # Create decoder inputs\n","  train_dec_input = np.zeros((train_input_reshaped.shape[0], output_train.shape[1], train_input_reshaped.shape[2]))\n","  val_dec_input = np.zeros((val_input_reshaped.shape[0], output_train.shape[1], val_input_reshaped.shape[2]))\n","  test_dec_input = np.zeros((test_input_reshaped.shape[0], output_test.shape[1], test_input_reshaped.shape[2]))\n","\n","  # Create the hard parameter sharing model\n","  model = get_hard_shared_model(input_train.shape[1], input_train.shape[2], output_train.shape)\n","\n","  # Compile and train the model\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[['accuracy'] for _ in range(output_train.shape[1])])\n","  best_val = 1000000\n","  patience = 0\n","  best_model = None\n","\n","  for k in range(200):\n","    # Train the model\n","    model.fit([train_input_reshaped, train_dec_input],\n","              [output_train[:, i] for i in range(output_train.shape[1])],\n","              epochs=1, batch_size=32, verbose=1)\n","\n","    # Predict validation data\n","    pred_val = np.array(model.predict([val_input_reshaped, val_dec_input]))\n","    pred_val = np.transpose(pred_val, (1, 0, 2)).squeeze()\n","    pred_val = np.argmax(pred_val, axis=-1).reshape(pred_val.shape[:-1])\n","    print(\"k:\", k, \"patience:\", patience)\n","\n","    # Evaluate the model\n","    losses = []\n","    for i in range(pred_val.shape[0]):\n","      total_ssq=0\n","      for j in [0,5,6,7,8,14,15]:\n","        total_ssq=np.sum(pred_val[i,j])+total_ssq\n","\n","      for j in [0,1,2,3,4,8,10]:\n","        total_ssq=np.sum(pred_val[i,j])+total_ssq\n","\n","      for j in [4,7,9,10,11,12,13]:\n","        total_ssq=np.sum(pred_val[i,j])+total_ssq\n","      total_ssq=total_ssq*3.74\n","      output_val_ssq= ssq_val[i,0]\n","      #print(\"total_ssq\",total_ssq)\n","      #print(\"output_val_ssq\",output_val_ssq)\n","      loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","      losses.append(loss)\n","    tmp_val_loss = np.mean(losses)\n","    if tmp_val_loss <= best_val:\n","        best_val = tmp_val_loss\n","        patience = 0\n","        best_model = model\n","    else:\n","        patience +=1\n","        if patience > 10:\n","          break\n","\n","  # Predict test data\n","  pred_test = np.array(best_model.predict([test_input_reshaped, test_dec_input]))\n","  pred_test = np.transpose(pred_test, (1, 0, 2)).squeeze()\n","  pred_test = np.argmax(pred_test, axis=-1).reshape(pred_test.shape[:-1])\n","\n","  # Evaluate the model\n","  pred_total_ssq = []\n","  for i in range(pred_test.shape[0]):\n","      total_ssq = 0\n","      for j in [0, 5, 6, 7, 8, 14, 15]:\n","          total_ssq += np.sum(pred_test[i, j])\n","\n","      for j in [0, 1, 2, 3, 4, 8, 10]:\n","          total_ssq += np.sum(pred_test[i, j])\n","\n","      for j in [4, 7, 9, 10, 11, 12, 13]:\n","          total_ssq += np.sum(pred_test[i, j])\n","\n","      total_ssq *= 3.74\n","      pred_total_ssq.append(total_ssq)\n","  # Overall Test Loss\n","  loss = sklearn.metrics.mean_squared_error(pred_total_ssq, output_test_total_ssq, squared = False)\n","  print(\"Test Loss no \",iteration,\":\" ,loss)\n","  total_losses.append(loss)\n","average_loss = sum(total_losses) / len(total_losses)\n","total_losses.append(average_loss)\n","print(\"average_loss:\", average_loss)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNJIFPegxIi54U4DrKSnOp"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}