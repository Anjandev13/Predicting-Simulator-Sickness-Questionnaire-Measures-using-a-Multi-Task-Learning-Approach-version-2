{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMay8g/e6emPqwkY2Nt//vC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"id":"fT_A9oAGAepC","executionInfo":{"status":"ok","timestamp":1726040439770,"user_tz":300,"elapsed":754,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TishlaEBAmlN","executionInfo":{"status":"ok","timestamp":1726040441151,"user_tz":300,"elapsed":1045,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"0283f783-68d8-4f62-e739-78a392e565e2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"],"metadata":{"id":"XeSwJ8oKAt2r","executionInfo":{"status":"ok","timestamp":1726040441151,"user_tz":300,"elapsed":7,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"],"metadata":{"id":"BFHyHoFvA5bX","executionInfo":{"status":"ok","timestamp":1726040441151,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","        arrays_3d.append(array_3d)\n","\n","    return arrays_3d\n"],"metadata":{"id":"QeoIWcudA94b","executionInfo":{"status":"ok","timestamp":1726040441151,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["sample_size=30\n","simulations = ['flat','noise','bumps']\n","participants = [str(i) for i in range(1, 27)]  # Participants 101 to 127\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"],"metadata":{"id":"fqaeUGUDBCtT","executionInfo":{"status":"ok","timestamp":1726040441152,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[0, n_columns].sum()\n","    o_val = df.iloc[0, o_columns].sum()\n","    d_val = df.iloc[0, d_columns].sum()\n","\n","    return n_val, o_val, d_val"],"metadata":{"id":"vPQyeAYKBYaO","executionInfo":{"status":"ok","timestamp":1726040441152,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          # n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          # total_ssq_values.append([n_val, o_val, d_val])\n","          ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"],"metadata":{"id":"Xpn0lDt0BfvE","executionInfo":{"status":"ok","timestamp":1726040441153,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["participants_group_1 = [1,3,4,11,25]\n","participants_group_2 = [2,7,8,9,17]\n","participants_group_3 = [10,12,13,22,23]\n","participants_group_4 = [5,14,18,20,21]\n","participants_group_5 = [6,15,16,19,24,26]\n","\n","arrays_group_1 = construct_3d_array(base_path, participants_group_1, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_2 = construct_3d_array(base_path, participants_group_2, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_3 = construct_3d_array(base_path, participants_group_3, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_4 = construct_3d_array(base_path, participants_group_4, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_5 = construct_3d_array(base_path, participants_group_5, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"],"metadata":{"id":"7k17K0HrCr6-","executionInfo":{"status":"ok","timestamp":1726040443455,"user_tz":300,"elapsed":2308,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Concatenate arrays along the first axis\n","input_group_1 = np.concatenate(arrays_group_1, axis=0)\n","input_group_2 = np.concatenate(arrays_group_2, axis=0)\n","input_group_3 = np.concatenate(arrays_group_3, axis=0)\n","input_group_4 = np.concatenate(arrays_group_4, axis=0)\n","input_group_5 = np.concatenate(arrays_group_5, axis=0)\n"],"metadata":{"id":"rRIv2QVJmygH","executionInfo":{"status":"ok","timestamp":1726040443455,"user_tz":300,"elapsed":4,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["output_group_1=merge_ssq_column(simulations,participants_group_1)\n","output_group_2=merge_ssq_column(simulations,participants_group_2)\n","output_group_3=merge_ssq_column(simulations,participants_group_3)\n","output_group_4=merge_ssq_column(simulations,participants_group_4)\n","output_group_5=merge_ssq_column(simulations,participants_group_5)\n","\n","output_group_1 = np.squeeze(output_group_1)\n","output_group_2 = np.squeeze(output_group_2)\n","output_group_3 = np.squeeze(output_group_3)\n","output_group_4 = np.squeeze(output_group_4)\n","output_group_5 = np.squeeze(output_group_5)\n","\n","\n","output_total_ssq_group_1=merge_total_ssq(simulations,participants_group_1)\n","output_total_ssq_group_2=merge_total_ssq(simulations,participants_group_2)\n","output_total_ssq_group_3=merge_total_ssq(simulations,participants_group_3)\n","output_total_ssq_group_4=merge_total_ssq(simulations,participants_group_4)\n","output_total_ssq_group_5=merge_total_ssq(simulations,participants_group_5)\n","\n","output_total_ssq_group_1=output_total_ssq_group_1.reshape(-1, 1)\n","output_total_ssq_group_2=output_total_ssq_group_2.reshape(-1, 1)\n","output_total_ssq_group_3=output_total_ssq_group_3.reshape(-1, 1)\n","output_total_ssq_group_4=output_total_ssq_group_4.reshape(-1, 1)\n","output_total_ssq_group_5=output_total_ssq_group_5.reshape(-1, 1)\n","\n"],"metadata":{"id":"Giawelxqm4DE","executionInfo":{"status":"ok","timestamp":1726040445165,"user_tz":300,"elapsed":1714,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"],"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1726040445166,"user_tz":300,"elapsed":4,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Input, GRU, Dense, Dropout\n","from keras.models import Model\n","import numpy as np\n","import sklearn\n","from keras.utils import to_categorical\n","\n","total_losses=[]\n","def get_shared_lstm(input_shape1, input_shape2):\n","    # Define shared LSTM model\n","    input_layer = Input(shape=(input_shape1, input_shape2))\n","    x = LSTM(64, return_sequences=False)(input_layer)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    shared_model = Model(inputs=input_layer, outputs=x)\n","    return shared_model\n","\n","def get_output_model(shared_LSTM_output, output_shape):\n","    # Define separate output model for each column\n","    output_models = []\n","    for i in range(output_shape[1]):\n","        x = Dense(256, activation='relu')(shared_LSTM_output)\n","        x = Dropout(0.2)(x)\n","        output = Dense(4, activation='softmax')(x)  # Output shape is (None, 4) for 4 classes\n","        output_models.append(output)\n","    return output_models\n","\n","\n","input_groups = [input_group_1, input_group_2, input_group_3, input_group_4, input_group_5]\n","output_groups = [output_group_1, output_group_2, output_group_3, output_group_4, output_group_5]\n","ssq_groups = [output_total_ssq_group_1, output_total_ssq_group_2, output_total_ssq_group_3, output_total_ssq_group_4, output_total_ssq_group_5]\n","\n","\n","# Specify the number of samples to select for each group in each iteration\n","samples_per_iteration = [\n","    [3, 3, 3, 3, 2],  # For input_group_1\n","    [3, 3, 3, 3, 2],  # For input_group_2\n","    [3, 3, 3, 2, 2],  # For input_group_3\n","    [2, 2, 2, 2, 3],  # For input_group_4\n","    [3, 3, 3, 3, 4]   # For input_group_5\n","]\n","\n","# Initialize a list of global indices arrays, one for each group\n","global_indices = [[] for _ in range(len(input_groups))]\n","print(\"global_indices\",global_indices)\n","\n","# Outer loop to repeat the sampling process for 5 iterations\n","for iteration in range(5):\n","  X_train, X_val, X_test = [], [], []\n","  y_train, y_val, y_test = [], [], []\n","  ssq_train, ssq_val, ssq_test = [], [], []\n","  print(f\"Iteration {iteration + 1}\")\n","  print(\"global_indices\",global_indices)\n","  # Loop over each group\n","  for i, (input_group, output_group, ssq_group) in enumerate(zip(input_groups, output_groups, ssq_groups)):\n","      num_samples = samples_per_iteration[i][iteration]  # Number of samples to select for the current group and iteration\n","\n","      # Create a set of available indices that haven't been selected yet for the current group\n","      available_indices = list(set(range(len(input_group))) - set(global_indices[i]))\n","\n","      # Check if there are fewer available indices than needed\n","      if len(available_indices) < num_samples:\n","          print(f\"Not enough indices left in group {i + 1} to select {num_samples} new samples.\")\n","          num_samples = len(available_indices)  # Adjust to take whatever is left\n","\n","      # Select the required number of samples from the available indices for the current group\n","      selected_indices = np.random.choice(available_indices, num_samples, replace=False)\n","      global_indices[i].extend(selected_indices)  # Add these indices to the group's global list\n","\n","      # Remove these selected samples from the input, output, and SSQ groups\n","      X_test_temp = input_group[selected_indices]\n","      y_test_temp = output_group[selected_indices]\n","      ssq_test_temp = ssq_group[selected_indices]\n","\n","      X_temp = np.delete(input_group, selected_indices, axis=0)\n","      y_temp = np.delete(output_group, selected_indices, axis=0)\n","      ssq_temp = np.delete(ssq_group, selected_indices, axis=0)\n","\n","      # Split the remaining data into a training set (60%) and a validation set (40%)\n","      X_train_temp, X_val_temp, y_train_temp, y_val_temp, ssq_train_temp, ssq_val_temp = train_test_split(\n","          X_temp, y_temp, ssq_temp, test_size=0.2)\n","\n","      # Append the results to the corresponding lists\n","      X_train.append(X_train_temp)\n","      X_val.append(X_val_temp)\n","      X_test.append(X_test_temp)\n","\n","      y_train.append(y_train_temp)\n","      y_val.append(y_val_temp)\n","      y_test.append(y_test_temp)\n","\n","      ssq_train.append(ssq_train_temp)\n","      ssq_val.append(ssq_val_temp)\n","      ssq_test.append(ssq_test_temp)\n","\n","  # After the loop, concatenate the data for all groups if needed\n","  input_train = np.concatenate(X_train, axis=0)\n","  input_val = np.concatenate(X_val, axis=0)\n","  input_test = np.concatenate(X_test, axis=0)\n","\n","  output_train = np.concatenate(y_train, axis=0)\n","  output_val = np.concatenate(y_val, axis=0)\n","  output_test = np.concatenate(y_test, axis=0)\n","\n","  ssq_test = np.concatenate(ssq_test, axis=0)\n","  ssq_val = np.concatenate(ssq_val, axis=0)\n","  output_test_total_ssq = np.concatenate(ssq_test, axis=0)\n","\n","\n","  #  this section for scaling both train and validation set simultaniously\n","  # Step 1: Combine the training and validation sets\n","  combined_input = np.concatenate([input_train, input_val], axis=0)\n","  combined_output = np.concatenate([output_train, output_val], axis=0)\n","\n","  # Step 2: Scale the combined input data\n","  # Assuming scale_input_data scales the data based on the combined dataset\n","  combined_input, input_test = scale_input_data(\n","      combined_input[:, (60-sample_size):(180-sample_size), :],\n","      input_test[:, (60-sample_size):(180-sample_size), :]\n","  )\n","\n","\n","    # Convert the original labels to one-hot encoded format\n","  output_train_encoded = to_categorical(combined_output, num_classes=4)\n","\n","  # Step 4: Split the combined data back into training and validation sets\n","  # Use the original shapes of input_train and input_val to slice the combined arrays\n","  input_train = combined_input[:input_train.shape[0], :, :]\n","  input_val = combined_input[input_train.shape[0]:, :, :]\n","\n","  output_train = output_train_encoded[:output_train.shape[0], :]\n","  output_val = output_train_encoded[output_train.shape[0]:, :]\n","\n","\n","\n","  print(\"input_train :\", input_train.shape)\n","  print(\"output_train :\", output_train.shape)\n","  print(\"input_val :\", input_val.shape)\n","  print(\"output_val :\", output_val.shape)\n","  print(\"input_test :\", input_test.shape)\n","  print(\"output_test :\", output_test.shape)\n","\n","\n","\n","\n","\n","\n","  # Reshape train and test inputs to match GRU input shape\n","  train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","  test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","  val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","  # Get shared LSTM model\n","  shared_lstm = get_shared_lstm(input_train.shape[1], input_train.shape[2])\n","\n","  # Create separate output models for each column\n","  output_models = get_output_model(shared_lstm.output, output_train.shape)\n","\n","  # Create combined model\n","  model = Model(inputs=shared_lstm.input, outputs=output_models)\n","\n","  # Compile and train the model\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[['accuracy'] for _ in range(output_train.shape[1])])\n","\n","  best_val_loss = float('inf')\n","  patience = 0\n","  best_model = None\n","\n","  # Early stopping based on validation loss\n","  for k in range(200):\n","      model.fit(train_input_reshaped, [output_train[:, i] for i in range(output_train.shape[1])], epochs=1, batch_size=32)\n","      pred_val = np.array(model.predict(val_input_reshaped))\n","      pred_val = np.transpose(pred_val.squeeze(), (1, 0, 2))\n","      pred_val = np.argmax(pred_val, axis=-1).reshape(pred_val.shape[:-1])\n","\n","      print(f\"k: {k}, patience: {patience}\")\n","\n","      # Evaluate the model based on SSQ for validation data\n","      losses = []\n","      for i in range(pred_val.shape[0]):\n","          total_ssq = 0\n","          for j in [0, 5, 6, 7, 8, 14, 15]:\n","              total_ssq += np.sum(pred_val[i, j])\n","\n","          for j in [0, 1, 2, 3, 4, 8, 10]:\n","              total_ssq += np.sum(pred_val[i, j])\n","\n","          for j in [4, 7, 9, 10, 11, 12, 13]:\n","              total_ssq += np.sum(pred_val[i, j])\n","\n","          total_ssq *= 3.74\n","          output_val_ssq = ssq_val[i, 0]\n","          loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","          losses.append(loss)\n","\n","      tmp_val_loss = np.mean(losses)\n","      if tmp_val_loss <= best_val_loss:\n","          best_val_loss = tmp_val_loss\n","          patience = 0\n","          best_model = model\n","      else:\n","          patience += 1\n","          if patience > 10:\n","              break\n","\n","  # Predict and evaluate test data using the best model\n","  pred_test = np.array(best_model.predict(test_input_reshaped))\n","  pred_test = np.transpose(pred_test.squeeze(), (1, 0, 2))\n","  pred_test = np.argmax(pred_test, axis=-1).reshape(pred_test.shape[:-1])\n","\n","  pred_total_ssq = []\n","  for i in range(pred_test.shape[0]):\n","      total_ssq = 0\n","      for j in [0, 5, 6, 7, 8, 14, 15]:\n","          total_ssq += np.sum(pred_test[i, j])\n","\n","      for j in [0, 1, 2, 3, 4, 8, 10]:\n","          total_ssq += np.sum(pred_test[i, j])\n","\n","      for j in [4, 7, 9, 10, 11, 12, 13]:\n","          total_ssq += np.sum(pred_test[i, j])\n","\n","      total_ssq *= 3.74\n","      pred_total_ssq.append(total_ssq)\n","\n","  # Overall Test Loss\n","  loss = sklearn.metrics.mean_squared_error(pred_total_ssq, output_test_total_ssq, squared=False)\n","  print(f\"Test Loss iteration {iteration}: {loss}\")\n","  total_losses.append(loss)\n","\n","average_loss = sum(total_losses) / len(total_losses)\n","total_losses.append(average_loss)\n","print(\"average_loss:\", average_loss)"],"metadata":{"id":"E6ssyYUeDJwI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726040578097,"user_tz":300,"elapsed":132934,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"bc297776-0273-45d6-d75f-11209f4a2fed"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["global_indices [[], [], [], [], []]\n","Iteration 1\n","global_indices [[], [], [], [], []]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (13, 120, 47)\n","output_val : (13, 16, 4)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 80ms/step - dense_167_accuracy: 0.1926 - dense_169_accuracy: 0.2205 - dense_171_accuracy: 0.6799 - dense_173_accuracy: 0.1242 - dense_175_accuracy: 0.1126 - dense_177_accuracy: 0.1509 - dense_179_accuracy: 0.1822 - dense_181_accuracy: 0.1021 - dense_183_accuracy: 0.2309 - dense_185_accuracy: 0.6207 - dense_187_accuracy: 0.5036 - dense_189_accuracy: 0.1717 - dense_191_accuracy: 0.4652 - dense_193_accuracy: 0.0429 - dense_195_accuracy: 0.2043 - dense_197_accuracy: 0.0429 - loss: 22.4245\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - dense_167_accuracy: 0.4919 - dense_169_accuracy: 0.8133 - dense_171_accuracy: 0.8770 - dense_173_accuracy: 0.5023 - dense_175_accuracy: 0.5348 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6148 - dense_181_accuracy: 0.5719 - dense_183_accuracy: 0.8770 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.8666 - dense_195_accuracy: 0.5882 - dense_197_accuracy: 0.7866 - loss: 18.8000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - dense_167_accuracy: 0.4281 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8874 - dense_173_accuracy: 0.5719 - dense_175_accuracy: 0.7170 - dense_177_accuracy: 0.8341 - dense_179_accuracy: 0.6044 - dense_181_accuracy: 0.5777 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8549 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7703 - dense_191_accuracy: 0.7215 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.8933 - loss: 15.1285\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - dense_167_accuracy: 0.4060 - dense_169_accuracy: 0.8341 - dense_171_accuracy: 0.8666 - dense_173_accuracy: 0.5719 - dense_175_accuracy: 0.7170 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6148 - dense_181_accuracy: 0.5986 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8133 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.7912 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.9141 - loss: 12.2597\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - dense_167_accuracy: 0.4652 - dense_169_accuracy: 0.8445 - dense_171_accuracy: 0.8874 - dense_173_accuracy: 0.5823 - dense_175_accuracy: 0.7378 - dense_177_accuracy: 0.8341 - dense_179_accuracy: 0.6461 - dense_181_accuracy: 0.5882 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.7912 - dense_191_accuracy: 0.7007 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.9141 - loss: 11.8939\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - dense_167_accuracy: 0.5081 - dense_169_accuracy: 0.8445 - dense_171_accuracy: 0.8666 - dense_173_accuracy: 0.5081 - dense_175_accuracy: 0.7378 - dense_177_accuracy: 0.8341 - dense_179_accuracy: 0.5940 - dense_181_accuracy: 0.5673 - dense_183_accuracy: 0.8445 - dense_185_accuracy: 0.8133 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7007 - dense_193_accuracy: 0.9408 - dense_195_accuracy: 0.5673 - dense_197_accuracy: 0.9037 - loss: 12.3027\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - dense_167_accuracy: 0.3526 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8666 - dense_173_accuracy: 0.4444 - dense_175_accuracy: 0.7274 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6148 - dense_181_accuracy: 0.5777 - dense_183_accuracy: 0.8133 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7912 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.8933 - loss: 12.2318\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - dense_167_accuracy: 0.4593 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8666 - dense_173_accuracy: 0.5244 - dense_175_accuracy: 0.7170 - dense_177_accuracy: 0.8133 - dense_179_accuracy: 0.5940 - dense_181_accuracy: 0.5673 - dense_183_accuracy: 0.8133 - dense_185_accuracy: 0.8133 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7007 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5673 - dense_197_accuracy: 0.9037 - loss: 11.9771\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","k: 7, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - dense_167_accuracy: 0.3051 - dense_169_accuracy: 0.8133 - dense_171_accuracy: 0.8874 - dense_173_accuracy: 0.4756 - dense_175_accuracy: 0.7170 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6194 - dense_181_accuracy: 0.5986 - dense_183_accuracy: 0.8133 - dense_185_accuracy: 0.8445 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.6090 - dense_197_accuracy: 0.9037 - loss: 11.4882\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 8, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - dense_167_accuracy: 0.3689 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8770 - dense_173_accuracy: 0.4444 - dense_175_accuracy: 0.7482 - dense_177_accuracy: 0.8133 - dense_179_accuracy: 0.6044 - dense_181_accuracy: 0.6044 - dense_183_accuracy: 0.8341 - dense_185_accuracy: 0.8237 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7703 - dense_191_accuracy: 0.6903 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5673 - dense_197_accuracy: 0.8933 - loss: 11.4039\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 9, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - dense_167_accuracy: 0.3689 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8770 - dense_173_accuracy: 0.4977 - dense_175_accuracy: 0.7274 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.5882 - dense_181_accuracy: 0.5882 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.9037 - loss: 11.3156\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 10, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - dense_167_accuracy: 0.3956 - dense_169_accuracy: 0.8341 - dense_171_accuracy: 0.8874 - dense_173_accuracy: 0.5081 - dense_175_accuracy: 0.7378 - dense_177_accuracy: 0.8445 - dense_179_accuracy: 0.6148 - dense_181_accuracy: 0.5777 - dense_183_accuracy: 0.8341 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.5986 - dense_197_accuracy: 0.9245 - loss: 10.8490\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 11, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - dense_167_accuracy: 0.5290 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8770 - dense_173_accuracy: 0.5882 - dense_175_accuracy: 0.7274 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6357 - dense_181_accuracy: 0.6090 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.8120 - dense_191_accuracy: 0.7424 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.6090 - dense_197_accuracy: 0.9141 - loss: 10.5391\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","k: 12, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - dense_167_accuracy: 0.5719 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8874 - dense_173_accuracy: 0.5511 - dense_175_accuracy: 0.7274 - dense_177_accuracy: 0.8341 - dense_179_accuracy: 0.6357 - dense_181_accuracy: 0.6090 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8341 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7320 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5986 - dense_197_accuracy: 0.9037 - loss: 10.8128\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 13, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_167_accuracy: 0.4385 - dense_169_accuracy: 0.8341 - dense_171_accuracy: 0.8979 - dense_173_accuracy: 0.5719 - dense_175_accuracy: 0.7274 - dense_177_accuracy: 0.8341 - dense_179_accuracy: 0.6044 - dense_181_accuracy: 0.5882 - dense_183_accuracy: 0.8341 - dense_185_accuracy: 0.8549 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.7912 - dense_191_accuracy: 0.7215 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.5882 - dense_197_accuracy: 0.9037 - loss: 10.3683\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 14, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - dense_167_accuracy: 0.4652 - dense_169_accuracy: 0.8237 - dense_171_accuracy: 0.8666 - dense_173_accuracy: 0.5719 - dense_175_accuracy: 0.7274 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.5940 - dense_181_accuracy: 0.5882 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8237 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7912 - dense_191_accuracy: 0.7007 - dense_193_accuracy: 0.9304 - dense_195_accuracy: 0.5882 - dense_197_accuracy: 0.8933 - loss: 10.9620\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 15, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - dense_167_accuracy: 0.4652 - dense_169_accuracy: 0.8133 - dense_171_accuracy: 0.8770 - dense_173_accuracy: 0.5823 - dense_175_accuracy: 0.7170 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6148 - dense_181_accuracy: 0.5882 - dense_183_accuracy: 0.8133 - dense_185_accuracy: 0.8445 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7807 - dense_191_accuracy: 0.7111 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.8933 - loss: 10.6410\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 16, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - dense_167_accuracy: 0.5348 - dense_169_accuracy: 0.8549 - dense_171_accuracy: 0.8770 - dense_173_accuracy: 0.5986 - dense_175_accuracy: 0.7586 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6148 - dense_181_accuracy: 0.5986 - dense_183_accuracy: 0.8341 - dense_185_accuracy: 0.8237 - dense_187_accuracy: 0.9571 - dense_189_accuracy: 0.8016 - dense_191_accuracy: 0.7215 - dense_193_accuracy: 0.9408 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.9037 - loss: 10.2817\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 17, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - dense_167_accuracy: 0.4815 - dense_169_accuracy: 0.8133 - dense_171_accuracy: 0.8666 - dense_173_accuracy: 0.6786 - dense_175_accuracy: 0.7066 - dense_177_accuracy: 0.8237 - dense_179_accuracy: 0.6044 - dense_181_accuracy: 0.5673 - dense_183_accuracy: 0.8237 - dense_185_accuracy: 0.8237 - dense_187_accuracy: 0.9466 - dense_189_accuracy: 0.7703 - dense_191_accuracy: 0.6903 - dense_193_accuracy: 0.9200 - dense_195_accuracy: 0.5777 - dense_197_accuracy: 0.9037 - loss: 10.7070\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 18, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n","Test Loss iteration 0: 33.286900469360965\n","Iteration 2\n","global_indices [[4, 13, 3], [8, 1, 5], [10, 1, 7], [3, 4], [15, 14, 0]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (13, 120, 47)\n","output_val : (13, 16, 4)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 80ms/step - dense_200_accuracy: 0.2088 - dense_202_accuracy: 0.1451 - dense_204_accuracy: 0.2530 - dense_206_accuracy: 0.2251 - dense_208_accuracy: 0.1717 - dense_210_accuracy: 0.3643 - dense_212_accuracy: 0.4756 - dense_214_accuracy: 0.2147 - dense_216_accuracy: 0.3110 - dense_218_accuracy: 0.1080 - dense_220_accuracy: 0.2205 - dense_222_accuracy: 0.0534 - dense_224_accuracy: 0.3110 - dense_226_accuracy: 0.1405 - dense_228_accuracy: 0.2518 - dense_230_accuracy: 0.2635 - loss: 22.3241\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - dense_200_accuracy: 0.4815 - dense_202_accuracy: 0.7378 - dense_204_accuracy: 0.9466 - dense_206_accuracy: 0.6474 - dense_208_accuracy: 0.6044 - dense_210_accuracy: 0.7703 - dense_212_accuracy: 0.5511 - dense_214_accuracy: 0.5882 - dense_216_accuracy: 0.8399 - dense_218_accuracy: 0.8133 - dense_220_accuracy: 0.8666 - dense_222_accuracy: 0.6474 - dense_224_accuracy: 0.5940 - dense_226_accuracy: 0.8666 - dense_228_accuracy: 0.4710 - dense_230_accuracy: 0.9037 - loss: 18.8320\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - dense_200_accuracy: 0.4873 - dense_202_accuracy: 0.7332 - dense_204_accuracy: 0.9466 - dense_206_accuracy: 0.6474 - dense_208_accuracy: 0.7436 - dense_210_accuracy: 0.7599 - dense_212_accuracy: 0.5302 - dense_214_accuracy: 0.5569 - dense_216_accuracy: 0.8504 - dense_218_accuracy: 0.8874 - dense_220_accuracy: 0.8933 - dense_222_accuracy: 0.7111 - dense_224_accuracy: 0.6740 - dense_226_accuracy: 0.8666 - dense_228_accuracy: 0.5081 - dense_230_accuracy: 0.9304 - loss: 15.0478\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - dense_200_accuracy: 0.3852 - dense_202_accuracy: 0.7541 - dense_204_accuracy: 0.9466 - dense_206_accuracy: 0.6578 - dense_208_accuracy: 0.7541 - dense_210_accuracy: 0.7912 - dense_212_accuracy: 0.5615 - dense_214_accuracy: 0.5882 - dense_216_accuracy: 0.8504 - dense_218_accuracy: 0.8666 - dense_220_accuracy: 0.9037 - dense_222_accuracy: 0.7215 - dense_224_accuracy: 0.6845 - dense_226_accuracy: 0.8770 - dense_228_accuracy: 0.4815 - dense_230_accuracy: 0.9200 - loss: 12.0472\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - dense_200_accuracy: 0.4977 - dense_202_accuracy: 0.7541 - dense_204_accuracy: 0.9571 - dense_206_accuracy: 0.6474 - dense_208_accuracy: 0.7541 - dense_210_accuracy: 0.7703 - dense_212_accuracy: 0.5615 - dense_214_accuracy: 0.5882 - dense_216_accuracy: 0.8504 - dense_218_accuracy: 0.8770 - dense_220_accuracy: 0.9037 - dense_222_accuracy: 0.7007 - dense_224_accuracy: 0.6740 - dense_226_accuracy: 0.8666 - dense_228_accuracy: 0.4815 - dense_230_accuracy: 0.9200 - loss: 11.8525\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - dense_200_accuracy: 0.4489 - dense_202_accuracy: 0.7541 - dense_204_accuracy: 0.9571 - dense_206_accuracy: 0.6786 - dense_208_accuracy: 0.7645 - dense_210_accuracy: 0.7599 - dense_212_accuracy: 0.5615 - dense_214_accuracy: 0.5777 - dense_216_accuracy: 0.8504 - dense_218_accuracy: 0.8770 - dense_220_accuracy: 0.8933 - dense_222_accuracy: 0.7007 - dense_224_accuracy: 0.6636 - dense_226_accuracy: 0.8770 - dense_228_accuracy: 0.4652 - dense_230_accuracy: 0.9304 - loss: 12.5281\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - dense_200_accuracy: 0.4177 - dense_202_accuracy: 0.7541 - dense_204_accuracy: 0.9571 - dense_206_accuracy: 0.6207 - dense_208_accuracy: 0.7436 - dense_210_accuracy: 0.7807 - dense_212_accuracy: 0.5511 - dense_214_accuracy: 0.5777 - dense_216_accuracy: 0.8608 - dense_218_accuracy: 0.8770 - dense_220_accuracy: 0.8933 - dense_222_accuracy: 0.7007 - dense_224_accuracy: 0.6740 - dense_226_accuracy: 0.8666 - dense_228_accuracy: 0.4548 - dense_230_accuracy: 0.9200 - loss: 11.9234\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - dense_200_accuracy: 0.4073 - dense_202_accuracy: 0.7436 - dense_204_accuracy: 0.9571 - dense_206_accuracy: 0.6474 - dense_208_accuracy: 0.7436 - dense_210_accuracy: 0.7807 - dense_212_accuracy: 0.5719 - dense_214_accuracy: 0.5673 - dense_216_accuracy: 0.8504 - dense_218_accuracy: 0.8770 - dense_220_accuracy: 0.8933 - dense_222_accuracy: 0.7111 - dense_224_accuracy: 0.6636 - dense_226_accuracy: 0.8770 - dense_228_accuracy: 0.4919 - dense_230_accuracy: 0.9304 - loss: 11.4115\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 7, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - dense_200_accuracy: 0.4815 - dense_202_accuracy: 0.7436 - dense_204_accuracy: 0.9571 - dense_206_accuracy: 0.6415 - dense_208_accuracy: 0.7541 - dense_210_accuracy: 0.7807 - dense_212_accuracy: 0.5882 - dense_214_accuracy: 0.5348 - dense_216_accuracy: 0.8504 - dense_218_accuracy: 0.8770 - dense_220_accuracy: 0.9037 - dense_222_accuracy: 0.7007 - dense_224_accuracy: 0.6636 - dense_226_accuracy: 0.8874 - dense_228_accuracy: 0.4281 - dense_230_accuracy: 0.9408 - loss: 10.6967\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 8, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - dense_200_accuracy: 0.4919 - dense_202_accuracy: 0.7853 - dense_204_accuracy: 0.9466 - dense_206_accuracy: 0.6044 - dense_208_accuracy: 0.7749 - dense_210_accuracy: 0.8016 - dense_212_accuracy: 0.5882 - dense_214_accuracy: 0.6253 - dense_216_accuracy: 0.8608 - dense_218_accuracy: 0.8770 - dense_220_accuracy: 0.9141 - dense_222_accuracy: 0.6903 - dense_224_accuracy: 0.6740 - dense_226_accuracy: 0.8770 - dense_228_accuracy: 0.4919 - dense_230_accuracy: 0.9200 - loss: 10.5565\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 9, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - dense_200_accuracy: 0.4756 - dense_202_accuracy: 0.7541 - dense_204_accuracy: 0.9466 - dense_206_accuracy: 0.6682 - dense_208_accuracy: 0.7645 - dense_210_accuracy: 0.7807 - dense_212_accuracy: 0.6148 - dense_214_accuracy: 0.5986 - dense_216_accuracy: 0.8608 - dense_218_accuracy: 0.8874 - dense_220_accuracy: 0.9037 - dense_222_accuracy: 0.7215 - dense_224_accuracy: 0.7053 - dense_226_accuracy: 0.8770 - dense_228_accuracy: 0.4652 - dense_230_accuracy: 0.9304 - loss: 10.4705\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","k: 10, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - dense_200_accuracy: 0.4710 - dense_202_accuracy: 0.7541 - dense_204_accuracy: 0.9675 - dense_206_accuracy: 0.6740 - dense_208_accuracy: 0.7541 - dense_210_accuracy: 0.7807 - dense_212_accuracy: 0.5452 - dense_214_accuracy: 0.5986 - dense_216_accuracy: 0.8399 - dense_218_accuracy: 0.8874 - dense_220_accuracy: 0.8933 - dense_222_accuracy: 0.6903 - dense_224_accuracy: 0.6845 - dense_226_accuracy: 0.8874 - dense_228_accuracy: 0.5615 - dense_230_accuracy: 0.9200 - loss: 10.5948\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 11, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449ms/step\n","Test Loss iteration 1: 57.193532601410205\n","Iteration 3\n","global_indices [[4, 13, 3, 8, 11, 6], [8, 1, 5, 6, 2, 10], [10, 1, 7, 5, 6, 9], [3, 4, 10, 7], [15, 14, 0, 8, 10, 4]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (13, 120, 47)\n","output_val : (13, 16, 4)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 120ms/step - dense_233_accuracy: 0.2147 - dense_235_accuracy: 0.3910 - dense_237_accuracy: 0.4131 - dense_239_accuracy: 0.2843 - dense_241_accuracy: 0.3481 - dense_243_accuracy: 0.0534 - dense_245_accuracy: 0.2889 - dense_247_accuracy: 0.0800 - dense_249_accuracy: 0.3214 - dense_251_accuracy: 0.1880 - dense_253_accuracy: 0.1347 - dense_255_accuracy: 0.3539 - dense_257_accuracy: 0.0917 - dense_259_accuracy: 0.1347 - dense_261_accuracy: 0.2414 - dense_263_accuracy: 0.0963 - loss: 22.6583\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - dense_233_accuracy: 0.5556 - dense_235_accuracy: 0.7320 - dense_237_accuracy: 0.9200 - dense_239_accuracy: 0.6578 - dense_241_accuracy: 0.6682 - dense_243_accuracy: 0.6148 - dense_245_accuracy: 0.5765 - dense_247_accuracy: 0.3051 - dense_249_accuracy: 0.7541 - dense_251_accuracy: 0.8666 - dense_253_accuracy: 0.8178 - dense_255_accuracy: 0.8178 - dense_257_accuracy: 0.7912 - dense_259_accuracy: 0.7807 - dense_261_accuracy: 0.6357 - dense_263_accuracy: 0.8608 - loss: 18.9890\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - dense_233_accuracy: 0.5348 - dense_235_accuracy: 0.7111 - dense_237_accuracy: 0.9408 - dense_239_accuracy: 0.6415 - dense_241_accuracy: 0.6845 - dense_243_accuracy: 0.8178 - dense_245_accuracy: 0.5511 - dense_247_accuracy: 0.6415 - dense_249_accuracy: 0.7645 - dense_251_accuracy: 0.8979 - dense_253_accuracy: 0.8770 - dense_255_accuracy: 0.8074 - dense_257_accuracy: 0.8283 - dense_259_accuracy: 0.8237 - dense_261_accuracy: 0.6148 - dense_263_accuracy: 0.8666 - loss: 15.2046\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - dense_233_accuracy: 0.5452 - dense_235_accuracy: 0.7215 - dense_237_accuracy: 0.9304 - dense_239_accuracy: 0.6415 - dense_241_accuracy: 0.6740 - dense_243_accuracy: 0.8074 - dense_245_accuracy: 0.5511 - dense_247_accuracy: 0.6311 - dense_249_accuracy: 0.7541 - dense_251_accuracy: 0.8874 - dense_253_accuracy: 0.8979 - dense_255_accuracy: 0.8074 - dense_257_accuracy: 0.8074 - dense_259_accuracy: 0.8445 - dense_261_accuracy: 0.5940 - dense_263_accuracy: 0.8770 - loss: 12.8253\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - dense_233_accuracy: 0.5348 - dense_235_accuracy: 0.7111 - dense_237_accuracy: 0.9408 - dense_239_accuracy: 0.6519 - dense_241_accuracy: 0.6845 - dense_243_accuracy: 0.7970 - dense_245_accuracy: 0.5511 - dense_247_accuracy: 0.6311 - dense_249_accuracy: 0.7541 - dense_251_accuracy: 0.8874 - dense_253_accuracy: 0.8666 - dense_255_accuracy: 0.7866 - dense_257_accuracy: 0.7970 - dense_259_accuracy: 0.8133 - dense_261_accuracy: 0.6044 - dense_263_accuracy: 0.8770 - loss: 12.3197\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - dense_233_accuracy: 0.5348 - dense_235_accuracy: 0.6799 - dense_237_accuracy: 0.9304 - dense_239_accuracy: 0.6311 - dense_241_accuracy: 0.6845 - dense_243_accuracy: 0.8074 - dense_245_accuracy: 0.5823 - dense_247_accuracy: 0.6415 - dense_249_accuracy: 0.7436 - dense_251_accuracy: 0.8770 - dense_253_accuracy: 0.8666 - dense_255_accuracy: 0.7970 - dense_257_accuracy: 0.7970 - dense_259_accuracy: 0.8237 - dense_261_accuracy: 0.6148 - dense_263_accuracy: 0.8874 - loss: 12.6032\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - dense_233_accuracy: 0.5290 - dense_235_accuracy: 0.7111 - dense_237_accuracy: 0.9304 - dense_239_accuracy: 0.6311 - dense_241_accuracy: 0.6636 - dense_243_accuracy: 0.7970 - dense_245_accuracy: 0.5511 - dense_247_accuracy: 0.6311 - dense_249_accuracy: 0.7332 - dense_251_accuracy: 0.8770 - dense_253_accuracy: 0.8666 - dense_255_accuracy: 0.7866 - dense_257_accuracy: 0.7866 - dense_259_accuracy: 0.8237 - dense_261_accuracy: 0.6148 - dense_263_accuracy: 0.8874 - loss: 12.8721\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - dense_233_accuracy: 0.4548 - dense_235_accuracy: 0.6903 - dense_237_accuracy: 0.9304 - dense_239_accuracy: 0.5777 - dense_241_accuracy: 0.7215 - dense_243_accuracy: 0.7970 - dense_245_accuracy: 0.5511 - dense_247_accuracy: 0.6311 - dense_249_accuracy: 0.7541 - dense_251_accuracy: 0.8770 - dense_253_accuracy: 0.8666 - dense_255_accuracy: 0.7970 - dense_257_accuracy: 0.7970 - dense_259_accuracy: 0.8133 - dense_261_accuracy: 0.6148 - dense_263_accuracy: 0.8874 - loss: 11.8870\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","k: 7, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - dense_233_accuracy: 0.4756 - dense_235_accuracy: 0.7007 - dense_237_accuracy: 0.9304 - dense_239_accuracy: 0.5719 - dense_241_accuracy: 0.6682 - dense_243_accuracy: 0.8074 - dense_245_accuracy: 0.5511 - dense_247_accuracy: 0.6311 - dense_249_accuracy: 0.7645 - dense_251_accuracy: 0.8770 - dense_253_accuracy: 0.8666 - dense_255_accuracy: 0.8074 - dense_257_accuracy: 0.8178 - dense_259_accuracy: 0.8341 - dense_261_accuracy: 0.6253 - dense_263_accuracy: 0.8770 - loss: 11.7893\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 8, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - dense_233_accuracy: 0.5185 - dense_235_accuracy: 0.7215 - dense_237_accuracy: 0.9200 - dense_239_accuracy: 0.5673 - dense_241_accuracy: 0.7007 - dense_243_accuracy: 0.7970 - dense_245_accuracy: 0.5882 - dense_247_accuracy: 0.6207 - dense_249_accuracy: 0.7541 - dense_251_accuracy: 0.8770 - dense_253_accuracy: 0.8874 - dense_255_accuracy: 0.8178 - dense_257_accuracy: 0.8074 - dense_259_accuracy: 0.8237 - dense_261_accuracy: 0.5673 - dense_263_accuracy: 0.8666 - loss: 11.8158\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 9, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - dense_233_accuracy: 0.5452 - dense_235_accuracy: 0.7007 - dense_237_accuracy: 0.9200 - dense_239_accuracy: 0.6415 - dense_241_accuracy: 0.6949 - dense_243_accuracy: 0.8074 - dense_245_accuracy: 0.5394 - dense_247_accuracy: 0.6415 - dense_249_accuracy: 0.7541 - dense_251_accuracy: 0.8874 - dense_253_accuracy: 0.8770 - dense_255_accuracy: 0.8178 - dense_257_accuracy: 0.8178 - dense_259_accuracy: 0.8341 - dense_261_accuracy: 0.5777 - dense_263_accuracy: 0.8666 - loss: 11.7145\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 10, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - dense_233_accuracy: 0.5348 - dense_235_accuracy: 0.7215 - dense_237_accuracy: 0.9200 - dense_239_accuracy: 0.6207 - dense_241_accuracy: 0.6949 - dense_243_accuracy: 0.8074 - dense_245_accuracy: 0.5615 - dense_247_accuracy: 0.6311 - dense_249_accuracy: 0.7749 - dense_251_accuracy: 0.8666 - dense_253_accuracy: 0.8770 - dense_255_accuracy: 0.8074 - dense_257_accuracy: 0.7970 - dense_259_accuracy: 0.8237 - dense_261_accuracy: 0.6044 - dense_263_accuracy: 0.8770 - loss: 11.5293\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","k: 11, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457ms/step\n","Test Loss iteration 2: 36.834728178717434\n","Iteration 4\n","global_indices [[4, 13, 3, 8, 11, 6, 1, 2, 7], [8, 1, 5, 6, 2, 10, 12, 13, 3], [10, 1, 7, 5, 6, 9, 0, 2, 8], [3, 4, 10, 7, 0, 8], [15, 14, 0, 8, 10, 4, 3, 9, 13]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (14, 120, 47)\n","output_val : (14, 16, 4)\n","input_test : (13, 120, 47)\n","output_test : (13, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - dense_266_accuracy: 0.0963 - dense_268_accuracy: 0.0859 - dense_270_accuracy: 0.4606 - dense_272_accuracy: 0.2088 - dense_274_accuracy: 0.6474 - dense_276_accuracy: 0.3006 - dense_278_accuracy: 0.1288 - dense_280_accuracy: 0.0650 - dense_282_accuracy: 0.1080 - dense_284_accuracy: 0.1613 - dense_286_accuracy: 0.2205 - dense_288_accuracy: 0.4502 - dense_290_accuracy: 0.2843 - dense_292_accuracy: 0.0917 - dense_294_accuracy: 0.2726 - dense_296_accuracy: 0.4177 - loss: 22.4554\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - dense_266_accuracy: 0.2622 - dense_268_accuracy: 0.6636 - dense_270_accuracy: 0.9141 - dense_272_accuracy: 0.5348 - dense_274_accuracy: 0.7541 - dense_276_accuracy: 0.8133 - dense_278_accuracy: 0.6311 - dense_280_accuracy: 0.5719 - dense_282_accuracy: 0.8074 - dense_284_accuracy: 0.8504 - dense_286_accuracy: 0.9200 - dense_288_accuracy: 0.7436 - dense_290_accuracy: 0.7007 - dense_292_accuracy: 0.8504 - dense_294_accuracy: 0.5185 - dense_296_accuracy: 0.8608 - loss: 18.9214\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - dense_266_accuracy: 0.4652 - dense_268_accuracy: 0.7541 - dense_270_accuracy: 0.8933 - dense_272_accuracy: 0.6578 - dense_274_accuracy: 0.7436 - dense_276_accuracy: 0.8237 - dense_278_accuracy: 0.6311 - dense_280_accuracy: 0.6044 - dense_282_accuracy: 0.8341 - dense_284_accuracy: 0.8399 - dense_286_accuracy: 0.9304 - dense_288_accuracy: 0.7541 - dense_290_accuracy: 0.7007 - dense_292_accuracy: 0.8504 - dense_294_accuracy: 0.5185 - dense_296_accuracy: 0.8608 - loss: 15.0487\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 2, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - dense_266_accuracy: 0.4815 - dense_268_accuracy: 0.7749 - dense_270_accuracy: 0.8933 - dense_272_accuracy: 0.6474 - dense_274_accuracy: 0.7749 - dense_276_accuracy: 0.8133 - dense_278_accuracy: 0.6207 - dense_280_accuracy: 0.6148 - dense_282_accuracy: 0.8341 - dense_284_accuracy: 0.8399 - dense_286_accuracy: 0.9200 - dense_288_accuracy: 0.7332 - dense_290_accuracy: 0.7007 - dense_292_accuracy: 0.8608 - dense_294_accuracy: 0.4873 - dense_296_accuracy: 0.8504 - loss: 12.4900\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 3, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - dense_266_accuracy: 0.4756 - dense_268_accuracy: 0.7645 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.6474 - dense_274_accuracy: 0.7541 - dense_276_accuracy: 0.8549 - dense_278_accuracy: 0.6623 - dense_280_accuracy: 0.6253 - dense_282_accuracy: 0.8445 - dense_284_accuracy: 0.8608 - dense_286_accuracy: 0.9408 - dense_288_accuracy: 0.7645 - dense_290_accuracy: 0.7111 - dense_292_accuracy: 0.8608 - dense_294_accuracy: 0.5081 - dense_296_accuracy: 0.8608 - loss: 12.4523\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 4, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - dense_266_accuracy: 0.4815 - dense_268_accuracy: 0.7645 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.6786 - dense_274_accuracy: 0.7853 - dense_276_accuracy: 0.8445 - dense_278_accuracy: 0.6623 - dense_280_accuracy: 0.6148 - dense_282_accuracy: 0.8549 - dense_284_accuracy: 0.8608 - dense_286_accuracy: 0.9512 - dense_288_accuracy: 0.7853 - dense_290_accuracy: 0.7320 - dense_292_accuracy: 0.8712 - dense_294_accuracy: 0.5394 - dense_296_accuracy: 0.8816 - loss: 11.7950\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 5, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - dense_266_accuracy: 0.5023 - dense_268_accuracy: 0.7541 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.6578 - dense_274_accuracy: 0.7332 - dense_276_accuracy: 0.8133 - dense_278_accuracy: 0.5998 - dense_280_accuracy: 0.5673 - dense_282_accuracy: 0.8237 - dense_284_accuracy: 0.8504 - dense_286_accuracy: 0.9200 - dense_288_accuracy: 0.7436 - dense_290_accuracy: 0.6903 - dense_292_accuracy: 0.8504 - dense_294_accuracy: 0.4815 - dense_296_accuracy: 0.8399 - loss: 12.4698\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 6, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - dense_266_accuracy: 0.5185 - dense_268_accuracy: 0.7541 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.6148 - dense_274_accuracy: 0.7541 - dense_276_accuracy: 0.8133 - dense_278_accuracy: 0.6207 - dense_280_accuracy: 0.5836 - dense_282_accuracy: 0.8237 - dense_284_accuracy: 0.8504 - dense_286_accuracy: 0.9200 - dense_288_accuracy: 0.7541 - dense_290_accuracy: 0.6578 - dense_292_accuracy: 0.8399 - dense_294_accuracy: 0.4710 - dense_296_accuracy: 0.8608 - loss: 11.6862\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 7, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - dense_266_accuracy: 0.4756 - dense_268_accuracy: 0.7749 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.6682 - dense_274_accuracy: 0.7645 - dense_276_accuracy: 0.8445 - dense_278_accuracy: 0.6415 - dense_280_accuracy: 0.6519 - dense_282_accuracy: 0.8341 - dense_284_accuracy: 0.8608 - dense_286_accuracy: 0.9408 - dense_288_accuracy: 0.7645 - dense_290_accuracy: 0.6890 - dense_292_accuracy: 0.8608 - dense_294_accuracy: 0.4919 - dense_296_accuracy: 0.8608 - loss: 10.9986\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 8, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - dense_266_accuracy: 0.4489 - dense_268_accuracy: 0.7645 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.7111 - dense_274_accuracy: 0.7541 - dense_276_accuracy: 0.8237 - dense_278_accuracy: 0.6311 - dense_280_accuracy: 0.6148 - dense_282_accuracy: 0.8237 - dense_284_accuracy: 0.8399 - dense_286_accuracy: 0.9200 - dense_288_accuracy: 0.7436 - dense_290_accuracy: 0.6207 - dense_292_accuracy: 0.8399 - dense_294_accuracy: 0.4385 - dense_296_accuracy: 0.8504 - loss: 11.6627\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 9, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - dense_266_accuracy: 0.4919 - dense_268_accuracy: 0.7541 - dense_270_accuracy: 0.9037 - dense_272_accuracy: 0.6519 - dense_274_accuracy: 0.7436 - dense_276_accuracy: 0.8133 - dense_278_accuracy: 0.6207 - dense_280_accuracy: 0.5940 - dense_282_accuracy: 0.8133 - dense_284_accuracy: 0.8504 - dense_286_accuracy: 0.9200 - dense_288_accuracy: 0.7645 - dense_290_accuracy: 0.6636 - dense_292_accuracy: 0.8504 - dense_294_accuracy: 0.5244 - dense_296_accuracy: 0.8399 - loss: 11.6011\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 10, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - dense_266_accuracy: 0.4652 - dense_268_accuracy: 0.7645 - dense_270_accuracy: 0.9141 - dense_272_accuracy: 0.6578 - dense_274_accuracy: 0.7749 - dense_276_accuracy: 0.8445 - dense_278_accuracy: 0.6519 - dense_280_accuracy: 0.6148 - dense_282_accuracy: 0.8445 - dense_284_accuracy: 0.8608 - dense_286_accuracy: 0.9408 - dense_288_accuracy: 0.7645 - dense_290_accuracy: 0.7215 - dense_292_accuracy: 0.8608 - dense_294_accuracy: 0.5185 - dense_296_accuracy: 0.8608 - loss: 10.9166\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 11, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/step\n","Test Loss iteration 3: 40.692955731352896\n","Iteration 5\n","global_indices [[4, 13, 3, 8, 11, 6, 1, 2, 7, 0, 5, 10], [8, 1, 5, 6, 2, 10, 12, 13, 3, 11, 7, 4], [10, 1, 7, 5, 6, 9, 0, 2, 8, 11, 3], [3, 4, 10, 7, 0, 8, 5, 6], [15, 14, 0, 8, 10, 4, 3, 9, 13, 1, 5, 12]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16, 4)\n","input_val : (14, 120, 47)\n","output_val : (14, 16, 4)\n","input_test : (13, 120, 47)\n","output_test : (13, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - dense_299_accuracy: 0.3956 - dense_301_accuracy: 0.1659 - dense_303_accuracy: 0.3806 - dense_305_accuracy: 0.4385 - dense_307_accuracy: 0.0976 - dense_309_accuracy: 0.0917 - dense_311_accuracy: 0.4385 - dense_313_accuracy: 0.2680 - dense_315_accuracy: 0.3051 - dense_317_accuracy: 0.2739 - dense_319_accuracy: 0.9304 - dense_321_accuracy: 0.6532 - dense_323_accuracy: 0.1613 - dense_325_accuracy: 0.1717 - dense_327_accuracy: 0.1347 - dense_329_accuracy: 0.1405 - loss: 21.8720\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step\n","k: 0, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - dense_299_accuracy: 0.5394 - dense_301_accuracy: 0.7482 - dense_303_accuracy: 0.9304 - dense_305_accuracy: 0.6357 - dense_307_accuracy: 0.7378 - dense_309_accuracy: 0.8341 - dense_311_accuracy: 0.6311 - dense_313_accuracy: 0.6311 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.6903 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5452 - dense_329_accuracy: 0.8770 - loss: 18.0170\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 1, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - dense_299_accuracy: 0.5140 - dense_301_accuracy: 0.7170 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.6311 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6103 - dense_313_accuracy: 0.6265 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.7066 - dense_325_accuracy: 0.8504 - dense_327_accuracy: 0.5198 - dense_329_accuracy: 0.8666 - loss: 13.9007\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 2, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - dense_299_accuracy: 0.5185 - dense_301_accuracy: 0.7378 - dense_303_accuracy: 0.9304 - dense_305_accuracy: 0.6519 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8341 - dense_311_accuracy: 0.6311 - dense_313_accuracy: 0.6474 - dense_315_accuracy: 0.7912 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.7866 - dense_323_accuracy: 0.7170 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5615 - dense_329_accuracy: 0.8770 - loss: 11.6855\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 3, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - dense_299_accuracy: 0.5394 - dense_301_accuracy: 0.7378 - dense_303_accuracy: 0.9304 - dense_305_accuracy: 0.6519 - dense_307_accuracy: 0.7170 - dense_309_accuracy: 0.8237 - dense_311_accuracy: 0.6519 - dense_313_accuracy: 0.6786 - dense_315_accuracy: 0.7599 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.7378 - dense_325_accuracy: 0.8399 - dense_327_accuracy: 0.5615 - dense_329_accuracy: 0.8770 - loss: 12.3834\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 4, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - dense_299_accuracy: 0.5407 - dense_301_accuracy: 0.7378 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.6786 - dense_307_accuracy: 0.7378 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6207 - dense_313_accuracy: 0.6578 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.8074 - dense_323_accuracy: 0.7170 - dense_325_accuracy: 0.8504 - dense_327_accuracy: 0.5511 - dense_329_accuracy: 0.8666 - loss: 12.2024\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 5, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - dense_299_accuracy: 0.4548 - dense_301_accuracy: 0.7274 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.6415 - dense_307_accuracy: 0.7436 - dense_309_accuracy: 0.8237 - dense_311_accuracy: 0.6474 - dense_313_accuracy: 0.6474 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.7274 - dense_325_accuracy: 0.8504 - dense_327_accuracy: 0.5511 - dense_329_accuracy: 0.8874 - loss: 11.5854\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 6, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - dense_299_accuracy: 0.5185 - dense_301_accuracy: 0.7332 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.5081 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6207 - dense_313_accuracy: 0.6369 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.7866 - dense_323_accuracy: 0.7066 - dense_325_accuracy: 0.8504 - dense_327_accuracy: 0.5407 - dense_329_accuracy: 0.8770 - loss: 11.2390\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","k: 7, patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - dense_299_accuracy: 0.4489 - dense_301_accuracy: 0.7586 - dense_303_accuracy: 0.9304 - dense_305_accuracy: 0.6682 - dense_307_accuracy: 0.7645 - dense_309_accuracy: 0.8341 - dense_311_accuracy: 0.6845 - dense_313_accuracy: 0.6311 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9408 - dense_319_accuracy: 0.9245 - dense_321_accuracy: 0.8074 - dense_323_accuracy: 0.7274 - dense_325_accuracy: 0.8712 - dense_327_accuracy: 0.5615 - dense_329_accuracy: 0.8874 - loss: 10.3444\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 8, patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - dense_299_accuracy: 0.5882 - dense_301_accuracy: 0.7436 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.6740 - dense_307_accuracy: 0.7170 - dense_309_accuracy: 0.8237 - dense_311_accuracy: 0.7111 - dense_313_accuracy: 0.6474 - dense_315_accuracy: 0.7703 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.7274 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5511 - dense_329_accuracy: 0.8770 - loss: 10.5830\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","k: 9, patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - dense_299_accuracy: 0.5882 - dense_301_accuracy: 0.7541 - dense_303_accuracy: 0.9408 - dense_305_accuracy: 0.7111 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8237 - dense_311_accuracy: 0.6103 - dense_313_accuracy: 0.6740 - dense_315_accuracy: 0.7912 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.8074 - dense_323_accuracy: 0.7170 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5511 - dense_329_accuracy: 0.8770 - loss: 9.9172\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","k: 10, patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - dense_299_accuracy: 0.6311 - dense_301_accuracy: 0.7215 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.6845 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6519 - dense_313_accuracy: 0.6578 - dense_315_accuracy: 0.7599 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.8074 - dense_323_accuracy: 0.7274 - dense_325_accuracy: 0.8504 - dense_327_accuracy: 0.5719 - dense_329_accuracy: 0.8770 - loss: 9.8636\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","k: 11, patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - dense_299_accuracy: 0.5777 - dense_301_accuracy: 0.7912 - dense_303_accuracy: 0.9408 - dense_305_accuracy: 0.7274 - dense_307_accuracy: 0.7378 - dense_309_accuracy: 0.8341 - dense_311_accuracy: 0.6415 - dense_313_accuracy: 0.6578 - dense_315_accuracy: 0.8016 - dense_317_accuracy: 0.9408 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.7378 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5615 - dense_329_accuracy: 0.8979 - loss: 9.4610\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","k: 12, patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - dense_299_accuracy: 0.5882 - dense_301_accuracy: 0.8608 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.7274 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6207 - dense_313_accuracy: 0.6845 - dense_315_accuracy: 0.7599 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.8074 - dense_323_accuracy: 0.7274 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5615 - dense_329_accuracy: 0.8666 - loss: 9.6308\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","k: 13, patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - dense_299_accuracy: 0.6044 - dense_301_accuracy: 0.7970 - dense_303_accuracy: 0.9304 - dense_305_accuracy: 0.7703 - dense_307_accuracy: 0.7274 - dense_309_accuracy: 0.8237 - dense_311_accuracy: 0.6474 - dense_313_accuracy: 0.7274 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.7170 - dense_325_accuracy: 0.8399 - dense_327_accuracy: 0.5511 - dense_329_accuracy: 0.8666 - loss: 9.3680\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 14, patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - dense_299_accuracy: 0.6044 - dense_301_accuracy: 0.8133 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.7703 - dense_307_accuracy: 0.7482 - dense_309_accuracy: 0.8237 - dense_311_accuracy: 0.6311 - dense_313_accuracy: 0.6636 - dense_315_accuracy: 0.7807 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.8178 - dense_323_accuracy: 0.7274 - dense_325_accuracy: 0.8608 - dense_327_accuracy: 0.5511 - dense_329_accuracy: 0.8874 - loss: 9.4707\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 15, patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - dense_299_accuracy: 0.6253 - dense_301_accuracy: 0.8074 - dense_303_accuracy: 0.9200 - dense_305_accuracy: 0.8224 - dense_307_accuracy: 0.7970 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6474 - dense_313_accuracy: 0.6740 - dense_315_accuracy: 0.7703 - dense_317_accuracy: 0.9304 - dense_319_accuracy: 0.8933 - dense_321_accuracy: 0.8074 - dense_323_accuracy: 0.7807 - dense_325_accuracy: 0.8399 - dense_327_accuracy: 0.5407 - dense_329_accuracy: 0.8770 - loss: 9.2344\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 16, patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - dense_299_accuracy: 0.6253 - dense_301_accuracy: 0.8237 - dense_303_accuracy: 0.9304 - dense_305_accuracy: 0.7541 - dense_307_accuracy: 0.6578 - dense_309_accuracy: 0.8133 - dense_311_accuracy: 0.6578 - dense_313_accuracy: 0.6845 - dense_315_accuracy: 0.7703 - dense_317_accuracy: 0.9200 - dense_319_accuracy: 0.9037 - dense_321_accuracy: 0.7970 - dense_323_accuracy: 0.6636 - dense_325_accuracy: 0.8504 - dense_327_accuracy: 0.5673 - dense_329_accuracy: 0.8666 - loss: 9.3290\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 17, patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n","Test Loss iteration 4: 36.83472817871744\n","average_loss: 40.968569031911784\n"]}]}]}