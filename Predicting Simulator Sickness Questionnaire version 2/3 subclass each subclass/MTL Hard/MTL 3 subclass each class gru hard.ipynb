{"cells":[{"cell_type":"code","execution_count":69,"metadata":{"id":"fT_A9oAGAepC","executionInfo":{"status":"ok","timestamp":1725436659222,"user_tz":300,"elapsed":265,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TishlaEBAmlN","executionInfo":{"status":"ok","timestamp":1725436662221,"user_tz":300,"elapsed":2702,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"444ccddb-c4eb-49ca-c0e8-65144a98d5cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"XeSwJ8oKAt2r","executionInfo":{"status":"ok","timestamp":1725436662221,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"BFHyHoFvA5bX","executionInfo":{"status":"ok","timestamp":1725436662222,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"QeoIWcudA94b","executionInfo":{"status":"ok","timestamp":1725436662222,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["\n","def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","            arrays_3d.append(array_3d)\n","    return arrays_3d\n"]},{"cell_type":"code","source":["sample_size=60\n","# simulations_train = ['noise','bumps']\n","# simulations_test=['flat']\n","# val_indices = [4, 10, 11, 26, 28, 31, 33, 37] # for flat\n","# train_indices = [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 38, 39, 40, 41] # for flat\n","\n","\n","# simulations_test=['noise']\n","# simulations_train = ['flat','bumps']\n","# val_indices = [7, 15, 17, 19, 28, 31, 32, 42, 44, 48] # for noise\n","# train_indices = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47] # for noise\n","\n","simulations_test=['bumps']\n","simulations_train = ['flat','noise']\n","val_indices = [1, 12, 16, 18, 22, 26, 28, 37, 41] # for speedbumps\n","train_indices = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44] # for speedbumps"],"metadata":{"id":"0D8UyttEAUzU","executionInfo":{"status":"ok","timestamp":1725436662222,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","execution_count":75,"metadata":{"id":"fqaeUGUDBCtT","executionInfo":{"status":"ok","timestamp":1725436662222,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["participants = [str(i) for i in range(1, 27)]  # Participants 101 to 123\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"DwS92BItBL4B","executionInfo":{"status":"ok","timestamp":1725436663262,"user_tz":300,"elapsed":1045,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["arrays_train = construct_3d_array(base_path, participants, simulations_train, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_test = construct_3d_array(base_path, participants, simulations_test, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","source":[],"metadata":{"id":"98DbLCnXafN5","executionInfo":{"status":"ok","timestamp":1725436663263,"user_tz":300,"elapsed":11,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","execution_count":77,"metadata":{"id":"GgAM9zg_BRe8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725436663263,"user_tz":300,"elapsed":10,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"c41899a2-ab92-40cd-8345-3d90ae85ccf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the final concatenated 3D array: (83, 180, 47)\n","Shape of the final concatenated 3D array: (23, 180, 47)\n"]}],"source":["# Concatenate arrays along the first axis\n","input_train = np.concatenate(arrays_train, axis=0)\n","input_test = np.concatenate(arrays_test, axis=0)\n","\n","# Display the shape of the final concatenated 3D array\n","print(f\"Shape of the final concatenated 3D array: {input_train.shape}\")\n","print(f\"Shape of the final concatenated 3D array: {input_test.shape}\")"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"vPQyeAYKBYaO","executionInfo":{"status":"ok","timestamp":1725436663263,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[:, n_columns].sum(axis=1)\n","    o_val = df.iloc[:, o_columns].sum(axis=1)\n","    d_val = df.iloc[:, d_columns].sum(axis=1)\n","\n","    return n_val,o_val,d_val"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"Xpn0lDt0BfvE","executionInfo":{"status":"ok","timestamp":1725436663263,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq_values.append([n_val, o_val, d_val])\n","          #ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          #total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"7k17K0HrCr6-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725436665249,"user_tz":300,"elapsed":1991,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"ffbd8be1-1a3c-4ed4-860c-c10c16f35e48"},"outputs":[{"output_type":"stream","name":"stdout","text":["(45, 3) (23, 3) (45, 1) (23, 1)\n"]}],"source":["output_train=merge_ssq_column(simulations_train,participants)\n","output_train = np.squeeze(output_train)\n","output_test=merge_ssq_column(simulations_test,participants)\n","output_test = np.squeeze(output_test)\n","output_train_total_ssq=merge_total_ssq(simulations_train,participants)\n","output_test_total_ssq=merge_total_ssq(simulations_test,participants)\n","output_train_total_ssq=output_train_total_ssq.reshape(-1, 1)\n","output_test_total_ssq=output_test_total_ssq.reshape(-1, 1)\n","print(output_train.shape,output_test.shape,output_train_total_ssq.shape,output_test_total_ssq.shape)\n","# print(output_train)\n","# print(output_train_total_ssq)\n"]},{"cell_type":"code","source":["input_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKwH-BAwaA3t","executionInfo":{"status":"ok","timestamp":1725436665249,"user_tz":300,"elapsed":23,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"bff4b611-3cbd-4a00-932c-5a399724a986"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(83, 180, 47)"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","execution_count":82,"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1725436665249,"user_tz":300,"elapsed":18,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"LyvV6GFDC66F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725436665250,"user_tz":300,"elapsed":18,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"a4eb4ef8-63d6-491a-ecbf-4b7da4b77508"},"outputs":[{"output_type":"stream","name":"stdout","text":["val input : (9, 120, 47)\n","train input : (36, 120, 47)\n","val output : (9, 1)\n","train output : (36, 3)\n"]}],"source":["input_train, input_test= scale_input_data(input_train[:, (60-sample_size):(180-sample_size), :], input_test[:, (60-sample_size):(180-sample_size), :])\n","output_train, min_val, max_val = scale_target_var(output_train)\n","\n","input_val = input_train[val_indices]\n","input_train = input_train[train_indices]\n","output_val = output_train_total_ssq[val_indices]\n","output_train = output_train[train_indices]\n","\n","print(\"val input :\",input_val.shape)\n","print(\"train input :\",input_train.shape)\n","print(\"val output :\",output_val.shape)\n","print(\"train output :\",output_train.shape)"]},{"cell_type":"code","source":["input_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7XAkiG-SZDI","executionInfo":{"status":"ok","timestamp":1725436665250,"user_tz":300,"elapsed":15,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"f34fc2e2-6339-4cd4-b4d0-27b616672e85"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(36, 120, 47)"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","execution_count":85,"metadata":{"id":"E6ssyYUeDJwI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725436711250,"user_tz":300,"elapsed":46012,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"91ca08d5-5cd8-4eab-ccc1-cc194ac4ad35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 420ms/step - loss: 0.0392 - sequential_60_mse: 0.0392 - val_loss: 5067.4839 - val_sequential_60_mse: 5067.4839\n","Epoch 2/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0239 - sequential_60_mse: 0.0239 - val_loss: 5068.7544 - val_sequential_60_mse: 5068.7544\n","Epoch 3/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0331 - sequential_60_mse: 0.0331 - val_loss: 5057.0684 - val_sequential_60_mse: 5057.0684\n","Epoch 4/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0304 - sequential_60_mse: 0.0304 - val_loss: 5059.8560 - val_sequential_60_mse: 5059.8560\n","Epoch 5/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0241 - sequential_60_mse: 0.0241 - val_loss: 5064.4043 - val_sequential_60_mse: 5064.4043\n","Epoch 6/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0224 - sequential_60_mse: 0.0224 - val_loss: 5065.1240 - val_sequential_60_mse: 5065.1240\n","Epoch 7/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0270 - sequential_60_mse: 0.0270 - val_loss: 5059.4473 - val_sequential_60_mse: 5059.4473\n","Epoch 8/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0214 - sequential_60_mse: 0.0214 - val_loss: 5054.0835 - val_sequential_60_mse: 5054.0835\n","Epoch 9/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0205 - sequential_60_mse: 0.0205 - val_loss: 5058.2588 - val_sequential_60_mse: 5058.2588\n","Epoch 10/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0166 - sequential_60_mse: 0.0166 - val_loss: 5061.9878 - val_sequential_60_mse: 5061.9878\n","Epoch 11/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0190 - sequential_60_mse: 0.0190 - val_loss: 5058.0850 - val_sequential_60_mse: 5058.0850\n","Epoch 12/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0150 - sequential_60_mse: 0.0150 - val_loss: 5053.5654 - val_sequential_60_mse: 5053.5654\n","Epoch 13/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0169 - sequential_60_mse: 0.0169 - val_loss: 5054.1562 - val_sequential_60_mse: 5054.1562\n","Epoch 14/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0178 - sequential_60_mse: 0.0178 - val_loss: 5058.2192 - val_sequential_60_mse: 5058.2192\n","Epoch 15/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0222 - sequential_60_mse: 0.0222 - val_loss: 5059.7485 - val_sequential_60_mse: 5059.7485\n","Epoch 16/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0196 - sequential_60_mse: 0.0196 - val_loss: 5056.5527 - val_sequential_60_mse: 5056.5527\n","Epoch 17/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0180 - sequential_60_mse: 0.0180 - val_loss: 5055.8716 - val_sequential_60_mse: 5055.8716\n","Epoch 17: early stopping\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0873 - sequential_60_mse: 0.0228\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n","(3, 23, 1)\n","after (23, 3)\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 768ms/step - loss: 0.1508 - sequential_63_mse: 0.1508 - val_loss: 5035.4795 - val_sequential_63_mse: 5035.4795\n","Epoch 2/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 0.0899 - sequential_63_mse: 0.0899 - val_loss: 5042.6074 - val_sequential_63_mse: 5042.6074\n","Epoch 3/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - loss: 0.0663 - sequential_63_mse: 0.0663 - val_loss: 5062.5088 - val_sequential_63_mse: 5062.5088\n","Epoch 4/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - loss: 0.0252 - sequential_63_mse: 0.0252 - val_loss: 5074.4395 - val_sequential_63_mse: 5074.4395\n","Epoch 5/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.0447 - sequential_63_mse: 0.0447 - val_loss: 5072.2266 - val_sequential_63_mse: 5072.2266\n","Epoch 6/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - loss: 0.0323 - sequential_63_mse: 0.0323 - val_loss: 5063.2749 - val_sequential_63_mse: 5063.2749\n","Epoch 6: early stopping\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0950 - sequential_63_mse: 0.0343\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n","(3, 23, 1)\n","after (23, 3)\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 411ms/step - loss: 0.0430 - sequential_66_mse: 0.0430 - val_loss: 5041.9438 - val_sequential_66_mse: 5041.9438\n","Epoch 2/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0628 - sequential_66_mse: 0.0628 - val_loss: 5062.6992 - val_sequential_66_mse: 5062.6992\n","Epoch 3/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0390 - sequential_66_mse: 0.0390 - val_loss: 5061.1479 - val_sequential_66_mse: 5061.1479\n","Epoch 4/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0357 - sequential_66_mse: 0.0357 - val_loss: 5055.4746 - val_sequential_66_mse: 5055.4746\n","Epoch 5/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0229 - sequential_66_mse: 0.0229 - val_loss: 5052.9629 - val_sequential_66_mse: 5052.9629\n","Epoch 6/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0301 - sequential_66_mse: 0.0301 - val_loss: 5050.9570 - val_sequential_66_mse: 5050.9570\n","Epoch 6: early stopping\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.1258 - sequential_66_mse: 0.0343\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n","(3, 23, 1)\n","after (23, 3)\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 607ms/step - loss: 0.1331 - sequential_69_mse: 0.1331 - val_loss: 5049.2373 - val_sequential_69_mse: 5049.2373\n","Epoch 2/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0273 - sequential_69_mse: 0.0273 - val_loss: 5055.2051 - val_sequential_69_mse: 5055.2051\n","Epoch 3/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0268 - sequential_69_mse: 0.0268 - val_loss: 5063.4272 - val_sequential_69_mse: 5063.4272\n","Epoch 4/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0235 - sequential_69_mse: 0.0235 - val_loss: 5063.2715 - val_sequential_69_mse: 5063.2715\n","Epoch 5/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0270 - sequential_69_mse: 0.0270 - val_loss: 5055.8105 - val_sequential_69_mse: 5055.8105\n","Epoch 6/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0241 - sequential_69_mse: 0.0241 - val_loss: 5048.9707 - val_sequential_69_mse: 5048.9707\n","Epoch 7/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0335 - sequential_69_mse: 0.0335 - val_loss: 5053.8687 - val_sequential_69_mse: 5053.8687\n","Epoch 8/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0296 - sequential_69_mse: 0.0296 - val_loss: 5062.6470 - val_sequential_69_mse: 5062.6470\n","Epoch 9/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.0201 - sequential_69_mse: 0.0201 - val_loss: 5065.1978 - val_sequential_69_mse: 5065.1978\n","Epoch 10/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.0249 - sequential_69_mse: 0.0249 - val_loss: 5062.4058 - val_sequential_69_mse: 5062.4058\n","Epoch 11/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0228 - sequential_69_mse: 0.0228 - val_loss: 5056.7051 - val_sequential_69_mse: 5056.7051\n","Epoch 11: early stopping\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0864 - sequential_69_mse: 0.0257\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n","(3, 23, 1)\n","after (23, 3)\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:664: UserWarning: Gradients do not exist for variables ['kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 412ms/step - loss: 0.0720 - sequential_72_mse: 0.0720 - val_loss: 5042.5938 - val_sequential_72_mse: 5042.5938\n","Epoch 2/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0609 - sequential_72_mse: 0.0609 - val_loss: 5071.5024 - val_sequential_72_mse: 5071.5024\n","Epoch 3/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0727 - sequential_72_mse: 0.0727 - val_loss: 5075.8193 - val_sequential_72_mse: 5075.8193\n","Epoch 4/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0680 - sequential_72_mse: 0.0680 - val_loss: 5065.0972 - val_sequential_72_mse: 5065.0972\n","Epoch 5/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0245 - sequential_72_mse: 0.0245 - val_loss: 5053.1470 - val_sequential_72_mse: 5053.1470\n","Epoch 6/20\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0299 - sequential_72_mse: 0.0299 - val_loss: 5048.5903 - val_sequential_72_mse: 5048.5903\n","Epoch 6: early stopping\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.2159 - sequential_72_mse: 0.0491\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n","(3, 23, 1)\n","after (23, 3)\n","4.131681125996219 2.5013970910959844 2.9425115572880145\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Input, GRU, Dense, Dropout\n","from keras.models import Model\n","import numpy as np\n","from keras.callbacks import EarlyStopping\n","import sklearn\n","rmse_n=[]\n","rmse_o=[]\n","rmse_d=[]\n","np.set_printoptions(precision=2)\n","for iteration in range(5):\n","  def get_shared_GRU(input_shape1, input_shape2):\n","      # Define shared GRU model\n","      input_layer = Input(shape=(input_shape1, input_shape2))\n","      x = GRU(64, return_sequences=False)(input_layer)\n","      x = Dense(256, activation='relu')(x)\n","      x = Dropout(0.2)(x)\n","      shared_model = Model(inputs=input_layer, outputs=x)\n","      return shared_model\n","\n","  def get_output_model(shared_GRU_output, output_shape):\n","      # Define separate output model for each column\n","      output_models = []\n","      for i in range(output_shape[1]):\n","          output_model = Sequential()\n","          output_model.add(Dense(256, activation='relu'))\n","          output_model.add(Dropout(0.2))\n","          output_model.add(Dense(1))  # Output shape is (None, 1) for each column\n","          output_model_output = output_model(shared_GRU_output)\n","          output_models.append(output_model_output)\n","      return output_models\n","\n","  # Assuming train_input, train_output, test_input, test_output are numpy arrays\n","\n","  # Reshape train and test inputs to match GRU input shape\n","  train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","  test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","  val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","  # Get shared GRU model\n","  shared_GRU = get_shared_GRU(input_train.shape[1], input_train.shape[2])\n","\n","  # Create separate output models for each column\n","  output_models = get_output_model(shared_GRU.output, output_train.shape)\n","\n","  # Create combined model\n","  model = Model(inputs=shared_GRU.input, outputs=output_models)\n","\n","  # Compile and train the model\n","  model.compile(loss='mse', optimizer='adam', metrics=[['mse'] for _ in range(output_train.shape[1])])  # Using MSE as loss and metric\n","  early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=5, verbose=1)\n","  model.fit(train_input_reshaped, output_train, epochs=20, batch_size=32,validation_data=(val_input_reshaped, output_val), callbacks=[early_stopping])\n","\n","\n","  # Predict test data\n","  model.fit(train_input_reshaped, [output_train[:, i] for i in range(output_train.shape[1])], epochs=1, batch_size=32)\n","\n","\n","  # Predict test data\n","  pred_test = np.array(model.predict(test_input_reshaped))\n","  print(pred_test.shape)\n","  pred_test = np.transpose(pred_test.squeeze(), (1, 0))\n","  print(\"after\",pred_test.shape)\n","  pred_test_n = np.zeros((pred_test.shape[0], 1))\n","  pred_test_o = np.zeros((pred_test.shape[0], 1))\n","  pred_test_d = np.zeros((pred_test.shape[0], 1))\n","  pred_test_final = np.empty((output_test.shape[0], 0))\n","  for m in range(pred_test.shape[0]):\n","    pred_test_n[m,0] = pred_test[m,0]*(max_val[0]-min_val[0]) + min_val[0]\n","    pred_test_o[m,0] = pred_test[m,1]*(max_val[1]-min_val[1]) + min_val[1]\n","    pred_test_d[m,0] = pred_test[m,2]*(max_val[2]-min_val[2]) + min_val[2]\n","\n","  pred_test_final=np.hstack((pred_test_final, pred_test_n))\n","  pred_test_final=np.hstack((pred_test_final, pred_test_o))\n","  pred_test_final=np.hstack((pred_test_final, pred_test_d))\n","\n","  # Overall Test Loss\n","  loss_n = sklearn.metrics.mean_squared_error(pred_test_final[:,0], output_test[:,0], squared = False)\n","  rmse_n.append(loss_n)\n","  loss_o = sklearn.metrics.mean_squared_error(pred_test_final[:,1], output_test[:,1], squared = False)\n","  rmse_o.append(loss_o)\n","  loss_d= sklearn.metrics.mean_squared_error(pred_test_final[:,2], output_test[:,2], squared = False)\n","  rmse_d.append(loss_d)\n","rmse_combined = np.column_stack((rmse_n, rmse_o, rmse_d))\n","rmse_n_loss = sum(rmse_n) / len(rmse_n)\n","rmse_o_loss = sum(rmse_o) / len(rmse_o)\n","rmse_d_loss = sum(rmse_d) / len(rmse_d)\n","average_rmse = np.array([rmse_n_loss, rmse_o_loss, rmse_d_loss])\n","\n","print(rmse_n_loss,rmse_o_loss,rmse_d_loss)\n","\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMp8GiJbFY7aSDss5Uw/Ski"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}