{"cells":[{"cell_type":"code","execution_count":73,"metadata":{"id":"fT_A9oAGAepC","executionInfo":{"status":"ok","timestamp":1725436918643,"user_tz":300,"elapsed":281,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TishlaEBAmlN","executionInfo":{"status":"ok","timestamp":1725436920651,"user_tz":300,"elapsed":1470,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"4c1c325f-a0f9-4914-e235-025c360e743c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"XeSwJ8oKAt2r","executionInfo":{"status":"ok","timestamp":1725436920652,"user_tz":300,"elapsed":7,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"BFHyHoFvA5bX","executionInfo":{"status":"ok","timestamp":1725436920652,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"QeoIWcudA94b","executionInfo":{"status":"ok","timestamp":1725436920652,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["\n","def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","            arrays_3d.append(array_3d)\n","    return arrays_3d\n"]},{"cell_type":"code","source":["sample_size=60\n","# simulations_train = ['noise','bumps']\n","# simulations_test=['flat']\n","# val_indices = [4, 10, 11, 26, 28, 31, 33, 37] # for flat\n","# train_indices = [0, 1, 2, 3, 5, 6, 7, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 32, 34, 35, 36, 38, 39, 40, 41] # for flat\n","\n","\n","# simulations_test=['noise']\n","# simulations_train = ['flat','bumps']\n","# val_indices = [7, 15, 17, 19, 28, 31, 32, 42, 44, 48] # for noise\n","# train_indices = [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 45, 46, 47] # for noise\n","\n","simulations_test=['bumps']\n","simulations_train = ['flat','noise']\n","val_indices = [1, 12, 16, 18, 22, 26, 28, 37, 41] # for speedbumps\n","train_indices = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 19, 20, 21, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44] # for speedbumps"],"metadata":{"id":"0D8UyttEAUzU","executionInfo":{"status":"ok","timestamp":1725436920652,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","execution_count":79,"metadata":{"id":"fqaeUGUDBCtT","executionInfo":{"status":"ok","timestamp":1725436920652,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["participants = [str(i) for i in range(1, 27)]  # Participants 101 to 123\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"DwS92BItBL4B","executionInfo":{"status":"ok","timestamp":1725436923262,"user_tz":300,"elapsed":2615,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["arrays_train = construct_3d_array(base_path, participants, simulations_train, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_test = construct_3d_array(base_path, participants, simulations_test, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","source":[],"metadata":{"id":"98DbLCnXafN5","executionInfo":{"status":"ok","timestamp":1725436923262,"user_tz":300,"elapsed":9,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","execution_count":81,"metadata":{"id":"GgAM9zg_BRe8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725436923263,"user_tz":300,"elapsed":9,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"960c944b-4eb4-4a1a-9af7-26eda921b389"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the final concatenated 3D array: (83, 180, 47)\n","Shape of the final concatenated 3D array: (23, 180, 47)\n"]}],"source":["# Concatenate arrays along the first axis\n","input_train = np.concatenate(arrays_train, axis=0)\n","input_test = np.concatenate(arrays_test, axis=0)\n","\n","# Display the shape of the final concatenated 3D array\n","print(f\"Shape of the final concatenated 3D array: {input_train.shape}\")\n","print(f\"Shape of the final concatenated 3D array: {input_test.shape}\")"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"vPQyeAYKBYaO","executionInfo":{"status":"ok","timestamp":1725436923263,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[:, n_columns].sum(axis=1)\n","    o_val = df.iloc[:, o_columns].sum(axis=1)\n","    d_val = df.iloc[:, d_columns].sum(axis=1)\n","\n","    return n_val,o_val,d_val"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"Xpn0lDt0BfvE","executionInfo":{"status":"ok","timestamp":1725436923263,"user_tz":300,"elapsed":6,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq_values.append([n_val, o_val, d_val])\n","          #ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          #total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"7k17K0HrCr6-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725436926797,"user_tz":300,"elapsed":3540,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"f72f3e89-347b-4ece-f395-c51da6defd5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(45, 3) (23, 3) (45, 1) (23, 1)\n"]}],"source":["output_train=merge_ssq_column(simulations_train,participants)\n","output_train = np.squeeze(output_train)\n","output_test=merge_ssq_column(simulations_test,participants)\n","output_test = np.squeeze(output_test)\n","output_train_total_ssq=merge_total_ssq(simulations_train,participants)\n","output_test_total_ssq=merge_total_ssq(simulations_test,participants)\n","output_train_total_ssq=output_train_total_ssq.reshape(-1, 1)\n","output_test_total_ssq=output_test_total_ssq.reshape(-1, 1)\n","print(output_train.shape,output_test.shape,output_train_total_ssq.shape,output_test_total_ssq.shape)\n","# print(output_train)\n","# print(output_train_total_ssq)\n"]},{"cell_type":"code","source":["input_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKwH-BAwaA3t","executionInfo":{"status":"ok","timestamp":1725436926797,"user_tz":300,"elapsed":10,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"28678643-f701-42a9-ec02-7c6293e41852"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(83, 180, 47)"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","execution_count":86,"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1725436926798,"user_tz":300,"elapsed":9,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"o18KTQ6FNMSL","executionInfo":{"status":"ok","timestamp":1725436926798,"user_tz":300,"elapsed":9,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["# import numpy as np\n","\n","\n","# new_data = np.zeros((38, 3))\n","\n","# # Assigning original serial numbers to the first column\n","# new_data[:, 0] = np.arange(1, 39)\n","\n","# # Assigning original values to the second column\n","# new_data[:, 1] = output_train_total_ssq[:, 0]\n","\n","# # Sorting the array based on the values (second column)\n","# sorted_indices = np.argsort(new_data[:, 1])\n","# sorted_data = new_data[sorted_indices]\n","\n","# # Assigning new serial numbers to the third column\n","# current_val = sorted_data[0][1]\n","# start_idx = 0\n","# for i, row in enumerate(sorted_data):\n","#     if row[1] != current_val:\n","#         sorted_data[start_idx:i, 2] = np.arange(start_idx + 1, i + 1)\n","#         start_idx = i\n","#         current_val = row[1]\n","\n","# # Assigning new serial numbers for the last group\n","# sorted_data[start_idx:, 2] = np.arange(start_idx + 1, len(sorted_data) + 1)\n","\n","# #print(sorted_data)\n"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"LyvV6GFDC66F","executionInfo":{"status":"ok","timestamp":1725436926798,"user_tz":300,"elapsed":8,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["input_train, input_test= scale_input_data(input_train[:, (60-sample_size):(180-sample_size), :], input_test[:, (60-sample_size):(180-sample_size), :])\n","output_train, min_val, max_val = scale_target_var(output_train)\n","\n","input_val = input_train[val_indices]\n","input_train = input_train[train_indices]\n","output_val = output_train_total_ssq[val_indices]\n","output_train = output_train[train_indices]\n"]},{"cell_type":"code","source":["print(\"input_val :\",input_val.shape)\n","print(\"input_train :\",input_train.shape)\n","print(\"output_val :\",output_val.shape)\n","print(\"output_train :\",output_train.shape)\n","print(\"output_test :\",output_test.shape)\n","print(\"input_test :\",input_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7XAkiG-SZDI","executionInfo":{"status":"ok","timestamp":1725436926798,"user_tz":300,"elapsed":8,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"59a9bdbc-1f5a-4053-8499-74024e92f790"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["input_val : (9, 120, 47)\n","input_train : (36, 120, 47)\n","output_val : (9, 1)\n","output_train : (36, 3)\n","output_test : (23, 3)\n","input_test : (23, 120, 47)\n"]}]},{"cell_type":"code","execution_count":90,"metadata":{"id":"E6ssyYUeDJwI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725437068692,"user_tz":300,"elapsed":141900,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}},"outputId":"e914e84f-d731-40ef-c82b-28de5cfa0592"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - loss: 0.4850 - output_0_mse: 0.1108 - output_1_mse: 0.1661 - output_2_mse: 0.2081\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.3149 - output_0_mse: 0.1757 - output_1_mse: 0.0369 - output_2_mse: 0.1023 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2735 - output_0_mse: 0.0946 - output_1_mse: 0.0452 - output_2_mse: 0.1337 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.2009 - output_0_mse: 0.1041 - output_1_mse: 0.0517 - output_2_mse: 0.0452\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.1237 - output_0_mse: 0.0659 - output_1_mse: 0.0218 - output_2_mse: 0.0361\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 4 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1330 - output_0_mse: 0.0694 - output_1_mse: 0.0302 - output_2_mse: 0.0333\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n","k: 5 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1215 - output_0_mse: 0.0562 - output_1_mse: 0.0271 - output_2_mse: 0.0383\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 6 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.1389 - output_0_mse: 0.0748 - output_1_mse: 0.0295 - output_2_mse: 0.0346\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","k: 7 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1029 - output_0_mse: 0.0513 - output_1_mse: 0.0265 - output_2_mse: 0.0251 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 8 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1185 - output_0_mse: 0.0448 - output_1_mse: 0.0416 - output_2_mse: 0.0321 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 9 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0977 - output_0_mse: 0.0311 - output_1_mse: 0.0396 - output_2_mse: 0.0270 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 10 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1160 - output_0_mse: 0.0586 - output_1_mse: 0.0257 - output_2_mse: 0.0317 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 11 patience: 10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0954 - output_0_mse: 0.0361 - output_1_mse: 0.0231 - output_2_mse: 0.0361 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 12 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0894 - output_0_mse: 0.0431 - output_1_mse: 0.0255 - output_2_mse: 0.0208 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 13 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0969 - output_0_mse: 0.0358 - output_1_mse: 0.0223 - output_2_mse: 0.0389 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 14 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0996 - output_0_mse: 0.0423 - output_1_mse: 0.0273 - output_2_mse: 0.0301 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 15 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0995 - output_0_mse: 0.0459 - output_1_mse: 0.0298 - output_2_mse: 0.0239 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 16 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1056 - output_0_mse: 0.0304 - output_1_mse: 0.0352 - output_2_mse: 0.0400 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 17 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0841 - output_0_mse: 0.0354 - output_1_mse: 0.0209 - output_2_mse: 0.0278 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 18 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0750 - output_0_mse: 0.0286 - output_1_mse: 0.0263 - output_2_mse: 0.0201 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 19 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0729 - output_0_mse: 0.0271 - output_1_mse: 0.0202 - output_2_mse: 0.0256 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 20 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0815 - output_0_mse: 0.0431 - output_1_mse: 0.0202 - output_2_mse: 0.0182 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 21 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0687 - output_0_mse: 0.0338 - output_1_mse: 0.0126 - output_2_mse: 0.0223 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 22 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0697 - output_0_mse: 0.0287 - output_1_mse: 0.0146 - output_2_mse: 0.0264 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 23 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0697 - output_0_mse: 0.0306 - output_1_mse: 0.0146 - output_2_mse: 0.0244 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 24 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0538 - output_0_mse: 0.0230 - output_1_mse: 0.0119 - output_2_mse: 0.0189 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 25 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0696 - output_0_mse: 0.0304 - output_1_mse: 0.0216 - output_2_mse: 0.0176 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 26 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 0.4922 - output_0_mse: 0.1060 - output_1_mse: 0.0415 - output_2_mse: 0.3447\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2009 - output_0_mse: 0.0737 - output_1_mse: 0.0880 - output_2_mse: 0.0392 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3111 - output_0_mse: 0.0490 - output_1_mse: 0.0892 - output_2_mse: 0.1729 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.1845 - output_0_mse: 0.0643 - output_1_mse: 0.0683 - output_2_mse: 0.0520\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.2405 - output_0_mse: 0.0682 - output_1_mse: 0.0745 - output_2_mse: 0.0978\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 4 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2193 - output_0_mse: 0.0660 - output_1_mse: 0.0605 - output_2_mse: 0.0928\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n","k: 5 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.1423 - output_0_mse: 0.0483 - output_1_mse: 0.0428 - output_2_mse: 0.0511\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 6 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.1298 - output_0_mse: 0.0506 - output_1_mse: 0.0429 - output_2_mse: 0.0363\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 7 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1266 - output_0_mse: 0.0463 - output_1_mse: 0.0453 - output_2_mse: 0.0350 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 8 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1284 - output_0_mse: 0.0509 - output_1_mse: 0.0354 - output_2_mse: 0.0420 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 9 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1072 - output_0_mse: 0.0406 - output_1_mse: 0.0320 - output_2_mse: 0.0345 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 10 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1253 - output_0_mse: 0.0440 - output_1_mse: 0.0484 - output_2_mse: 0.0329 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 11 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0981 - output_0_mse: 0.0503 - output_1_mse: 0.0183 - output_2_mse: 0.0295\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 12 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0885 - output_0_mse: 0.0350 - output_1_mse: 0.0268 - output_2_mse: 0.0267 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 13 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0807 - output_0_mse: 0.0379 - output_1_mse: 0.0179 - output_2_mse: 0.0248 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 14 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0952 - output_0_mse: 0.0518 - output_1_mse: 0.0211 - output_2_mse: 0.0224 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 15 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0967 - output_0_mse: 0.0499 - output_1_mse: 0.0168 - output_2_mse: 0.0300 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 16 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0821 - output_0_mse: 0.0314 - output_1_mse: 0.0251 - output_2_mse: 0.0256 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 17 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - loss: 0.2509 - output_0_mse: 0.0779 - output_1_mse: 0.1267 - output_2_mse: 0.0463\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1984 - output_0_mse: 0.1005 - output_1_mse: 0.0334 - output_2_mse: 0.0645 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2375 - output_0_mse: 0.0613 - output_1_mse: 0.1200 - output_2_mse: 0.0561 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.2173 - output_0_mse: 0.0649 - output_1_mse: 0.0517 - output_2_mse: 0.1007 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1661 - output_0_mse: 0.0427 - output_1_mse: 0.0620 - output_2_mse: 0.0614 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 4 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1449 - output_0_mse: 0.0409 - output_1_mse: 0.0356 - output_2_mse: 0.0684 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 5 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1231 - output_0_mse: 0.0487 - output_1_mse: 0.0423 - output_2_mse: 0.0322\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 6 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1192 - output_0_mse: 0.0466 - output_1_mse: 0.0341 - output_2_mse: 0.0384 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 7 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1559 - output_0_mse: 0.0881 - output_1_mse: 0.0251 - output_2_mse: 0.0428 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 8 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1032 - output_0_mse: 0.0397 - output_1_mse: 0.0266 - output_2_mse: 0.0369 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 9 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1186 - output_0_mse: 0.0455 - output_1_mse: 0.0297 - output_2_mse: 0.0435\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 10 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.1115 - output_0_mse: 0.0539 - output_1_mse: 0.0216 - output_2_mse: 0.0361\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 11 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0694 - output_0_mse: 0.0320 - output_1_mse: 0.0146 - output_2_mse: 0.0227\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n","k: 12 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0758 - output_0_mse: 0.0343 - output_1_mse: 0.0219 - output_2_mse: 0.0197\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n","k: 13 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1029 - output_0_mse: 0.0389 - output_1_mse: 0.0232 - output_2_mse: 0.0409\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n","k: 14 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0875 - output_0_mse: 0.0343 - output_1_mse: 0.0309 - output_2_mse: 0.0223 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n","k: 15 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1057 - output_0_mse: 0.0355 - output_1_mse: 0.0357 - output_2_mse: 0.0344 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 16 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0816 - output_0_mse: 0.0258 - output_1_mse: 0.0292 - output_2_mse: 0.0266 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 17 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0678 - output_0_mse: 0.0327 - output_1_mse: 0.0161 - output_2_mse: 0.0190 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 18 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0595 - output_0_mse: 0.0281 - output_1_mse: 0.0178 - output_2_mse: 0.0136 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 19 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0545 - output_0_mse: 0.0242 - output_1_mse: 0.0167 - output_2_mse: 0.0135 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n","k: 20 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0687 - output_0_mse: 0.0369 - output_1_mse: 0.0150 - output_2_mse: 0.0168 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 21 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 0.9810 - output_0_mse: 0.3694 - output_1_mse: 0.0948 - output_2_mse: 0.5168\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1812 - output_0_mse: 0.0582 - output_1_mse: 0.0631 - output_2_mse: 0.0599 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2698 - output_0_mse: 0.1016 - output_1_mse: 0.0688 - output_2_mse: 0.0994 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1618 - output_0_mse: 0.0921 - output_1_mse: 0.0343 - output_2_mse: 0.0354 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1757 - output_0_mse: 0.0789 - output_1_mse: 0.0351 - output_2_mse: 0.0617 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 4 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1420 - output_0_mse: 0.0615 - output_1_mse: 0.0354 - output_2_mse: 0.0451 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 5 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1152 - output_0_mse: 0.0515 - output_1_mse: 0.0345 - output_2_mse: 0.0292 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 6 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1203 - output_0_mse: 0.0313 - output_1_mse: 0.0323 - output_2_mse: 0.0568 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 7 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1184 - output_0_mse: 0.0515 - output_1_mse: 0.0228 - output_2_mse: 0.0441 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 8 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1186 - output_0_mse: 0.0327 - output_1_mse: 0.0293 - output_2_mse: 0.0566 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 9 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0861 - output_0_mse: 0.0459 - output_1_mse: 0.0181 - output_2_mse: 0.0221 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","k: 10 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0777 - output_0_mse: 0.0285 - output_1_mse: 0.0259 - output_2_mse: 0.0233 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 11 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0920 - output_0_mse: 0.0451 - output_1_mse: 0.0141 - output_2_mse: 0.0328 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 12 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0723 - output_0_mse: 0.0365 - output_1_mse: 0.0157 - output_2_mse: 0.0201 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 13 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0738 - output_0_mse: 0.0292 - output_1_mse: 0.0203 - output_2_mse: 0.0242 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 14 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.1055 - output_0_mse: 0.0552 - output_1_mse: 0.0231 - output_2_mse: 0.0271\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 15 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1066 - output_0_mse: 0.0427 - output_1_mse: 0.0208 - output_2_mse: 0.0431\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","k: 16 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - loss: 0.0628 - output_0_mse: 0.0236 - output_1_mse: 0.0185 - output_2_mse: 0.0206\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 17 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0847 - output_0_mse: 0.0381 - output_1_mse: 0.0200 - output_2_mse: 0.0266\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 18 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0725 - output_0_mse: 0.0351 - output_1_mse: 0.0241 - output_2_mse: 0.0134\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 19 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0659 - output_0_mse: 0.0264 - output_1_mse: 0.0177 - output_2_mse: 0.0218\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n","k: 20 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0725 - output_0_mse: 0.0269 - output_1_mse: 0.0215 - output_2_mse: 0.0241 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 21 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0779 - output_0_mse: 0.0295 - output_1_mse: 0.0264 - output_2_mse: 0.0220 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 22 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0896 - output_0_mse: 0.0445 - output_1_mse: 0.0227 - output_2_mse: 0.0223 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 23 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0757 - output_0_mse: 0.0333 - output_1_mse: 0.0208 - output_2_mse: 0.0216\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 24 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0672 - output_0_mse: 0.0306 - output_1_mse: 0.0146 - output_2_mse: 0.0220 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 25 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0471 - output_0_mse: 0.0236 - output_1_mse: 0.0137 - output_2_mse: 0.0098 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 26 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0599 - output_0_mse: 0.0270 - output_1_mse: 0.0128 - output_2_mse: 0.0200 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 27 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0598 - output_0_mse: 0.0297 - output_1_mse: 0.0124 - output_2_mse: 0.0177 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 28 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0688 - output_0_mse: 0.0398 - output_1_mse: 0.0162 - output_2_mse: 0.0127 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 29 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0846 - output_0_mse: 0.0369 - output_1_mse: 0.0302 - output_2_mse: 0.0174 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","k: 30 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - loss: 0.7363 - output_0_mse: 0.6018 - output_1_mse: 0.0921 - output_2_mse: 0.0425\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2029 - output_0_mse: 0.0919 - output_1_mse: 0.0686 - output_2_mse: 0.0424 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2915 - output_0_mse: 0.1741 - output_1_mse: 0.0660 - output_2_mse: 0.0514 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2061 - output_0_mse: 0.0644 - output_1_mse: 0.1020 - output_2_mse: 0.0397 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1458 - output_0_mse: 0.0599 - output_1_mse: 0.0378 - output_2_mse: 0.0481 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1587 - output_0_mse: 0.0587 - output_1_mse: 0.0672 - output_2_mse: 0.0328 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.1008 - output_0_mse: 0.0312 - output_1_mse: 0.0287 - output_2_mse: 0.0410\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 6 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1411 - output_0_mse: 0.0607 - output_1_mse: 0.0356 - output_2_mse: 0.0447\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","k: 7 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.1177 - output_0_mse: 0.0458 - output_1_mse: 0.0444 - output_2_mse: 0.0275\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n","k: 8 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0989 - output_0_mse: 0.0415 - output_1_mse: 0.0210 - output_2_mse: 0.0364\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n","k: 9 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0915 - output_0_mse: 0.0349 - output_1_mse: 0.0225 - output_2_mse: 0.0341\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n","k: 10 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1026 - output_0_mse: 0.0444 - output_1_mse: 0.0223 - output_2_mse: 0.0359 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 11 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0933 - output_0_mse: 0.0426 - output_1_mse: 0.0299 - output_2_mse: 0.0208 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 12 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1176 - output_0_mse: 0.0476 - output_1_mse: 0.0264 - output_2_mse: 0.0435 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","k: 13 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1036 - output_0_mse: 0.0331 - output_1_mse: 0.0284 - output_2_mse: 0.0421 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","k: 14 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0918 - output_0_mse: 0.0356 - output_1_mse: 0.0331 - output_2_mse: 0.0231 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","k: 15 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0937 - output_0_mse: 0.0383 - output_1_mse: 0.0301 - output_2_mse: 0.0252 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","k: 16 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0627 - output_0_mse: 0.0321 - output_1_mse: 0.0146 - output_2_mse: 0.0160\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 17 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0681 - output_0_mse: 0.0233 - output_1_mse: 0.0200 - output_2_mse: 0.0248 \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","k: 18 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n","4.473787529351079 2.5829801863615938 2.8681874604341973\n"]}],"source":["from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n","from keras.optimizers import Adam\n","import numpy as np\n","import sklearn\n","\n","rmse_n=[]\n","rmse_o=[]\n","rmse_d=[]\n","\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Self attention\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Cross attention\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, enc_outputs)\n","    x = Dropout(dropout)(x)\n","    res = x + res\n","\n","    # Feed forward\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def get_hard_shared_model(input_shape1, input_shape2, output_shape):\n","    # Encoder input\n","    enc_inputs = Input(shape=(input_shape1, input_shape2))\n","\n","    # Encoder\n","    enc_outputs = transformer_encoder(enc_inputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Decoder input\n","    dec_inputs = Input(shape=(output_shape[1], input_shape2))\n","\n","    # Decoder\n","    dec_outputs = transformer_decoder(dec_inputs, enc_outputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Global pooling\n","    x = GlobalAveragePooling1D()(dec_outputs)\n","\n","    # Shared dense layer\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","\n","    # Task-specific output layers\n","    outputs = []\n","    for i in range(output_shape[1]):\n","        output = Dense(1, name=f'output_{i}')(x)\n","        outputs.append(output)\n","\n","    return Model([enc_inputs, dec_inputs], outputs)\n","\n","for iteration in range(5):\n","    # Reshape inputs\n","    train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","    test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","    val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","    # Create decoder inputs\n","    train_dec_input = np.zeros((train_input_reshaped.shape[0], output_train.shape[1], train_input_reshaped.shape[2]))\n","    val_dec_input = np.zeros((val_input_reshaped.shape[0], output_train.shape[1], val_input_reshaped.shape[2]))\n","    test_dec_input = np.zeros((test_input_reshaped.shape[0], output_test.shape[1], test_input_reshaped.shape[2]))\n","\n","    # Create the hard parameter sharing model\n","    model = get_hard_shared_model(input_train.shape[1], input_train.shape[2], output_train.shape)\n","\n","    # Compile and train the model\n","    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=[['mse'] for _ in range(output_train.shape[1])])\n","    best_val = 1000000\n","    patience = 0\n","    best_model = None\n","\n","    for k in range(200):\n","        # Train the model\n","        model.fit([train_input_reshaped, train_dec_input],\n","                  [output_train[:, i] for i in range(output_train.shape[1])],\n","                  epochs=1, batch_size=32, verbose=1)\n","\n","        # Predict validation data\n","        pred_val = np.array(model.predict([val_input_reshaped, val_dec_input]))\n","        pred_val = np.transpose(pred_val, (1, 0, 2)).squeeze()\n","        print(\"k:\", k, \"patience:\", patience)\n","\n","        # Evaluate the model\n","        losses = []\n","        for i in range(pred_val.shape[0]):\n","            total_ssq = 0\n","            for j in range(3):\n","                total_ssq = np.sum(pred_val[i,j] * (max_val[j] - min_val[j]) + min_val[j]) + total_ssq\n","            total_ssq = total_ssq * 3.74\n","            output_val_ssq = output_val[i,0]\n","            loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","            losses.append(loss)\n","        tmp_val_loss = np.mean(losses)\n","        if tmp_val_loss <= best_val:\n","            best_val = tmp_val_loss\n","            patience = 0\n","            best_model = model\n","        else:\n","            patience += 1\n","            if patience > 10:\n","                break\n","\n","    # Predict test data\n","    pred_test = np.array(best_model.predict([test_input_reshaped, test_dec_input]))\n","    pred_test = np.transpose(pred_test, (1, 0, 2)).squeeze()\n","    pred_test_n = np.zeros((pred_test.shape[0], 1))\n","    pred_test_o = np.zeros((pred_test.shape[0], 1))\n","    pred_test_d = np.zeros((pred_test.shape[0], 1))\n","    pred_test_final = np.empty((output_test.shape[0], 0))\n","    for m in range(pred_test.shape[0]):\n","      pred_test_n[m,0] = pred_test[m,0]*(max_val[0]-min_val[0]) + min_val[0]\n","      pred_test_o[m,0] = pred_test[m,1]*(max_val[1]-min_val[1]) + min_val[1]\n","      pred_test_d[m,0] = pred_test[m,2]*(max_val[2]-min_val[2]) + min_val[2]\n","\n","    pred_test_final=np.hstack((pred_test_final, pred_test_n))\n","    pred_test_final=np.hstack((pred_test_final, pred_test_o))\n","    pred_test_final=np.hstack((pred_test_final, pred_test_d))\n","\n","    # Overall Test Loss\n","    loss_n = sklearn.metrics.mean_squared_error(pred_test_final[:,0], output_test[:,0], squared = False)\n","    rmse_n.append(loss_n)\n","    loss_o = sklearn.metrics.mean_squared_error(pred_test_final[:,1], output_test[:,1], squared = False)\n","    rmse_o.append(loss_o)\n","    loss_d= sklearn.metrics.mean_squared_error(pred_test_final[:,2], output_test[:,2], squared = False)\n","    rmse_d.append(loss_d)\n","rmse_combined = np.column_stack((rmse_n, rmse_o, rmse_d))\n","rmse_n_loss = sum(rmse_n) / len(rmse_n)\n","rmse_o_loss = sum(rmse_o) / len(rmse_o)\n","rmse_d_loss = sum(rmse_d) / len(rmse_d)\n","average_rmse = np.array([rmse_n_loss, rmse_o_loss, rmse_d_loss])\n","\n","print(rmse_n_loss,rmse_o_loss,rmse_d_loss)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwQxjLfDa65h9rpy+LToHX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}