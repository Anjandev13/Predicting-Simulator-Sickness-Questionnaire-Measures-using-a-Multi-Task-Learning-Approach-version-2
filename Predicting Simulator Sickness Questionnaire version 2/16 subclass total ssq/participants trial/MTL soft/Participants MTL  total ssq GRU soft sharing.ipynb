{"cells":[{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":200,"status":"ok","timestamp":1724916368735,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fT_A9oAGAepC"},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1560,"status":"ok","timestamp":1724916370490,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"TishlaEBAmlN","outputId":"a96c9ffd-9e24-4130-9d9a-4433c782c7c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724916370491,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"XeSwJ8oKAt2r"},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724916370491,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"BFHyHoFvA5bX"},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1724916370491,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"QeoIWcudA94b"},"outputs":[],"source":["def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","        arrays_3d.append(array_3d)\n","\n","    return arrays_3d\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":233,"status":"ok","timestamp":1724916370720,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fqaeUGUDBCtT"},"outputs":[],"source":["sample_size=60\n","simulations = ['flat','noise','bumps']\n","participants = [str(i) for i in range(1, 27)]  # Participants 101 to 127\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1724916370720,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"vPQyeAYKBYaO"},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[0, n_columns].sum()\n","    o_val = df.iloc[0, o_columns].sum()\n","    d_val = df.iloc[0, d_columns].sum()\n","\n","    return n_val, o_val, d_val"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1724916370720,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"Xpn0lDt0BfvE"},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          # n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          # total_ssq_values.append([n_val, o_val, d_val])\n","          ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":6690,"status":"ok","timestamp":1724916377407,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"7k17K0HrCr6-"},"outputs":[],"source":["participants_group_1 = [1,3,4,11,25]\n","participants_group_2 = [2,7,8,9,17]\n","participants_group_3 = [10,12,13,22,23]\n","participants_group_4 = [5,14,18,20,21]\n","participants_group_5 = [6,15,16,19,24,26]\n","\n","arrays_group_1 = construct_3d_array(base_path, participants_group_1, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_2 = construct_3d_array(base_path, participants_group_2, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_3 = construct_3d_array(base_path, participants_group_3, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_4 = construct_3d_array(base_path, participants_group_4, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_5 = construct_3d_array(base_path, participants_group_5, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724916377408,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"26ADF-kiC1EZ"},"outputs":[],"source":["# Concatenate arrays along the first axis\n","input_group_1 = np.concatenate(arrays_group_1, axis=0)\n","input_group_2 = np.concatenate(arrays_group_2, axis=0)\n","input_group_3 = np.concatenate(arrays_group_3, axis=0)\n","input_group_4 = np.concatenate(arrays_group_4, axis=0)\n","input_group_5 = np.concatenate(arrays_group_5, axis=0)\n"]},{"cell_type":"code","source":["output_group_1=merge_ssq_column(simulations,participants_group_1)\n","output_group_2=merge_ssq_column(simulations,participants_group_2)\n","output_group_3=merge_ssq_column(simulations,participants_group_3)\n","output_group_4=merge_ssq_column(simulations,participants_group_4)\n","output_group_5=merge_ssq_column(simulations,participants_group_5)\n","\n","output_group_1 = np.squeeze(output_group_1)\n","output_group_2 = np.squeeze(output_group_2)\n","output_group_3 = np.squeeze(output_group_3)\n","output_group_4 = np.squeeze(output_group_4)\n","output_group_5 = np.squeeze(output_group_5)\n","\n","\n","output_total_ssq_group_1=merge_total_ssq(simulations,participants_group_1)\n","output_total_ssq_group_2=merge_total_ssq(simulations,participants_group_2)\n","output_total_ssq_group_3=merge_total_ssq(simulations,participants_group_3)\n","output_total_ssq_group_4=merge_total_ssq(simulations,participants_group_4)\n","output_total_ssq_group_5=merge_total_ssq(simulations,participants_group_5)\n","\n","output_total_ssq_group_1=output_total_ssq_group_1.reshape(-1, 1)\n","output_total_ssq_group_2=output_total_ssq_group_2.reshape(-1, 1)\n","output_total_ssq_group_3=output_total_ssq_group_3.reshape(-1, 1)\n","output_total_ssq_group_4=output_total_ssq_group_4.reshape(-1, 1)\n","output_total_ssq_group_5=output_total_ssq_group_5.reshape(-1, 1)\n","\n"],"metadata":{"id":"gSu7F2MHsI4v","executionInfo":{"status":"ok","timestamp":1724916378104,"user_tz":300,"elapsed":702,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"],"metadata":{"id":"hEGUDzs3hGXO","executionInfo":{"status":"ok","timestamp":1724916378104,"user_tz":300,"elapsed":8,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E6ssyYUeDJwI","outputId":"dbc6c859-a718-40f1-aadf-ab36b4f12f91"},"outputs":[{"output_type":"stream","name":"stdout","text":["input_train : (38, 120, 47)\n","output_train : (38, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (16, 120, 47)\n","output_test : (16, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 622ms/step - loss: 183.1399 - sequential_80_mse: 0.1617 - sequential_81_mse: 0.1254 - sequential_82_mse: 0.1001 - sequential_83_mse: 0.1446 - sequential_84_mse: 0.1035 - sequential_85_mse: 0.0785 - sequential_86_mse: 0.1325 - sequential_87_mse: 0.1538 - sequential_88_mse: 0.0703 - sequential_89_mse: 0.0697 - sequential_90_mse: 0.1294 - sequential_91_mse: 0.0912 - sequential_92_mse: 0.1225 - sequential_93_mse: 0.0982 - sequential_94_mse: 0.1683 - sequential_95_mse: 0.0750\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 175.9966 - sequential_80_mse: 0.1010 - sequential_81_mse: 0.0919 - sequential_82_mse: 0.0695 - sequential_83_mse: 0.0954 - sequential_84_mse: 0.0733 - sequential_85_mse: 0.0733 - sequential_86_mse: 0.1228 - sequential_87_mse: 0.0903 - sequential_88_mse: 0.0832 - sequential_89_mse: 0.0773 - sequential_90_mse: 0.1426 - sequential_91_mse: 0.0790 - sequential_92_mse: 0.0789 - sequential_93_mse: 0.0779 - sequential_94_mse: 0.1179 - sequential_95_mse: 0.0989   \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 593ms/step - loss: 169.1580 - sequential_80_mse: 0.0893 - sequential_81_mse: 0.0737 - sequential_82_mse: 0.0579 - sequential_83_mse: 0.1132 - sequential_84_mse: 0.0488 - sequential_85_mse: 0.0826 - sequential_86_mse: 0.1148 - sequential_87_mse: 0.0874 - sequential_88_mse: 0.0511 - sequential_89_mse: 0.0715 - sequential_90_mse: 0.0525 - sequential_91_mse: 0.0658 - sequential_92_mse: 0.0624 - sequential_93_mse: 0.0867 - sequential_94_mse: 0.0975 - sequential_95_mse: 0.0762\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - loss: 162.7507 - sequential_80_mse: 0.0675 - sequential_81_mse: 0.0722 - sequential_82_mse: 0.0891 - sequential_83_mse: 0.0893 - sequential_84_mse: 0.0580 - sequential_85_mse: 0.0775 - sequential_86_mse: 0.1189 - sequential_87_mse: 0.0902 - sequential_88_mse: 0.0422 - sequential_89_mse: 0.0608 - sequential_90_mse: 0.0655 - sequential_91_mse: 0.0779 - sequential_92_mse: 0.0577 - sequential_93_mse: 0.0940 - sequential_94_mse: 0.0940 - sequential_95_mse: 0.0944\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step - loss: 156.2520 - sequential_80_mse: 0.0702 - sequential_81_mse: 0.0511 - sequential_82_mse: 0.0333 - sequential_83_mse: 0.0667 - sequential_84_mse: 0.0548 - sequential_85_mse: 0.0437 - sequential_86_mse: 0.0953 - sequential_87_mse: 0.0703 - sequential_88_mse: 0.0380 - sequential_89_mse: 0.0485 - sequential_90_mse: 0.0727 - sequential_91_mse: 0.0631 - sequential_92_mse: 0.0576 - sequential_93_mse: 0.0663 - sequential_94_mse: 0.0956 - sequential_95_mse: 0.0741\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step - loss: 150.1963 - sequential_80_mse: 0.0558 - sequential_81_mse: 0.0716 - sequential_82_mse: 0.0470 - sequential_83_mse: 0.0921 - sequential_84_mse: 0.0516 - sequential_85_mse: 0.0540 - sequential_86_mse: 0.1118 - sequential_87_mse: 0.0694 - sequential_88_mse: 0.0415 - sequential_89_mse: 0.0571 - sequential_90_mse: 0.0502 - sequential_91_mse: 0.0667 - sequential_92_mse: 0.0443 - sequential_93_mse: 0.0859 - sequential_94_mse: 0.0710 - sequential_95_mse: 0.0560\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588ms/step - loss: 144.2163 - sequential_80_mse: 0.0555 - sequential_81_mse: 0.0569 - sequential_82_mse: 0.0647 - sequential_83_mse: 0.1027 - sequential_84_mse: 0.0513 - sequential_85_mse: 0.0551 - sequential_86_mse: 0.0914 - sequential_87_mse: 0.0595 - sequential_88_mse: 0.0371 - sequential_89_mse: 0.0463 - sequential_90_mse: 0.0381 - sequential_91_mse: 0.0448 - sequential_92_mse: 0.0394 - sequential_93_mse: 0.0607 - sequential_94_mse: 0.0891 - sequential_95_mse: 0.0587\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n","k: 6 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - loss: 138.4482 - sequential_80_mse: 0.0514 - sequential_81_mse: 0.0508 - sequential_82_mse: 0.0429 - sequential_83_mse: 0.0714 - sequential_84_mse: 0.0424 - sequential_85_mse: 0.0675 - sequential_86_mse: 0.0815 - sequential_87_mse: 0.0727 - sequential_88_mse: 0.0346 - sequential_89_mse: 0.0528 - sequential_90_mse: 0.0485 - sequential_91_mse: 0.0585 - sequential_92_mse: 0.0464 - sequential_93_mse: 0.0589 - sequential_94_mse: 0.0691 - sequential_95_mse: 0.0562   \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n","k: 7 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 875ms/step - loss: 132.8308 - sequential_80_mse: 0.0541 - sequential_81_mse: 0.0502 - sequential_82_mse: 0.0283 - sequential_83_mse: 0.0703 - sequential_84_mse: 0.0435 - sequential_85_mse: 0.0567 - sequential_86_mse: 0.0884 - sequential_87_mse: 0.0502 - sequential_88_mse: 0.0425 - sequential_89_mse: 0.0308 - sequential_90_mse: 0.0401 - sequential_91_mse: 0.0509 - sequential_92_mse: 0.0473 - sequential_93_mse: 0.0492 - sequential_94_mse: 0.0779 - sequential_95_mse: 0.0465\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n","k: 8 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step - loss: 127.4397 - sequential_80_mse: 0.0854 - sequential_81_mse: 0.0302 - sequential_82_mse: 0.0268 - sequential_83_mse: 0.0724 - sequential_84_mse: 0.0329 - sequential_85_mse: 0.0553 - sequential_86_mse: 0.0677 - sequential_87_mse: 0.0524 - sequential_88_mse: 0.0421 - sequential_89_mse: 0.0365 - sequential_90_mse: 0.0302 - sequential_91_mse: 0.0510 - sequential_92_mse: 0.0416 - sequential_93_mse: 0.0484 - sequential_94_mse: 0.0771 - sequential_95_mse: 0.0431\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n","k: 9 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step - loss: 122.2268 - sequential_80_mse: 0.0544 - sequential_81_mse: 0.0374 - sequential_82_mse: 0.0339 - sequential_83_mse: 0.0610 - sequential_84_mse: 0.0347 - sequential_85_mse: 0.0500 - sequential_86_mse: 0.0875 - sequential_87_mse: 0.0759 - sequential_88_mse: 0.0352 - sequential_89_mse: 0.0312 - sequential_90_mse: 0.0276 - sequential_91_mse: 0.0404 - sequential_92_mse: 0.0433 - sequential_93_mse: 0.0407 - sequential_94_mse: 0.0580 - sequential_95_mse: 0.0442\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n","k: 10 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step - loss: 117.3028 - sequential_80_mse: 0.0446 - sequential_81_mse: 0.0405 - sequential_82_mse: 0.0236 - sequential_83_mse: 0.0588 - sequential_84_mse: 0.0376 - sequential_85_mse: 0.0537 - sequential_86_mse: 0.1005 - sequential_87_mse: 0.0750 - sequential_88_mse: 0.0262 - sequential_89_mse: 0.0395 - sequential_90_mse: 0.0414 - sequential_91_mse: 0.0567 - sequential_92_mse: 0.0475 - sequential_93_mse: 0.0625 - sequential_94_mse: 0.0763 - sequential_95_mse: 0.0426\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n","k: 11 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - loss: 112.5255 - sequential_80_mse: 0.0465 - sequential_81_mse: 0.0389 - sequential_82_mse: 0.0211 - sequential_83_mse: 0.0734 - sequential_84_mse: 0.0527 - sequential_85_mse: 0.0628 - sequential_86_mse: 0.0889 - sequential_87_mse: 0.0583 - sequential_88_mse: 0.0290 - sequential_89_mse: 0.0436 - sequential_90_mse: 0.0545 - sequential_91_mse: 0.0839 - sequential_92_mse: 0.0445 - sequential_93_mse: 0.0543 - sequential_94_mse: 0.0643 - sequential_95_mse: 0.0534\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n","k: 12 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Test Loss no  0 : 32.677088817276314\n","input_train : (38, 120, 47)\n","output_train : (38, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (16, 120, 47)\n","output_test : (16, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 182.7524 - sequential_100_mse: 0.1281 - sequential_101_mse: 0.1036 - sequential_102_mse: 0.1326 - sequential_103_mse: 0.1517 - sequential_104_mse: 0.0475 - sequential_105_mse: 0.0772 - sequential_106_mse: 0.0591 - sequential_107_mse: 0.1148 - sequential_108_mse: 0.0521 - sequential_109_mse: 0.0385 - sequential_110_mse: 0.1014 - sequential_111_mse: 0.0879 - sequential_96_mse: 0.0832 - sequential_97_mse: 0.0734 - sequential_98_mse: 0.0855 - sequential_99_mse: 0.1083\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step - loss: 175.9017 - sequential_100_mse: 0.0691 - sequential_101_mse: 0.0835 - sequential_102_mse: 0.1051 - sequential_103_mse: 0.2128 - sequential_104_mse: 0.0588 - sequential_105_mse: 0.0643 - sequential_106_mse: 0.0359 - sequential_107_mse: 0.0807 - sequential_108_mse: 0.0670 - sequential_109_mse: 0.0352 - sequential_110_mse: 0.0968 - sequential_111_mse: 0.0729 - sequential_96_mse: 0.1287 - sequential_97_mse: 0.0647 - sequential_98_mse: 0.0748 - sequential_99_mse: 0.1755\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step - loss: 169.0459 - sequential_100_mse: 0.0417 - sequential_101_mse: 0.1108 - sequential_102_mse: 0.1101 - sequential_103_mse: 0.0921 - sequential_104_mse: 0.0331 - sequential_105_mse: 0.0620 - sequential_106_mse: 0.0271 - sequential_107_mse: 0.0887 - sequential_108_mse: 0.0485 - sequential_109_mse: 0.0370 - sequential_110_mse: 0.0882 - sequential_111_mse: 0.0883 - sequential_96_mse: 0.1119 - sequential_97_mse: 0.0897 - sequential_98_mse: 0.0729 - sequential_99_mse: 0.0906\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - loss: 162.4753 - sequential_100_mse: 0.0405 - sequential_101_mse: 0.0716 - sequential_102_mse: 0.0873 - sequential_103_mse: 0.1775 - sequential_104_mse: 0.0356 - sequential_105_mse: 0.0501 - sequential_106_mse: 0.0275 - sequential_107_mse: 0.0699 - sequential_108_mse: 0.0420 - sequential_109_mse: 0.0285 - sequential_110_mse: 0.0623 - sequential_111_mse: 0.0629 - sequential_96_mse: 0.0996 - sequential_97_mse: 0.0641 - sequential_98_mse: 0.0777 - sequential_99_mse: 0.0810\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - loss: 156.1257 - sequential_100_mse: 0.0446 - sequential_101_mse: 0.0697 - sequential_102_mse: 0.0915 - sequential_103_mse: 0.1745 - sequential_104_mse: 0.0230 - sequential_105_mse: 0.0388 - sequential_106_mse: 0.0177 - sequential_107_mse: 0.0583 - sequential_108_mse: 0.0405 - sequential_109_mse: 0.0197 - sequential_110_mse: 0.0727 - sequential_111_mse: 0.0681 - sequential_96_mse: 0.0898 - sequential_97_mse: 0.0459 - sequential_98_mse: 0.0626 - sequential_99_mse: 0.0869   \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n","k: 4 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 875ms/step - loss: 149.9202 - sequential_100_mse: 0.0331 - sequential_101_mse: 0.0799 - sequential_102_mse: 0.0692 - sequential_103_mse: 0.0954 - sequential_104_mse: 0.0301 - sequential_105_mse: 0.0340 - sequential_106_mse: 0.0165 - sequential_107_mse: 0.0594 - sequential_108_mse: 0.0389 - sequential_109_mse: 0.0148 - sequential_110_mse: 0.0833 - sequential_111_mse: 0.0704 - sequential_96_mse: 0.0710 - sequential_97_mse: 0.0621 - sequential_98_mse: 0.0538 - sequential_99_mse: 0.0792\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n","k: 5 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step - loss: 143.9302 - sequential_100_mse: 0.0266 - sequential_101_mse: 0.0613 - sequential_102_mse: 0.0691 - sequential_103_mse: 0.0984 - sequential_104_mse: 0.0222 - sequential_105_mse: 0.0365 - sequential_106_mse: 0.0272 - sequential_107_mse: 0.0764 - sequential_108_mse: 0.0329 - sequential_109_mse: 0.0184 - sequential_110_mse: 0.0854 - sequential_111_mse: 0.0489 - sequential_96_mse: 0.0714 - sequential_97_mse: 0.0390 - sequential_98_mse: 0.0475 - sequential_99_mse: 0.0512\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n","k: 6 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step - loss: 138.2558 - sequential_100_mse: 0.0401 - sequential_101_mse: 0.0580 - sequential_102_mse: 0.0918 - sequential_103_mse: 0.1192 - sequential_104_mse: 0.0188 - sequential_105_mse: 0.0259 - sequential_106_mse: 0.0265 - sequential_107_mse: 0.0588 - sequential_108_mse: 0.0340 - sequential_109_mse: 0.0172 - sequential_110_mse: 0.0841 - sequential_111_mse: 0.0493 - sequential_96_mse: 0.0573 - sequential_97_mse: 0.0525 - sequential_98_mse: 0.0543 - sequential_99_mse: 0.0791\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 7 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - loss: 132.5894 - sequential_100_mse: 0.0311 - sequential_101_mse: 0.0426 - sequential_102_mse: 0.0754 - sequential_103_mse: 0.1038 - sequential_104_mse: 0.0227 - sequential_105_mse: 0.0316 - sequential_106_mse: 0.0184 - sequential_107_mse: 0.0511 - sequential_108_mse: 0.0274 - sequential_109_mse: 0.0143 - sequential_110_mse: 0.0608 - sequential_111_mse: 0.0487 - sequential_96_mse: 0.0738 - sequential_97_mse: 0.0415 - sequential_98_mse: 0.0404 - sequential_99_mse: 0.0654\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n","k: 8 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step - loss: 127.2367 - sequential_100_mse: 0.0257 - sequential_101_mse: 0.0545 - sequential_102_mse: 0.0757 - sequential_103_mse: 0.0988 - sequential_104_mse: 0.0240 - sequential_105_mse: 0.0276 - sequential_106_mse: 0.0179 - sequential_107_mse: 0.0660 - sequential_108_mse: 0.0288 - sequential_109_mse: 0.0185 - sequential_110_mse: 0.0718 - sequential_111_mse: 0.0458 - sequential_96_mse: 0.0738 - sequential_97_mse: 0.0415 - sequential_98_mse: 0.0388 - sequential_99_mse: 0.0552\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n","k: 9 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 121.9963 - sequential_100_mse: 0.0245 - sequential_101_mse: 0.0478 - sequential_102_mse: 0.0641 - sequential_103_mse: 0.0911 - sequential_104_mse: 0.0217 - sequential_105_mse: 0.0224 - sequential_106_mse: 0.0171 - sequential_107_mse: 0.0612 - sequential_108_mse: 0.0220 - sequential_109_mse: 0.0146 - sequential_110_mse: 0.0634 - sequential_111_mse: 0.0592 - sequential_96_mse: 0.0606 - sequential_97_mse: 0.0360 - sequential_98_mse: 0.0543 - sequential_99_mse: 0.0528\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n","k: 10 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 627ms/step - loss: 116.9596 - sequential_100_mse: 0.0258 - sequential_101_mse: 0.0463 - sequential_102_mse: 0.0646 - sequential_103_mse: 0.1052 - sequential_104_mse: 0.0177 - sequential_105_mse: 0.0240 - sequential_106_mse: 0.0192 - sequential_107_mse: 0.0420 - sequential_108_mse: 0.0276 - sequential_109_mse: 0.0144 - sequential_110_mse: 0.0540 - sequential_111_mse: 0.0477 - sequential_96_mse: 0.0530 - sequential_97_mse: 0.0411 - sequential_98_mse: 0.0416 - sequential_99_mse: 0.0634\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n","k: 11 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step - loss: 112.0841 - sequential_100_mse: 0.0295 - sequential_101_mse: 0.0446 - sequential_102_mse: 0.0571 - sequential_103_mse: 0.0965 - sequential_104_mse: 0.0149 - sequential_105_mse: 0.0257 - sequential_106_mse: 0.0177 - sequential_107_mse: 0.0487 - sequential_108_mse: 0.0248 - sequential_109_mse: 0.0138 - sequential_110_mse: 0.0488 - sequential_111_mse: 0.0377 - sequential_96_mse: 0.0582 - sequential_97_mse: 0.0335 - sequential_98_mse: 0.0536 - sequential_99_mse: 0.0432\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n","k: 12 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591ms/step - loss: 107.4391 - sequential_100_mse: 0.0230 - sequential_101_mse: 0.0462 - sequential_102_mse: 0.0641 - sequential_103_mse: 0.0863 - sequential_104_mse: 0.0191 - sequential_105_mse: 0.0252 - sequential_106_mse: 0.0151 - sequential_107_mse: 0.0491 - sequential_108_mse: 0.0342 - sequential_109_mse: 0.0140 - sequential_110_mse: 0.0568 - sequential_111_mse: 0.0495 - sequential_96_mse: 0.0547 - sequential_97_mse: 0.0329 - sequential_98_mse: 0.0430 - sequential_99_mse: 0.0542\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 13 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Test Loss no  1 : 20.256429704310563\n","input_train : (38, 120, 47)\n","output_train : (38, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (16, 120, 47)\n","output_test : (16, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 616ms/step - loss: 181.9321 - sequential_112_mse: 0.2907 - sequential_113_mse: 0.0960 - sequential_114_mse: 0.0916 - sequential_115_mse: 0.1340 - sequential_116_mse: 0.0828 - sequential_117_mse: 0.0821 - sequential_118_mse: 0.1402 - sequential_119_mse: 0.1190 - sequential_120_mse: 0.0885 - sequential_121_mse: 0.0718 - sequential_122_mse: 0.0521 - sequential_123_mse: 0.1546 - sequential_124_mse: 0.0549 - sequential_125_mse: 0.1165 - sequential_126_mse: 0.1308 - sequential_127_mse: 0.1177\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 878ms/step - loss: 174.7582 - sequential_112_mse: 0.1213 - sequential_113_mse: 0.0811 - sequential_114_mse: 0.0620 - sequential_115_mse: 0.1062 - sequential_116_mse: 0.0621 - sequential_117_mse: 0.0924 - sequential_118_mse: 0.1139 - sequential_119_mse: 0.1276 - sequential_120_mse: 0.0714 - sequential_121_mse: 0.0616 - sequential_122_mse: 0.0525 - sequential_123_mse: 0.1046 - sequential_124_mse: 0.0470 - sequential_125_mse: 0.0671 - sequential_126_mse: 0.1137 - sequential_127_mse: 0.1373\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 168.2442 - sequential_112_mse: 0.1391 - sequential_113_mse: 0.0991 - sequential_114_mse: 0.1157 - sequential_115_mse: 0.0740 - sequential_116_mse: 0.0647 - sequential_117_mse: 0.0612 - sequential_118_mse: 0.1603 - sequential_119_mse: 0.1233 - sequential_120_mse: 0.0805 - sequential_121_mse: 0.0675 - sequential_122_mse: 0.0556 - sequential_123_mse: 0.0757 - sequential_124_mse: 0.0798 - sequential_125_mse: 0.0484 - sequential_126_mse: 0.1268 - sequential_127_mse: 0.1164\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591ms/step - loss: 161.6163 - sequential_112_mse: 0.1135 - sequential_113_mse: 0.0711 - sequential_114_mse: 0.0771 - sequential_115_mse: 0.0549 - sequential_116_mse: 0.0569 - sequential_117_mse: 0.0594 - sequential_118_mse: 0.1392 - sequential_119_mse: 0.1050 - sequential_120_mse: 0.0662 - sequential_121_mse: 0.0393 - sequential_122_mse: 0.0514 - sequential_123_mse: 0.0902 - sequential_124_mse: 0.0611 - sequential_125_mse: 0.0844 - sequential_126_mse: 0.1309 - sequential_127_mse: 0.0651\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - loss: 155.2225 - sequential_112_mse: 0.0880 - sequential_113_mse: 0.0753 - sequential_114_mse: 0.0471 - sequential_115_mse: 0.0688 - sequential_116_mse: 0.0358 - sequential_117_mse: 0.0659 - sequential_118_mse: 0.0973 - sequential_119_mse: 0.0893 - sequential_120_mse: 0.0496 - sequential_121_mse: 0.0824 - sequential_122_mse: 0.0464 - sequential_123_mse: 0.0958 - sequential_124_mse: 0.0457 - sequential_125_mse: 0.0495 - sequential_126_mse: 0.0819 - sequential_127_mse: 0.0827\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step - loss: 149.1436 - sequential_112_mse: 0.0894 - sequential_113_mse: 0.0541 - sequential_114_mse: 0.0601 - sequential_115_mse: 0.0761 - sequential_116_mse: 0.0468 - sequential_117_mse: 0.0511 - sequential_118_mse: 0.1055 - sequential_119_mse: 0.1238 - sequential_120_mse: 0.0369 - sequential_121_mse: 0.0594 - sequential_122_mse: 0.0358 - sequential_123_mse: 0.0763 - sequential_124_mse: 0.0371 - sequential_125_mse: 0.0476 - sequential_126_mse: 0.1003 - sequential_127_mse: 0.0780\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 996ms/step - loss: 143.2732 - sequential_112_mse: 0.0804 - sequential_113_mse: 0.0646 - sequential_114_mse: 0.0529 - sequential_115_mse: 0.0591 - sequential_116_mse: 0.0392 - sequential_117_mse: 0.0462 - sequential_118_mse: 0.1359 - sequential_119_mse: 0.1082 - sequential_120_mse: 0.0440 - sequential_121_mse: 0.0461 - sequential_122_mse: 0.0346 - sequential_123_mse: 0.0635 - sequential_124_mse: 0.0468 - sequential_125_mse: 0.0726 - sequential_126_mse: 0.1085 - sequential_127_mse: 0.0789\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n","k: 6 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 137.4339 - sequential_112_mse: 0.0841 - sequential_113_mse: 0.0564 - sequential_114_mse: 0.0363 - sequential_115_mse: 0.0469 - sequential_116_mse: 0.0268 - sequential_117_mse: 0.0615 - sequential_118_mse: 0.1026 - sequential_119_mse: 0.0752 - sequential_120_mse: 0.0426 - sequential_121_mse: 0.0467 - sequential_122_mse: 0.0351 - sequential_123_mse: 0.0647 - sequential_124_mse: 0.0377 - sequential_125_mse: 0.0455 - sequential_126_mse: 0.1128 - sequential_127_mse: 0.0575\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step\n","k: 7 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591ms/step - loss: 131.9091 - sequential_112_mse: 0.0823 - sequential_113_mse: 0.0651 - sequential_114_mse: 0.0438 - sequential_115_mse: 0.0451 - sequential_116_mse: 0.0360 - sequential_117_mse: 0.0638 - sequential_118_mse: 0.1001 - sequential_119_mse: 0.0881 - sequential_120_mse: 0.0328 - sequential_121_mse: 0.0483 - sequential_122_mse: 0.0277 - sequential_123_mse: 0.0606 - sequential_124_mse: 0.0309 - sequential_125_mse: 0.0467 - sequential_126_mse: 0.0818 - sequential_127_mse: 0.0665\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n","k: 8 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - loss: 126.5445 - sequential_112_mse: 0.0822 - sequential_113_mse: 0.0485 - sequential_114_mse: 0.0364 - sequential_115_mse: 0.0402 - sequential_116_mse: 0.0460 - sequential_117_mse: 0.0520 - sequential_118_mse: 0.0990 - sequential_119_mse: 0.0909 - sequential_120_mse: 0.0338 - sequential_121_mse: 0.0424 - sequential_122_mse: 0.0371 - sequential_123_mse: 0.0510 - sequential_124_mse: 0.0356 - sequential_125_mse: 0.0473 - sequential_126_mse: 0.0874 - sequential_127_mse: 0.0593\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 9 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618ms/step - loss: 121.4255 - sequential_112_mse: 0.0647 - sequential_113_mse: 0.0563 - sequential_114_mse: 0.0430 - sequential_115_mse: 0.0476 - sequential_116_mse: 0.0383 - sequential_117_mse: 0.0676 - sequential_118_mse: 0.0904 - sequential_119_mse: 0.0913 - sequential_120_mse: 0.0301 - sequential_121_mse: 0.0394 - sequential_122_mse: 0.0346 - sequential_123_mse: 0.0543 - sequential_124_mse: 0.0368 - sequential_125_mse: 0.0505 - sequential_126_mse: 0.1181 - sequential_127_mse: 0.0611\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n","k: 10 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618ms/step - loss: 116.2719 - sequential_112_mse: 0.0616 - sequential_113_mse: 0.0478 - sequential_114_mse: 0.0341 - sequential_115_mse: 0.0428 - sequential_116_mse: 0.0242 - sequential_117_mse: 0.0493 - sequential_118_mse: 0.0934 - sequential_119_mse: 0.0764 - sequential_120_mse: 0.0242 - sequential_121_mse: 0.0290 - sequential_122_mse: 0.0319 - sequential_123_mse: 0.0528 - sequential_124_mse: 0.0299 - sequential_125_mse: 0.0335 - sequential_126_mse: 0.0698 - sequential_127_mse: 0.0440\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n","k: 11 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - loss: 111.5404 - sequential_112_mse: 0.0645 - sequential_113_mse: 0.0663 - sequential_114_mse: 0.0372 - sequential_115_mse: 0.0443 - sequential_116_mse: 0.0334 - sequential_117_mse: 0.0537 - sequential_118_mse: 0.0729 - sequential_119_mse: 0.0779 - sequential_120_mse: 0.0276 - sequential_121_mse: 0.0506 - sequential_122_mse: 0.0338 - sequential_123_mse: 0.0451 - sequential_124_mse: 0.0303 - sequential_125_mse: 0.0438 - sequential_126_mse: 0.0746 - sequential_127_mse: 0.0573   \n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n","k: 12 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Test Loss no  2 : 30.090332409132674\n","input_train : (38, 120, 47)\n","output_train : (38, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (16, 120, 47)\n","output_test : (16, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 625ms/step - loss: 181.7599 - sequential_128_mse: 0.2142 - sequential_129_mse: 0.0754 - sequential_130_mse: 0.0659 - sequential_131_mse: 0.0956 - sequential_132_mse: 0.0569 - sequential_133_mse: 0.0695 - sequential_134_mse: 0.1584 - sequential_135_mse: 0.1632 - sequential_136_mse: 0.0538 - sequential_137_mse: 0.0596 - sequential_138_mse: 0.0806 - sequential_139_mse: 0.1056 - sequential_140_mse: 0.0644 - sequential_141_mse: 0.0969 - sequential_142_mse: 0.1734 - sequential_143_mse: 0.0622\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - loss: 175.0794 - sequential_128_mse: 0.2855 - sequential_129_mse: 0.0757 - sequential_130_mse: 0.0849 - sequential_131_mse: 0.1061 - sequential_132_mse: 0.0520 - sequential_133_mse: 0.0769 - sequential_134_mse: 0.1765 - sequential_135_mse: 0.1406 - sequential_136_mse: 0.0664 - sequential_137_mse: 0.0450 - sequential_138_mse: 0.1141 - sequential_139_mse: 0.1306 - sequential_140_mse: 0.0628 - sequential_141_mse: 0.1021 - sequential_142_mse: 0.1018 - sequential_143_mse: 0.0720\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - loss: 168.2620 - sequential_128_mse: 0.1586 - sequential_129_mse: 0.0877 - sequential_130_mse: 0.0236 - sequential_131_mse: 0.1062 - sequential_132_mse: 0.0520 - sequential_133_mse: 0.1024 - sequential_134_mse: 0.1140 - sequential_135_mse: 0.1634 - sequential_136_mse: 0.0384 - sequential_137_mse: 0.0636 - sequential_138_mse: 0.0483 - sequential_139_mse: 0.0655 - sequential_140_mse: 0.0738 - sequential_141_mse: 0.0439 - sequential_142_mse: 0.2254 - sequential_143_mse: 0.0663\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - loss: 161.6227 - sequential_128_mse: 0.1016 - sequential_129_mse: 0.0589 - sequential_130_mse: 0.0472 - sequential_131_mse: 0.0744 - sequential_132_mse: 0.0450 - sequential_133_mse: 0.0795 - sequential_134_mse: 0.1359 - sequential_135_mse: 0.1143 - sequential_136_mse: 0.0410 - sequential_137_mse: 0.0496 - sequential_138_mse: 0.0633 - sequential_139_mse: 0.0729 - sequential_140_mse: 0.0734 - sequential_141_mse: 0.0471 - sequential_142_mse: 0.1165 - sequential_143_mse: 0.0585\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step - loss: 155.3640 - sequential_128_mse: 0.1310 - sequential_129_mse: 0.0580 - sequential_130_mse: 0.0358 - sequential_131_mse: 0.0724 - sequential_132_mse: 0.0491 - sequential_133_mse: 0.0668 - sequential_134_mse: 0.1313 - sequential_135_mse: 0.1054 - sequential_136_mse: 0.0317 - sequential_137_mse: 0.0535 - sequential_138_mse: 0.0500 - sequential_139_mse: 0.0583 - sequential_140_mse: 0.0614 - sequential_141_mse: 0.0367 - sequential_142_mse: 0.1383 - sequential_143_mse: 0.0560\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n","k: 4 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - loss: 149.4671 - sequential_128_mse: 0.1834 - sequential_129_mse: 0.0488 - sequential_130_mse: 0.0192 - sequential_131_mse: 0.0690 - sequential_132_mse: 0.0633 - sequential_133_mse: 0.1026 - sequential_134_mse: 0.1151 - sequential_135_mse: 0.1448 - sequential_136_mse: 0.0408 - sequential_137_mse: 0.0638 - sequential_138_mse: 0.0302 - sequential_139_mse: 0.0646 - sequential_140_mse: 0.0457 - sequential_141_mse: 0.0470 - sequential_142_mse: 0.1991 - sequential_143_mse: 0.0459\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n","k: 5 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 143.3789 - sequential_128_mse: 0.1500 - sequential_129_mse: 0.0395 - sequential_130_mse: 0.0234 - sequential_131_mse: 0.0630 - sequential_132_mse: 0.0369 - sequential_133_mse: 0.0744 - sequential_134_mse: 0.1061 - sequential_135_mse: 0.1297 - sequential_136_mse: 0.0340 - sequential_137_mse: 0.0491 - sequential_138_mse: 0.0423 - sequential_139_mse: 0.0670 - sequential_140_mse: 0.0451 - sequential_141_mse: 0.0306 - sequential_142_mse: 0.1235 - sequential_143_mse: 0.0466\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n","k: 6 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step - loss: 137.5653 - sequential_128_mse: 0.1025 - sequential_129_mse: 0.0613 - sequential_130_mse: 0.0205 - sequential_131_mse: 0.0562 - sequential_132_mse: 0.0310 - sequential_133_mse: 0.0538 - sequential_134_mse: 0.1110 - sequential_135_mse: 0.1039 - sequential_136_mse: 0.0315 - sequential_137_mse: 0.0460 - sequential_138_mse: 0.0371 - sequential_139_mse: 0.0663 - sequential_140_mse: 0.0413 - sequential_141_mse: 0.0273 - sequential_142_mse: 0.1016 - sequential_143_mse: 0.0440\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 7 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step - loss: 132.0463 - sequential_128_mse: 0.1015 - sequential_129_mse: 0.0470 - sequential_130_mse: 0.0153 - sequential_131_mse: 0.0585 - sequential_132_mse: 0.0324 - sequential_133_mse: 0.0650 - sequential_134_mse: 0.1145 - sequential_135_mse: 0.1116 - sequential_136_mse: 0.0329 - sequential_137_mse: 0.0408 - sequential_138_mse: 0.0390 - sequential_139_mse: 0.0494 - sequential_140_mse: 0.0527 - sequential_141_mse: 0.0264 - sequential_142_mse: 0.0985 - sequential_143_mse: 0.0421\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n","k: 8 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step - loss: 126.6658 - sequential_128_mse: 0.0817 - sequential_129_mse: 0.0444 - sequential_130_mse: 0.0145 - sequential_131_mse: 0.0542 - sequential_132_mse: 0.0246 - sequential_133_mse: 0.0554 - sequential_134_mse: 0.1360 - sequential_135_mse: 0.0913 - sequential_136_mse: 0.0312 - sequential_137_mse: 0.0389 - sequential_138_mse: 0.0362 - sequential_139_mse: 0.0456 - sequential_140_mse: 0.0383 - sequential_141_mse: 0.0337 - sequential_142_mse: 0.1113 - sequential_143_mse: 0.0441\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n","k: 9 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - loss: 121.4200 - sequential_128_mse: 0.0955 - sequential_129_mse: 0.0461 - sequential_130_mse: 0.0183 - sequential_131_mse: 0.0519 - sequential_132_mse: 0.0219 - sequential_133_mse: 0.0442 - sequential_134_mse: 0.0967 - sequential_135_mse: 0.1013 - sequential_136_mse: 0.0262 - sequential_137_mse: 0.0375 - sequential_138_mse: 0.0239 - sequential_139_mse: 0.0471 - sequential_140_mse: 0.0292 - sequential_141_mse: 0.0233 - sequential_142_mse: 0.0951 - sequential_143_mse: 0.0347\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n","k: 10 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993ms/step - loss: 116.4774 - sequential_128_mse: 0.0970 - sequential_129_mse: 0.0370 - sequential_130_mse: 0.0143 - sequential_131_mse: 0.0381 - sequential_132_mse: 0.0268 - sequential_133_mse: 0.0541 - sequential_134_mse: 0.0963 - sequential_135_mse: 0.1127 - sequential_136_mse: 0.0298 - sequential_137_mse: 0.0317 - sequential_138_mse: 0.0372 - sequential_139_mse: 0.0542 - sequential_140_mse: 0.0446 - sequential_141_mse: 0.0268 - sequential_142_mse: 0.0927 - sequential_143_mse: 0.0363\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n","k: 11 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - loss: 111.6283 - sequential_128_mse: 0.0836 - sequential_129_mse: 0.0384 - sequential_130_mse: 0.0131 - sequential_131_mse: 0.0384 - sequential_132_mse: 0.0245 - sequential_133_mse: 0.0600 - sequential_134_mse: 0.0898 - sequential_135_mse: 0.0872 - sequential_136_mse: 0.0295 - sequential_137_mse: 0.0437 - sequential_138_mse: 0.0295 - sequential_139_mse: 0.0522 - sequential_140_mse: 0.0370 - sequential_141_mse: 0.0340 - sequential_142_mse: 0.0890 - sequential_143_mse: 0.0361\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n","k: 12 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step - loss: 107.0170 - sequential_128_mse: 0.0965 - sequential_129_mse: 0.0345 - sequential_130_mse: 0.0178 - sequential_131_mse: 0.0509 - sequential_132_mse: 0.0279 - sequential_133_mse: 0.0534 - sequential_134_mse: 0.1087 - sequential_135_mse: 0.0912 - sequential_136_mse: 0.0236 - sequential_137_mse: 0.0448 - sequential_138_mse: 0.0304 - sequential_139_mse: 0.0489 - sequential_140_mse: 0.0326 - sequential_141_mse: 0.0241 - sequential_142_mse: 0.0959 - sequential_143_mse: 0.0298\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n","k: 13 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step - loss: 102.5317 - sequential_128_mse: 0.0970 - sequential_129_mse: 0.0303 - sequential_130_mse: 0.0123 - sequential_131_mse: 0.0455 - sequential_132_mse: 0.0223 - sequential_133_mse: 0.0461 - sequential_134_mse: 0.0959 - sequential_135_mse: 0.0831 - sequential_136_mse: 0.0321 - sequential_137_mse: 0.0415 - sequential_138_mse: 0.0352 - sequential_139_mse: 0.0485 - sequential_140_mse: 0.0387 - sequential_141_mse: 0.0277 - sequential_142_mse: 0.0995 - sequential_143_mse: 0.0398\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n","k: 14 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - loss: 98.2621 - sequential_128_mse: 0.1027 - sequential_129_mse: 0.0341 - sequential_130_mse: 0.0137 - sequential_131_mse: 0.0426 - sequential_132_mse: 0.0313 - sequential_133_mse: 0.0544 - sequential_134_mse: 0.0963 - sequential_135_mse: 0.0870 - sequential_136_mse: 0.0332 - sequential_137_mse: 0.0366 - sequential_138_mse: 0.0339 - sequential_139_mse: 0.0633 - sequential_140_mse: 0.0420 - sequential_141_mse: 0.0264 - sequential_142_mse: 0.0953 - sequential_143_mse: 0.0408\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n","k: 15 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Test Loss no  3 : 30.425091029084523\n","input_train : (38, 120, 47)\n","output_train : (38, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (16, 120, 47)\n","output_test : (16, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 624ms/step - loss: 183.6184 - sequential_144_mse: 0.1997 - sequential_145_mse: 0.3924 - sequential_146_mse: 0.1196 - sequential_147_mse: 0.1028 - sequential_148_mse: 0.0648 - sequential_149_mse: 0.1063 - sequential_150_mse: 0.1647 - sequential_151_mse: 0.1276 - sequential_152_mse: 0.2410 - sequential_153_mse: 0.1042 - sequential_154_mse: 0.0846 - sequential_155_mse: 0.0785 - sequential_156_mse: 0.1856 - sequential_157_mse: 0.1153 - sequential_158_mse: 0.2111 - sequential_159_mse: 0.0889\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 795ms/step - loss: 176.6872 - sequential_144_mse: 0.1527 - sequential_145_mse: 0.0845 - sequential_146_mse: 0.0794 - sequential_147_mse: 0.1294 - sequential_148_mse: 0.0622 - sequential_149_mse: 0.1136 - sequential_150_mse: 0.1564 - sequential_151_mse: 0.0829 - sequential_152_mse: 0.2779 - sequential_153_mse: 0.3338 - sequential_154_mse: 0.1060 - sequential_155_mse: 0.0715 - sequential_156_mse: 0.1916 - sequential_157_mse: 0.1103 - sequential_158_mse: 0.1795 - sequential_159_mse: 0.0811\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step - loss: 169.7097 - sequential_144_mse: 0.0797 - sequential_145_mse: 0.1199 - sequential_146_mse: 0.0498 - sequential_147_mse: 0.0780 - sequential_148_mse: 0.0843 - sequential_149_mse: 0.0994 - sequential_150_mse: 0.0996 - sequential_151_mse: 0.1658 - sequential_152_mse: 0.2167 - sequential_153_mse: 0.1346 - sequential_154_mse: 0.1333 - sequential_155_mse: 0.1096 - sequential_156_mse: 0.0702 - sequential_157_mse: 0.1627 - sequential_158_mse: 0.1138 - sequential_159_mse: 0.0802\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step - loss: 163.1962 - sequential_144_mse: 0.0927 - sequential_145_mse: 0.0651 - sequential_146_mse: 0.0470 - sequential_147_mse: 0.1057 - sequential_148_mse: 0.0873 - sequential_149_mse: 0.1003 - sequential_150_mse: 0.1149 - sequential_151_mse: 0.0832 - sequential_152_mse: 0.2212 - sequential_153_mse: 0.1579 - sequential_154_mse: 0.1074 - sequential_155_mse: 0.0483 - sequential_156_mse: 0.1131 - sequential_157_mse: 0.1215 - sequential_158_mse: 0.1428 - sequential_159_mse: 0.0627\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step - loss: 156.7719 - sequential_144_mse: 0.1109 - sequential_145_mse: 0.0742 - sequential_146_mse: 0.0453 - sequential_147_mse: 0.0808 - sequential_148_mse: 0.0545 - sequential_149_mse: 0.0757 - sequential_150_mse: 0.0973 - sequential_151_mse: 0.0713 - sequential_152_mse: 0.1993 - sequential_153_mse: 0.1562 - sequential_154_mse: 0.0631 - sequential_155_mse: 0.0575 - sequential_156_mse: 0.1093 - sequential_157_mse: 0.0727 - sequential_158_mse: 0.1331 - sequential_159_mse: 0.0662\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n","k: 4 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step - loss: 150.6272 - sequential_144_mse: 0.0779 - sequential_145_mse: 0.0690 - sequential_146_mse: 0.0475 - sequential_147_mse: 0.0690 - sequential_148_mse: 0.0467 - sequential_149_mse: 0.0654 - sequential_150_mse: 0.1168 - sequential_151_mse: 0.0907 - sequential_152_mse: 0.1514 - sequential_153_mse: 0.1299 - sequential_154_mse: 0.0833 - sequential_155_mse: 0.0608 - sequential_156_mse: 0.1039 - sequential_157_mse: 0.1046 - sequential_158_mse: 0.0942 - sequential_159_mse: 0.0630\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step\n","k: 5 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 905ms/step - loss: 144.6761 - sequential_144_mse: 0.0595 - sequential_145_mse: 0.0809 - sequential_146_mse: 0.0327 - sequential_147_mse: 0.0889 - sequential_148_mse: 0.0685 - sequential_149_mse: 0.0719 - sequential_150_mse: 0.0816 - sequential_151_mse: 0.0585 - sequential_152_mse: 0.1744 - sequential_153_mse: 0.1248 - sequential_154_mse: 0.0842 - sequential_155_mse: 0.0429 - sequential_156_mse: 0.0786 - sequential_157_mse: 0.1175 - sequential_158_mse: 0.0850 - sequential_159_mse: 0.0508\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n","k: 6 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 911ms/step - loss: 138.9191 - sequential_144_mse: 0.0748 - sequential_145_mse: 0.0609 - sequential_146_mse: 0.0323 - sequential_147_mse: 0.1059 - sequential_148_mse: 0.0505 - sequential_149_mse: 0.0604 - sequential_150_mse: 0.0821 - sequential_151_mse: 0.0710 - sequential_152_mse: 0.1532 - sequential_153_mse: 0.1254 - sequential_154_mse: 0.0761 - sequential_155_mse: 0.0457 - sequential_156_mse: 0.0779 - sequential_157_mse: 0.0692 - sequential_158_mse: 0.0942 - sequential_159_mse: 0.0649\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n","k: 7 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step - loss: 133.3500 - sequential_144_mse: 0.0665 - sequential_145_mse: 0.0627 - sequential_146_mse: 0.0293 - sequential_147_mse: 0.0768 - sequential_148_mse: 0.0563 - sequential_149_mse: 0.0561 - sequential_150_mse: 0.0948 - sequential_151_mse: 0.0608 - sequential_152_mse: 0.1414 - sequential_153_mse: 0.1020 - sequential_154_mse: 0.0816 - sequential_155_mse: 0.0494 - sequential_156_mse: 0.0748 - sequential_157_mse: 0.0762 - sequential_158_mse: 0.1012 - sequential_159_mse: 0.0682\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n","k: 8 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step - loss: 127.9027 - sequential_144_mse: 0.0664 - sequential_145_mse: 0.0551 - sequential_146_mse: 0.0226 - sequential_147_mse: 0.0694 - sequential_148_mse: 0.0391 - sequential_149_mse: 0.0539 - sequential_150_mse: 0.0737 - sequential_151_mse: 0.0547 - sequential_152_mse: 0.1581 - sequential_153_mse: 0.1000 - sequential_154_mse: 0.0819 - sequential_155_mse: 0.0349 - sequential_156_mse: 0.0802 - sequential_157_mse: 0.0709 - sequential_158_mse: 0.0845 - sequential_159_mse: 0.0503\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n","k: 9 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step - loss: 122.7243 - sequential_144_mse: 0.0524 - sequential_145_mse: 0.0567 - sequential_146_mse: 0.0273 - sequential_147_mse: 0.0602 - sequential_148_mse: 0.0564 - sequential_149_mse: 0.0523 - sequential_150_mse: 0.0775 - sequential_151_mse: 0.0564 - sequential_152_mse: 0.1487 - sequential_153_mse: 0.1052 - sequential_154_mse: 0.1015 - sequential_155_mse: 0.0431 - sequential_156_mse: 0.0706 - sequential_157_mse: 0.0619 - sequential_158_mse: 0.0692 - sequential_159_mse: 0.0456\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n","k: 10 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step - loss: 117.6902 - sequential_144_mse: 0.0439 - sequential_145_mse: 0.0584 - sequential_146_mse: 0.0263 - sequential_147_mse: 0.0671 - sequential_148_mse: 0.0392 - sequential_149_mse: 0.0402 - sequential_150_mse: 0.0687 - sequential_151_mse: 0.0593 - sequential_152_mse: 0.1542 - sequential_153_mse: 0.0884 - sequential_154_mse: 0.0708 - sequential_155_mse: 0.0463 - sequential_156_mse: 0.0752 - sequential_157_mse: 0.0839 - sequential_158_mse: 0.0796 - sequential_159_mse: 0.0418\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n","k: 11 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - loss: 112.8368 - sequential_144_mse: 0.0447 - sequential_145_mse: 0.0446 - sequential_146_mse: 0.0241 - sequential_147_mse: 0.0640 - sequential_148_mse: 0.0398 - sequential_149_mse: 0.0443 - sequential_150_mse: 0.0637 - sequential_151_mse: 0.0475 - sequential_152_mse: 0.1326 - sequential_153_mse: 0.0999 - sequential_154_mse: 0.0625 - sequential_155_mse: 0.0491 - sequential_156_mse: 0.0759 - sequential_157_mse: 0.0730 - sequential_158_mse: 0.0903 - sequential_159_mse: 0.0529\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n","k: 12 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 642ms/step - loss: 108.1759 - sequential_144_mse: 0.0439 - sequential_145_mse: 0.0454 - sequential_146_mse: 0.0230 - sequential_147_mse: 0.0573 - sequential_148_mse: 0.0497 - sequential_149_mse: 0.0469 - sequential_150_mse: 0.0726 - sequential_151_mse: 0.0546 - sequential_152_mse: 0.1153 - sequential_153_mse: 0.0905 - sequential_154_mse: 0.0648 - sequential_155_mse: 0.0449 - sequential_156_mse: 0.0771 - sequential_157_mse: 0.0763 - sequential_158_mse: 0.0804 - sequential_159_mse: 0.0543\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step\n","k: 13 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","Test Loss no  4 : 44.6776184459925\n","average_loss: 31.625312081159315\n"]}],"source":["import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Input, GRU, Dense, Dropout\n","from keras.models import Model\n","import numpy as np\n","import sklearn\n","\n","def soft_parameter_sharing_regularizer(model, alpha=0.01):\n","    GRU_layers = [layer for layer in model.layers if isinstance(layer, GRU)]\n","    if not GRU_layers:\n","        return 0.0\n","\n","    weights = [tf.convert_to_tensor(layer.weights[0]) for layer in GRU_layers]\n","\n","    shared_weights = tf.reduce_mean(tf.stack(weights), axis=0)\n","    return alpha * tf.reduce_sum([tf.reduce_sum(tf.square(w - shared_weights)) for w in weights])\n","\n","def get_individual_GRU(input_shape1, input_shape2):\n","    input_layer = Input(shape=(input_shape1, input_shape2))\n","\n","    GRU_layers = []\n","    for _ in range(output_train.shape[1]):\n","        x = GRU(64, return_sequences=False)(input_layer)\n","        x = Dense(256, activation='relu')(x)\n","        x = Dropout(0.2)(x)\n","        GRU_layers.append(x)\n","\n","    return GRU_layers, input_layer\n","\n","def get_output_model(GRU_outputs, output_shape):\n","    output_models = []\n","    for i in range(output_shape[1]):\n","        output_model = Sequential()\n","        output_model.add(Dense(256, activation='relu'))\n","        output_model.add(Dropout(0.2))\n","        output_model.add(Dense(1))\n","        output_model_output = output_model(GRU_outputs[i])\n","        output_models.append(output_model_output)\n","    return output_models\n","\n","total_losses = []\n","for iteration in range(5):\n","\n","\n","\n","  # Assuming input_groups and output_groups are lists of arrays for the 5 groups\n","    input_groups = [input_group_1, input_group_2, input_group_3, input_group_4, input_group_5]\n","    output_groups = [output_group_1, output_group_2, output_group_3, output_group_4, output_group_5]\n","    ssq_groups = [output_total_ssq_group_1, output_total_ssq_group_2, output_total_ssq_group_3, output_total_ssq_group_4, output_total_ssq_group_5]\n","\n","    # Initialize lists for storing training, validation, and test sets\n","    X_train, X_val, X_test = [], [], []\n","    y_train, y_val, y_test = [], [], []\n","    ssq_train, ssq_val, ssq_test = [], [], []\n","\n","    # Loop over each group\n","    for input_group, output_group, ssq_group in zip(input_groups, output_groups, ssq_groups):\n","        # Step 1: Split the group into a training/validation set (80%) and a test set (20%)\n","        X_temp, X_test_temp, y_temp, y_test_temp, ssq_temp, ssq_test_temp = train_test_split(\n","            input_group, output_group, ssq_group, test_size=0.2)\n","\n","        # Step 2: Split the training/validation set into a training set (60%) and a validation set (20%)\n","        X_train_temp, X_val_temp, y_train_temp, y_val_temp, ssq_train_temp, ssq_val_temp = train_test_split(\n","            X_temp, y_temp, ssq_temp, test_size=0.25)  # 0.25 * 0.8 = 0.2\n","\n","        # Step 3: Append the results to the corresponding lists\n","        X_train.append(X_train_temp)\n","        X_val.append(X_val_temp)\n","        X_test.append(X_test_temp)\n","\n","        y_train.append(y_train_temp)\n","        y_val.append(y_val_temp)\n","        y_test.append(y_test_temp)\n","\n","        ssq_train.append(ssq_train_temp)\n","        ssq_val.append(ssq_val_temp)\n","        ssq_test.append(ssq_test_temp)\n","\n","    # After the loop, concatenate the data for all groups if needed\n","    input_train = np.concatenate(X_train, axis=0)\n","    input_val = np.concatenate(X_val, axis=0)\n","    input_test = np.concatenate(X_test, axis=0)\n","\n","    output_train = np.concatenate(y_train, axis=0)\n","    output_val = np.concatenate(y_val, axis=0)\n","    output_test = np.concatenate(y_test, axis=0)\n","\n","    output_test_total_ssq = np.concatenate(ssq_test, axis=0)\n","    # input_train, input_test= scale_input_data(input_train[:, (60-sample_size):(180-sample_size), :], input_test[:, (60-sample_size):(180-sample_size), :])\n","    # output_train, min_val, max_val = scale_target_var(output_train)\n","\n","\n","    #  this section for scaling both train and validation set simultaniously\n","      # Step 1: Combine the training and validation sets\n","    combined_input = np.concatenate([input_train, input_val], axis=0)\n","    combined_output = np.concatenate([output_train, output_val], axis=0)\n","\n","    # Step 2: Scale the combined input data\n","    # Assuming scale_input_data scales the data based on the combined dataset\n","    combined_input, input_test = scale_input_data(\n","        combined_input[:, (60-sample_size):(180-sample_size), :],\n","        input_test[:, (60-sample_size):(180-sample_size), :]\n","    )\n","\n","    # Step 3: Scale the combined output data\n","    # Assuming scale_target_var scales the data and returns min_val, max_val\n","    combined_output, min_val, max_val = scale_target_var(combined_output)\n","\n","    # Step 4: Split the combined data back into training and validation sets\n","    # Use the original shapes of input_train and input_val to slice the combined arrays\n","    input_train = combined_input[:input_train.shape[0], :, :]\n","    input_val = combined_input[input_train.shape[0]:, :, :]\n","\n","    output_train = combined_output[:output_train.shape[0], :]\n","    output_val = combined_output[output_train.shape[0]:, :]\n","\n","\n","\n","    print(\"input_train :\", input_train.shape)\n","    print(\"output_train :\", output_train.shape)\n","    print(\"input_val :\", input_val.shape)\n","    print(\"output_val :\", output_val.shape)\n","    print(\"input_test :\", input_test.shape)\n","    print(\"output_test :\", output_test.shape)\n","\n","\n","\n","    # Reshape inputs\n","    train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","    test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","    val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","    # Get individual GRU outputs\n","    GRU_outputs, input_layer = get_individual_GRU(input_train.shape[1], input_train.shape[2])\n","\n","    # Create separate output models for each column\n","    output_models = get_output_model(GRU_outputs, output_train.shape)\n","\n","    # Create combined model\n","    model = Model(inputs=input_layer, outputs=output_models)\n","\n","    # Custom loss function\n","    def custom_loss(y_true, y_pred):\n","        mse = tf.keras.losses.mse(y_true, y_pred)\n","        reg_loss = soft_parameter_sharing_regularizer(model)\n","        return mse + reg_loss\n","\n","    # Compile and train the model\n","    model.compile(loss=custom_loss, optimizer='adam', metrics=[['mse'] for _ in range(output_train.shape[1])])\n","\n","    best_val = 1000000\n","    patience = 0\n","    best_model = None\n","\n","    for k in range(200):\n","      model.fit(train_input_reshaped, [output_train[:, i] for i in range(output_train.shape[1])], epochs=1, batch_size=32)\n","      pred_val = np.array(model.predict(val_input_reshaped))\n","      pred_val = np.transpose(pred_val.squeeze(), (1, 0))\n","      print(\"k:\", k, \"patience:\", patience)\n","\n","      losses = []\n","      for i in range(pred_val.shape[0]):\n","        total_ssq=0\n","        for j in [0,5,6,7,8,14,15]:\n","          total_ssq=np.sum(pred_val[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [0,1,2,3,4,8,10]:\n","          total_ssq=np.sum(pred_val[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [4,7,9,10,11,12,13]:\n","          total_ssq=np.sum(pred_val[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","        total_ssq=total_ssq*3.74\n","        output_val_ssq= output_val[i,0]\n","        #print(\"total_ssq\",total_ssq)\n","        #print(\"output_val_ssq\",output_val_ssq)\n","        loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","        losses.append(loss)\n","      tmp_val_loss = np.mean(losses)\n","      if tmp_val_loss <= best_val:\n","          best_val = tmp_val_loss\n","          patience = 0\n","          best_model = model\n","      else:\n","          patience +=1\n","          if patience > 10:\n","            break\n","\n","    # Predict test data\n","    pred_test = np.array(best_model.predict(test_input_reshaped))\n","    pred_test = np.transpose(pred_test.squeeze(), (1, 0))\n","    # Evaluate the model\n","    pred_total_ssq = []\n","    #losses=[]\n","    for i in range(pred_test.shape[0]):\n","        total_ssq=0\n","        for j in [0,5,6,7,8,14,15]:\n","          total_ssq=np.sum(pred_test[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [0,1,2,3,4,8,10]:\n","          total_ssq=np.sum(pred_test[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [4,7,9,10,11,12,13]:\n","          total_ssq=np.sum(pred_test[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","        total_ssq=total_ssq*3.74\n","\n","        pred_total_ssq.append(total_ssq)\n","\n","\n","    # Overall Test Loss\n","    loss = sklearn.metrics.mean_squared_error(pred_total_ssq, output_test_total_ssq, squared = False)\n","    print(\"Test Loss no \",iteration,\":\" ,loss)\n","    total_losses.append(loss)\n","\n","average_loss = sum(total_losses) / len(total_losses)\n","total_losses.append(average_loss)\n","print(\"average_loss:\", average_loss)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYnTOt2i0Z0ZK4Ig1VjnOS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}