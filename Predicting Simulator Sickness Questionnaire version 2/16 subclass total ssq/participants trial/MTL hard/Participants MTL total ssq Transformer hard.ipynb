{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1724917529381,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fT_A9oAGAepC"},"outputs":[],"source":["from google.colab import drive\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from scipy import stats\n","import numpy as np\n","import logging\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import datetime\n","import matplotlib.dates as mdates\n","import os"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1052,"status":"ok","timestamp":1724917530606,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"TishlaEBAmlN","outputId":"3686ec6b-096c-4323-ce5b-035324a7728b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the base path to the desired directory on Google Drive\n","base_path = '/content/drive/MyDrive/Study_1_Data/'"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1724917530606,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"XeSwJ8oKAt2r"},"outputs":[],"source":["def read_csv(file_path):\n","    data = pd.read_csv(file_path)\n","    return data"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1724917530607,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"BFHyHoFvA5bX"},"outputs":[],"source":["def process_data(data, columns_to_remove):\n","    processed_data = data.drop(columns=columns_to_remove).values\n","    return processed_data"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724917530607,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"QeoIWcudA94b"},"outputs":[],"source":["def construct_3d_array(base_dir, participants, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye):\n","    \"\"\"\n","    Construct 3D array from CSV files.\n","    \"\"\"\n","    num_rows = 180  # Define number of rows to keep (last 180 rows)\n","    arrays_3d = []\n","\n","    for participant in participants:\n","        participant_id = f\"{int(participant):02d}\"  # Format participant number to two digits\n","\n","        valid_simulations = []\n","\n","        for simulation in simulations:\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","\n","            # Check if all files exist\n","            if all(os.path.exists(file) for file in [hr_file_path, gsr_file_path, head_file_path, eye_file_path]):\n","                valid_simulations.append(simulation)\n","\n","        num_valid_simulations = len(valid_simulations)\n","        if num_valid_simulations == 0:\n","            continue  # Skip this participant if no valid simulations are found\n","\n","        array_3d = np.zeros((num_valid_simulations, num_rows, 47)) # hr=1, gsr=1, head=15-3, eye=41-8 total columns after removing columns= 48\n","\n","        for s_idx, simulation in enumerate(valid_simulations):\n","            # Process hr data\n","            hr_file_path = os.path.join(base_dir, participant_id, simulation, f'HR{simulation.capitalize()}.csv')\n","            hr_data = read_csv(hr_file_path)\n","            processed_hr_data = process_data(hr_data, columns_to_remove_hr)\n","            processed_hr_data = processed_hr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process gsr data\n","            gsr_file_path = os.path.join(base_dir, participant_id, simulation, f'EDA{simulation.capitalize()}_downsampled.csv')\n","            gsr_data = read_csv(gsr_file_path)\n","            processed_gsr_data = process_data(gsr_data, columns_to_remove_gsr)\n","            processed_gsr_data = processed_gsr_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process head data\n","            head_file_path = os.path.join(base_dir, participant_id, simulation, 'head_tracking_downsampled.csv')\n","            head_data = read_csv(head_file_path)\n","            processed_head_data = process_data(head_data, columns_to_remove_head)\n","            processed_head_data = processed_head_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Process eye data\n","            eye_file_path = os.path.join(base_dir, participant_id, simulation, 'eye_tracking_downsampled.csv')\n","            eye_data = read_csv(eye_file_path)\n","            processed_eye_data = process_data(eye_data, columns_to_remove_eye)\n","            processed_eye_data = processed_eye_data[-num_rows:]  # Keep only the last 180 rows\n","\n","            # Combine processed data\n","            combined_data = np.concatenate((processed_hr_data, processed_gsr_data, processed_head_data, processed_eye_data), axis=1)\n","\n","            array_3d[s_idx, :, :] = combined_data\n","\n","        arrays_3d.append(array_3d)\n","\n","    return arrays_3d\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724917530607,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"fqaeUGUDBCtT"},"outputs":[],"source":["sample_size=60\n","simulations = ['flat','noise','bumps']\n","participants = [str(i) for i in range(1, 27)]  # Participants 101 to 127\n","columns_to_remove_hr = []\n","columns_to_remove_gsr = []\n","columns_to_remove_eye = ['#Frame','Time', 'Unnamed: 40','ConvergenceValid','Left_Eye_Closed','Right_Eye_Closed','LocalGazeValid','WorldGazeValid']\n","columns_to_remove_head = ['#Frame','Time', 'Unnamed: 14']"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1724917530607,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"vPQyeAYKBYaO"},"outputs":[],"source":["def calculate_total_ssq(csv_file):\n","    # Read the CSV file into a DataFrame\n","    df = pd.read_csv(csv_file)\n","    n_columns = [0, 5, 6, 7, 8, 14, 15]\n","    o_columns = [0, 1, 2, 3, 4, 8, 10]\n","    d_columns = [4, 7, 9, 10, 11, 12, 13]\n","\n","    # Calculate sum for each specified set of columns\n","    n_val = df.iloc[0, n_columns].sum()\n","    o_val = df.iloc[0, o_columns].sum()\n","    d_val = df.iloc[0, d_columns].sum()\n","\n","    return n_val, o_val, d_val"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1724917530607,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"Xpn0lDt0BfvE"},"outputs":[],"source":["def merge_ssq_column(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          df = pd.read_csv(csv_path)\n","          # n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          # total_ssq_values.append([n_val, o_val, d_val])\n","          ssq_values_participant = df.iloc[:, 0:17].values.flatten()   # Assuming SSQ values are in columns 1 to 16\n","          total_ssq_values.append(ssq_values_participant)\n","  ssq_array = np.array(total_ssq_values)\n","  return ssq_array\n","\n","def merge_total_ssq(conditions,participants):\n","  directories = []\n","  total_ssq_values = []\n","  for participant in participants:\n","      participant = f\"{int(participant):02d}\"\n","      for condition in conditions:\n","          directory = os.path.join(base_path, participant, condition)\n","          directories.append(directory)\n","\n","  # Loop through each directory\n","  for directory in directories:\n","      # Check if the directory exists\n","      if not os.path.exists(directory):\n","          continue\n","\n","      # Get all CSV files in the directory that are named 'ssq.csv'\n","      csv_files = [file for file in os.listdir(directory) if file == 'ssq.csv']\n","\n","      # Loop through each CSV file\n","      for csv_file in csv_files:\n","          csv_path = os.path.join(directory, csv_file)\n","          n_val,o_val,d_val = calculate_total_ssq(csv_path)\n","          total_ssq = (n_val+o_val+d_val) * 3.74\n","          df = pd.read_csv(csv_path)\n","          df[\"total-ssq\"] = total_ssq\n","          #print(\"csv_path: \",csv_path,\"   \",total_ssq)\n","          total_ssq_values.append(total_ssq)\n","  # Create a DataFrame from the list of total SSQ values\n","  df_total_ssq = pd.DataFrame(total_ssq_values, columns=[\"total-ssq\"])\n","  # Convert the list of total SSQ values to a NumPy array\n","  total_ssq_array = np.array(total_ssq_values)\n","  return total_ssq_array\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"7k17K0HrCr6-","executionInfo":{"status":"ok","timestamp":1724917533669,"user_tz":300,"elapsed":3066,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["participants_group_1 = [1,3,4,11,25]\n","participants_group_2 = [2,7,8,9,17]\n","participants_group_3 = [10,12,13,22,23]\n","participants_group_4 = [5,14,18,20,21]\n","participants_group_5 = [6,15,16,19,24,26]\n","\n","arrays_group_1 = construct_3d_array(base_path, participants_group_1, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_2 = construct_3d_array(base_path, participants_group_2, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_3 = construct_3d_array(base_path, participants_group_3, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_4 = construct_3d_array(base_path, participants_group_4, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)\n","arrays_group_5 = construct_3d_array(base_path, participants_group_5, simulations, columns_to_remove_hr, columns_to_remove_gsr, columns_to_remove_head, columns_to_remove_eye)"]},{"cell_type":"code","source":["# Concatenate arrays along the first axis\n","input_group_1 = np.concatenate(arrays_group_1, axis=0)\n","input_group_2 = np.concatenate(arrays_group_2, axis=0)\n","input_group_3 = np.concatenate(arrays_group_3, axis=0)\n","input_group_4 = np.concatenate(arrays_group_4, axis=0)\n","input_group_5 = np.concatenate(arrays_group_5, axis=0)\n"],"metadata":{"id":"bt-7nB84mtwe","executionInfo":{"status":"ok","timestamp":1724917533669,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["output_group_1=merge_ssq_column(simulations,participants_group_1)\n","output_group_2=merge_ssq_column(simulations,participants_group_2)\n","output_group_3=merge_ssq_column(simulations,participants_group_3)\n","output_group_4=merge_ssq_column(simulations,participants_group_4)\n","output_group_5=merge_ssq_column(simulations,participants_group_5)\n","\n","output_group_1 = np.squeeze(output_group_1)\n","output_group_2 = np.squeeze(output_group_2)\n","output_group_3 = np.squeeze(output_group_3)\n","output_group_4 = np.squeeze(output_group_4)\n","output_group_5 = np.squeeze(output_group_5)\n","\n","\n","output_total_ssq_group_1=merge_total_ssq(simulations,participants_group_1)\n","output_total_ssq_group_2=merge_total_ssq(simulations,participants_group_2)\n","output_total_ssq_group_3=merge_total_ssq(simulations,participants_group_3)\n","output_total_ssq_group_4=merge_total_ssq(simulations,participants_group_4)\n","output_total_ssq_group_5=merge_total_ssq(simulations,participants_group_5)\n","\n","output_total_ssq_group_1=output_total_ssq_group_1.reshape(-1, 1)\n","output_total_ssq_group_2=output_total_ssq_group_2.reshape(-1, 1)\n","output_total_ssq_group_3=output_total_ssq_group_3.reshape(-1, 1)\n","output_total_ssq_group_4=output_total_ssq_group_4.reshape(-1, 1)\n","output_total_ssq_group_5=output_total_ssq_group_5.reshape(-1, 1)\n","\n"],"metadata":{"id":"2xrL7s_Vm5iI","executionInfo":{"status":"ok","timestamp":1724917535463,"user_tz":300,"elapsed":1799,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"26ADF-kiC1EZ","executionInfo":{"status":"ok","timestamp":1724917535464,"user_tz":300,"elapsed":5,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"}}},"outputs":[],"source":["def scale_input_data(input_train, input_test):\n","    # Get the shape of the input data\n","    num_samples_train, time_steps_train, num_features = input_train.shape\n","    num_samples_test, time_steps_test, _ = input_test.shape\n","\n","    # Reshape the input data into 2D arrays\n","    flattened_train_data = input_train.reshape(-1, num_features)\n","    flattened_test_data = input_test.reshape(-1, num_features)\n","\n","    # Initialize a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # Fit the scaler on the training data and transform both train and test data\n","    scaled_train_data = scaler.fit_transform(flattened_train_data)\n","    scaled_test_data = scaler.transform(flattened_test_data)\n","\n","    # Reshape the scaled data back to its original shape\n","    scaled_train_data = scaled_train_data.reshape(num_samples_train, time_steps_train, num_features)\n","    scaled_test_data = scaled_test_data.reshape(num_samples_test, time_steps_test, num_features)\n","\n","    return scaled_train_data, scaled_test_data\n","\n","def scale_target_var(target_data):\n","    min_val, max_val = np.min(target_data, axis=0), np.max(target_data, axis=0)\n","    target_data = (target_data-min_val)/(max_val-min_val)\n","\n","    return target_data, min_val, max_val"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238945,"status":"ok","timestamp":1724917774405,"user":{"displayName":"Anjan Kumar Dev","userId":"10866355726897008846"},"user_tz":300},"id":"E6ssyYUeDJwI","outputId":"7331f1af-8f4e-4b85-bbb1-471e46b856de"},"outputs":[{"output_type":"stream","name":"stdout","text":["global_indices [[], [], [], [], []]\n","Iteration 1\n","global_indices [[], [], [], [], []]\n","input_train : (41, 120, 47)\n","output_train : (41, 16)\n","input_val : (13, 120, 47)\n","output_val : (13, 16)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 106ms/step - loss: 2.7906 - output_0_mse: 0.2012 - output_10_mse: 0.2510 - output_11_mse: 0.1054 - output_12_mse: 0.4350 - output_13_mse: 0.0839 - output_14_mse: 0.4276 - output_15_mse: 0.1412 - output_1_mse: 0.1841 - output_2_mse: 0.0341 - output_3_mse: 0.1390 - output_4_mse: 0.0954 - output_5_mse: 0.0793 - output_6_mse: 0.1733 - output_7_mse: 0.2844 - output_8_mse: 0.0582 - output_9_mse: 0.0976\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 1.5403 - output_0_mse: 0.1722 - output_10_mse: 0.0530 - output_11_mse: 0.0889 - output_12_mse: 0.0683 - output_13_mse: 0.1010 - output_14_mse: 0.1658 - output_15_mse: 0.0587 - output_1_mse: 0.1000 - output_2_mse: 0.0565 - output_3_mse: 0.1020 - output_4_mse: 0.0523 - output_5_mse: 0.0777 - output_6_mse: 0.1044 - output_7_mse: 0.2134 - output_8_mse: 0.0637 - output_9_mse: 0.0625\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 1.3773 - output_0_mse: 0.1302 - output_10_mse: 0.0588 - output_11_mse: 0.0702 - output_12_mse: 0.0705 - output_13_mse: 0.0730 - output_14_mse: 0.1014 - output_15_mse: 0.0953 - output_1_mse: 0.0995 - output_2_mse: 0.0416 - output_3_mse: 0.0966 - output_4_mse: 0.0442 - output_5_mse: 0.0680 - output_6_mse: 0.1456 - output_7_mse: 0.1631 - output_8_mse: 0.0653 - output_9_mse: 0.0539\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.3437 - output_0_mse: 0.1308 - output_10_mse: 0.0551 - output_11_mse: 0.1144 - output_12_mse: 0.0574 - output_13_mse: 0.0570 - output_14_mse: 0.1205 - output_15_mse: 0.0805 - output_1_mse: 0.0746 - output_2_mse: 0.0344 - output_3_mse: 0.0911 - output_4_mse: 0.0724 - output_5_mse: 0.0841 - output_6_mse: 0.1186 - output_7_mse: 0.1308 - output_8_mse: 0.0587 - output_9_mse: 0.0632\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 1.1619 - output_0_mse: 0.0972 - output_10_mse: 0.0318 - output_11_mse: 0.0801 - output_12_mse: 0.0628 - output_13_mse: 0.0548 - output_14_mse: 0.1078 - output_15_mse: 0.0594 - output_1_mse: 0.0742 - output_2_mse: 0.0272 - output_3_mse: 0.1015 - output_4_mse: 0.0635 - output_5_mse: 0.0564 - output_6_mse: 0.1280 - output_7_mse: 0.1287 - output_8_mse: 0.0467 - output_9_mse: 0.0418\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 4 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.3092 - output_0_mse: 0.1024 - output_10_mse: 0.0461 - output_11_mse: 0.0672 - output_12_mse: 0.0721 - output_13_mse: 0.1137 - output_14_mse: 0.1343 - output_15_mse: 0.0845 - output_1_mse: 0.0798 - output_2_mse: 0.0433 - output_3_mse: 0.0901 - output_4_mse: 0.0531 - output_5_mse: 0.0907 - output_6_mse: 0.1195 - output_7_mse: 0.1190 - output_8_mse: 0.0505 - output_9_mse: 0.0430\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 5 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.0894 - output_0_mse: 0.1065 - output_10_mse: 0.0513 - output_11_mse: 0.0658 - output_12_mse: 0.0653 - output_13_mse: 0.0494 - output_14_mse: 0.1164 - output_15_mse: 0.0836 - output_1_mse: 0.0577 - output_2_mse: 0.0261 - output_3_mse: 0.0829 - output_4_mse: 0.0516 - output_5_mse: 0.0650 - output_6_mse: 0.1003 - output_7_mse: 0.0947 - output_8_mse: 0.0291 - output_9_mse: 0.0437\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 6 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 1.1519 - output_0_mse: 0.0833 - output_10_mse: 0.0576 - output_11_mse: 0.0909 - output_12_mse: 0.0705 - output_13_mse: 0.0581 - output_14_mse: 0.0915 - output_15_mse: 0.0697 - output_1_mse: 0.0518 - output_2_mse: 0.0428 - output_3_mse: 0.0736 - output_4_mse: 0.0625 - output_5_mse: 0.0983 - output_6_mse: 0.0923 - output_7_mse: 0.0991 - output_8_mse: 0.0476 - output_9_mse: 0.0623\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 7 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.0740 - output_0_mse: 0.0754 - output_10_mse: 0.0537 - output_11_mse: 0.0753 - output_12_mse: 0.0510 - output_13_mse: 0.0778 - output_14_mse: 0.0746 - output_15_mse: 0.0704 - output_1_mse: 0.0621 - output_2_mse: 0.0169 - output_3_mse: 0.0862 - output_4_mse: 0.0582 - output_5_mse: 0.0566 - output_6_mse: 0.1163 - output_7_mse: 0.0883 - output_8_mse: 0.0589 - output_9_mse: 0.0523\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 8 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.9446 - output_0_mse: 0.0579 - output_10_mse: 0.0367 - output_11_mse: 0.0859 - output_12_mse: 0.0538 - output_13_mse: 0.0499 - output_14_mse: 0.0885 - output_15_mse: 0.0650 - output_1_mse: 0.0519 - output_2_mse: 0.0272 - output_3_mse: 0.0676 - output_4_mse: 0.0472 - output_5_mse: 0.0548 - output_6_mse: 0.0718 - output_7_mse: 0.0912 - output_8_mse: 0.0526 - output_9_mse: 0.0425\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 9 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 188ms/step - loss: 0.9647 - output_0_mse: 0.0704 - output_10_mse: 0.0370 - output_11_mse: 0.0881 - output_12_mse: 0.0378 - output_13_mse: 0.0541 - output_14_mse: 0.0926 - output_15_mse: 0.0698 - output_1_mse: 0.0644 - output_2_mse: 0.0165 - output_3_mse: 0.0752 - output_4_mse: 0.0332 - output_5_mse: 0.0618 - output_6_mse: 0.0796 - output_7_mse: 0.0967 - output_8_mse: 0.0511 - output_9_mse: 0.0364\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n","k: 10 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - loss: 0.8628 - output_0_mse: 0.0529 - output_10_mse: 0.0314 - output_11_mse: 0.0829 - output_12_mse: 0.0327 - output_13_mse: 0.0514 - output_14_mse: 0.0813 - output_15_mse: 0.0561 - output_1_mse: 0.0476 - output_2_mse: 0.0247 - output_3_mse: 0.0579 - output_4_mse: 0.0416 - output_5_mse: 0.0619 - output_6_mse: 0.0767 - output_7_mse: 0.0840 - output_8_mse: 0.0383 - output_9_mse: 0.0418\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n","k: 11 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - loss: 0.8160 - output_0_mse: 0.0651 - output_10_mse: 0.0419 - output_11_mse: 0.0553 - output_12_mse: 0.0305 - output_13_mse: 0.0394 - output_14_mse: 0.0679 - output_15_mse: 0.0525 - output_1_mse: 0.0524 - output_2_mse: 0.0361 - output_3_mse: 0.0788 - output_4_mse: 0.0377 - output_5_mse: 0.0543 - output_6_mse: 0.0624 - output_7_mse: 0.0727 - output_8_mse: 0.0290 - output_9_mse: 0.0400\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","k: 12 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - loss: 0.7900 - output_0_mse: 0.0584 - output_10_mse: 0.0368 - output_11_mse: 0.0686 - output_12_mse: 0.0314 - output_13_mse: 0.0467 - output_14_mse: 0.0771 - output_15_mse: 0.0512 - output_1_mse: 0.0509 - output_2_mse: 0.0218 - output_3_mse: 0.0546 - output_4_mse: 0.0444 - output_5_mse: 0.0421 - output_6_mse: 0.0703 - output_7_mse: 0.0558 - output_8_mse: 0.0368 - output_9_mse: 0.0429\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n","k: 13 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - loss: 0.9398 - output_0_mse: 0.0647 - output_10_mse: 0.0419 - output_11_mse: 0.0730 - output_12_mse: 0.0468 - output_13_mse: 0.0635 - output_14_mse: 0.0821 - output_15_mse: 0.0564 - output_1_mse: 0.0520 - output_2_mse: 0.0375 - output_3_mse: 0.0519 - output_4_mse: 0.0449 - output_5_mse: 0.0695 - output_6_mse: 0.0732 - output_7_mse: 0.0706 - output_8_mse: 0.0448 - output_9_mse: 0.0669\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n","k: 14 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.6818 - output_0_mse: 0.0576 - output_10_mse: 0.0267 - output_11_mse: 0.0638 - output_12_mse: 0.0277 - output_13_mse: 0.0425 - output_14_mse: 0.0671 - output_15_mse: 0.0336 - output_1_mse: 0.0410 - output_2_mse: 0.0205 - output_3_mse: 0.0546 - output_4_mse: 0.0400 - output_5_mse: 0.0385 - output_6_mse: 0.0590 - output_7_mse: 0.0422 - output_8_mse: 0.0306 - output_9_mse: 0.0365\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 15 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.7027 - output_0_mse: 0.0446 - output_10_mse: 0.0260 - output_11_mse: 0.0541 - output_12_mse: 0.0261 - output_13_mse: 0.0503 - output_14_mse: 0.0728 - output_15_mse: 0.0458 - output_1_mse: 0.0399 - output_2_mse: 0.0247 - output_3_mse: 0.0515 - output_4_mse: 0.0370 - output_5_mse: 0.0361 - output_6_mse: 0.0598 - output_7_mse: 0.0503 - output_8_mse: 0.0368 - output_9_mse: 0.0467\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 16 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.6634 - output_0_mse: 0.0429 - output_10_mse: 0.0355 - output_11_mse: 0.0543 - output_12_mse: 0.0213 - output_13_mse: 0.0446 - output_14_mse: 0.0538 - output_15_mse: 0.0559 - output_1_mse: 0.0468 - output_2_mse: 0.0212 - output_3_mse: 0.0639 - output_4_mse: 0.0219 - output_5_mse: 0.0349 - output_6_mse: 0.0489 - output_7_mse: 0.0372 - output_8_mse: 0.0339 - output_9_mse: 0.0465\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 17 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.6179 - output_0_mse: 0.0485 - output_10_mse: 0.0220 - output_11_mse: 0.0479 - output_12_mse: 0.0198 - output_13_mse: 0.0464 - output_14_mse: 0.0374 - output_15_mse: 0.0283 - output_1_mse: 0.0373 - output_2_mse: 0.0221 - output_3_mse: 0.0763 - output_4_mse: 0.0227 - output_5_mse: 0.0446 - output_6_mse: 0.0559 - output_7_mse: 0.0356 - output_8_mse: 0.0245 - output_9_mse: 0.0485\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 18 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.6079 - output_0_mse: 0.0487 - output_10_mse: 0.0166 - output_11_mse: 0.0461 - output_12_mse: 0.0216 - output_13_mse: 0.0347 - output_14_mse: 0.0517 - output_15_mse: 0.0307 - output_1_mse: 0.0382 - output_2_mse: 0.0301 - output_3_mse: 0.0623 - output_4_mse: 0.0276 - output_5_mse: 0.0264 - output_6_mse: 0.0615 - output_7_mse: 0.0389 - output_8_mse: 0.0288 - output_9_mse: 0.0441\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","k: 19 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.6276 - output_0_mse: 0.0498 - output_10_mse: 0.0263 - output_11_mse: 0.0495 - output_12_mse: 0.0222 - output_13_mse: 0.0400 - output_14_mse: 0.0402 - output_15_mse: 0.0324 - output_1_mse: 0.0424 - output_2_mse: 0.0160 - output_3_mse: 0.0558 - output_4_mse: 0.0349 - output_5_mse: 0.0393 - output_6_mse: 0.0648 - output_7_mse: 0.0364 - output_8_mse: 0.0317 - output_9_mse: 0.0461\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 20 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step\n","Test Loss: 29.742760458860104\n","Iteration 2\n","global_indices [[0, 9, 3], [7, 9, 11], [11, 4, 6], [5, 3], [0, 14, 10]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16)\n","input_val : (13, 120, 47)\n","output_val : (13, 16)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - loss: 3.2818 - output_0_mse: 0.3941 - output_10_mse: 0.1598 - output_11_mse: 0.1443 - output_12_mse: 0.1871 - output_13_mse: 0.2254 - output_14_mse: 0.1999 - output_15_mse: 0.0837 - output_1_mse: 0.3530 - output_2_mse: 0.1234 - output_3_mse: 0.1084 - output_4_mse: 0.1516 - output_5_mse: 0.2028 - output_6_mse: 0.4161 - output_7_mse: 0.3421 - output_8_mse: 0.1059 - output_9_mse: 0.0842\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 1.5860 - output_0_mse: 0.1292 - output_10_mse: 0.0789 - output_11_mse: 0.0932 - output_12_mse: 0.0821 - output_13_mse: 0.1788 - output_14_mse: 0.1010 - output_15_mse: 0.0825 - output_1_mse: 0.1635 - output_2_mse: 0.0744 - output_3_mse: 0.0729 - output_4_mse: 0.0959 - output_5_mse: 0.0730 - output_6_mse: 0.1191 - output_7_mse: 0.1198 - output_8_mse: 0.0637 - output_9_mse: 0.0580\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 1.3160 - output_0_mse: 0.1251 - output_10_mse: 0.0471 - output_11_mse: 0.0636 - output_12_mse: 0.0721 - output_13_mse: 0.0851 - output_14_mse: 0.0755 - output_15_mse: 0.0897 - output_1_mse: 0.1352 - output_2_mse: 0.0400 - output_3_mse: 0.0939 - output_4_mse: 0.0529 - output_5_mse: 0.0960 - output_6_mse: 0.0935 - output_7_mse: 0.1157 - output_8_mse: 0.0613 - output_9_mse: 0.0693\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 1.2595 - output_0_mse: 0.0988 - output_10_mse: 0.0605 - output_11_mse: 0.0711 - output_12_mse: 0.0737 - output_13_mse: 0.0578 - output_14_mse: 0.0817 - output_15_mse: 0.0809 - output_1_mse: 0.0946 - output_2_mse: 0.0459 - output_3_mse: 0.0749 - output_4_mse: 0.0625 - output_5_mse: 0.0789 - output_6_mse: 0.1283 - output_7_mse: 0.1333 - output_8_mse: 0.0569 - output_9_mse: 0.0597\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 3 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 1.1731 - output_0_mse: 0.0947 - output_10_mse: 0.0572 - output_11_mse: 0.0886 - output_12_mse: 0.0760 - output_13_mse: 0.0532 - output_14_mse: 0.0941 - output_15_mse: 0.0575 - output_1_mse: 0.0852 - output_2_mse: 0.0386 - output_3_mse: 0.0979 - output_4_mse: 0.0479 - output_5_mse: 0.0760 - output_6_mse: 0.0964 - output_7_mse: 0.1033 - output_8_mse: 0.0500 - output_9_mse: 0.0564\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 4 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.1460 - output_0_mse: 0.0895 - output_10_mse: 0.0455 - output_11_mse: 0.0993 - output_12_mse: 0.0488 - output_13_mse: 0.0573 - output_14_mse: 0.0847 - output_15_mse: 0.0580 - output_1_mse: 0.0927 - output_2_mse: 0.0534 - output_3_mse: 0.0934 - output_4_mse: 0.0435 - output_5_mse: 0.0726 - output_6_mse: 0.0840 - output_7_mse: 0.1067 - output_8_mse: 0.0526 - output_9_mse: 0.0639\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n","k: 5 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 1.0846 - output_0_mse: 0.0892 - output_10_mse: 0.0414 - output_11_mse: 0.0786 - output_12_mse: 0.0587 - output_13_mse: 0.0659 - output_14_mse: 0.0834 - output_15_mse: 0.0626 - output_1_mse: 0.0669 - output_2_mse: 0.0586 - output_3_mse: 0.0740 - output_4_mse: 0.0439 - output_5_mse: 0.0667 - output_6_mse: 0.0801 - output_7_mse: 0.1023 - output_8_mse: 0.0507 - output_9_mse: 0.0618\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 6 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.9415 - output_0_mse: 0.0687 - output_10_mse: 0.0368 - output_11_mse: 0.0781 - output_12_mse: 0.0458 - output_13_mse: 0.0484 - output_14_mse: 0.0936 - output_15_mse: 0.0561 - output_1_mse: 0.0581 - output_2_mse: 0.0488 - output_3_mse: 0.0712 - output_4_mse: 0.0350 - output_5_mse: 0.0521 - output_6_mse: 0.0789 - output_7_mse: 0.0816 - output_8_mse: 0.0348 - output_9_mse: 0.0535\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","k: 7 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.8832 - output_0_mse: 0.0619 - output_10_mse: 0.0418 - output_11_mse: 0.0656 - output_12_mse: 0.0339 - output_13_mse: 0.0621 - output_14_mse: 0.0732 - output_15_mse: 0.0505 - output_1_mse: 0.0804 - output_2_mse: 0.0350 - output_3_mse: 0.0732 - output_4_mse: 0.0311 - output_5_mse: 0.0488 - output_6_mse: 0.0776 - output_7_mse: 0.0784 - output_8_mse: 0.0335 - output_9_mse: 0.0364\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 8 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.0029 - output_0_mse: 0.0617 - output_10_mse: 0.0391 - output_11_mse: 0.0808 - output_12_mse: 0.0662 - output_13_mse: 0.0754 - output_14_mse: 0.0711 - output_15_mse: 0.0554 - output_1_mse: 0.0635 - output_2_mse: 0.0381 - output_3_mse: 0.0674 - output_4_mse: 0.0565 - output_5_mse: 0.0580 - output_6_mse: 0.0872 - output_7_mse: 0.0813 - output_8_mse: 0.0431 - output_9_mse: 0.0582\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 9 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.9312 - output_0_mse: 0.0730 - output_10_mse: 0.0336 - output_11_mse: 0.0657 - output_12_mse: 0.0599 - output_13_mse: 0.0424 - output_14_mse: 0.0792 - output_15_mse: 0.0458 - output_1_mse: 0.0636 - output_2_mse: 0.0517 - output_3_mse: 0.0659 - output_4_mse: 0.0537 - output_5_mse: 0.0693 - output_6_mse: 0.0712 - output_7_mse: 0.0674 - output_8_mse: 0.0386 - output_9_mse: 0.0500\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n","k: 10 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - loss: 0.8365 - output_0_mse: 0.0563 - output_10_mse: 0.0244 - output_11_mse: 0.0816 - output_12_mse: 0.0294 - output_13_mse: 0.0568 - output_14_mse: 0.0612 - output_15_mse: 0.0520 - output_1_mse: 0.0679 - output_2_mse: 0.0342 - output_3_mse: 0.0769 - output_4_mse: 0.0366 - output_5_mse: 0.0393 - output_6_mse: 0.0774 - output_7_mse: 0.0586 - output_8_mse: 0.0398 - output_9_mse: 0.0442\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n","k: 11 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","Test Loss: 37.539332881435215\n","Iteration 3\n","global_indices [[0, 9, 3, 13, 8, 10], [7, 9, 11, 13, 1, 6], [11, 4, 6, 0, 3, 7], [5, 3, 2, 6], [0, 14, 10, 13, 9, 3]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16)\n","input_val : (13, 120, 47)\n","output_val : (13, 16)\n","input_test : (14, 120, 47)\n","output_test : (14, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 112ms/step - loss: 2.3464 - output_0_mse: 0.0890 - output_10_mse: 0.1862 - output_11_mse: 0.1439 - output_12_mse: 0.2146 - output_13_mse: 0.0977 - output_14_mse: 0.1613 - output_15_mse: 0.1066 - output_1_mse: 0.1434 - output_2_mse: 0.1204 - output_3_mse: 0.1051 - output_4_mse: 0.0812 - output_5_mse: 0.1087 - output_6_mse: 0.2426 - output_7_mse: 0.1208 - output_8_mse: 0.2526 - output_9_mse: 0.1724\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - loss: 1.3937 - output_0_mse: 0.1011 - output_10_mse: 0.0725 - output_11_mse: 0.1093 - output_12_mse: 0.0461 - output_13_mse: 0.0509 - output_14_mse: 0.1018 - output_15_mse: 0.1091 - output_1_mse: 0.0832 - output_2_mse: 0.0559 - output_3_mse: 0.0968 - output_4_mse: 0.0749 - output_5_mse: 0.0687 - output_6_mse: 0.1803 - output_7_mse: 0.1176 - output_8_mse: 0.0631 - output_9_mse: 0.0623\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - loss: 1.3168 - output_0_mse: 0.0868 - output_10_mse: 0.0568 - output_11_mse: 0.0972 - output_12_mse: 0.0866 - output_13_mse: 0.0448 - output_14_mse: 0.1239 - output_15_mse: 0.0820 - output_1_mse: 0.1076 - output_2_mse: 0.0784 - output_3_mse: 0.0746 - output_4_mse: 0.0602 - output_5_mse: 0.1005 - output_6_mse: 0.1186 - output_7_mse: 0.0904 - output_8_mse: 0.0524 - output_9_mse: 0.0562\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - loss: 1.0162 - output_0_mse: 0.0815 - output_10_mse: 0.0343 - output_11_mse: 0.1024 - output_12_mse: 0.0290 - output_13_mse: 0.0471 - output_14_mse: 0.0956 - output_15_mse: 0.0559 - output_1_mse: 0.0604 - output_2_mse: 0.0882 - output_3_mse: 0.0803 - output_4_mse: 0.0491 - output_5_mse: 0.0470 - output_6_mse: 0.0956 - output_7_mse: 0.0585 - output_8_mse: 0.0370 - output_9_mse: 0.0541\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 3 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 1.0680 - output_0_mse: 0.0950 - output_10_mse: 0.0472 - output_11_mse: 0.0913 - output_12_mse: 0.0561 - output_13_mse: 0.0541 - output_14_mse: 0.0835 - output_15_mse: 0.0821 - output_1_mse: 0.0737 - output_2_mse: 0.0723 - output_3_mse: 0.0609 - output_4_mse: 0.0641 - output_5_mse: 0.0475 - output_6_mse: 0.0842 - output_7_mse: 0.0657 - output_8_mse: 0.0469 - output_9_mse: 0.0434\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 4 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 1.0821 - output_0_mse: 0.0881 - output_10_mse: 0.0551 - output_11_mse: 0.0879 - output_12_mse: 0.0468 - output_13_mse: 0.0425 - output_14_mse: 0.0991 - output_15_mse: 0.0745 - output_1_mse: 0.0548 - output_2_mse: 0.0633 - output_3_mse: 0.0988 - output_4_mse: 0.0597 - output_5_mse: 0.0472 - output_6_mse: 0.0918 - output_7_mse: 0.0743 - output_8_mse: 0.0459 - output_9_mse: 0.0525\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 5 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.0682 - output_0_mse: 0.0898 - output_10_mse: 0.0270 - output_11_mse: 0.1038 - output_12_mse: 0.0570 - output_13_mse: 0.0487 - output_14_mse: 0.0843 - output_15_mse: 0.0663 - output_1_mse: 0.0536 - output_2_mse: 0.0783 - output_3_mse: 0.0906 - output_4_mse: 0.0466 - output_5_mse: 0.0480 - output_6_mse: 0.0928 - output_7_mse: 0.0711 - output_8_mse: 0.0556 - output_9_mse: 0.0548\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 6 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.9983 - output_0_mse: 0.0872 - output_10_mse: 0.0313 - output_11_mse: 0.0715 - output_12_mse: 0.0536 - output_13_mse: 0.0509 - output_14_mse: 0.0704 - output_15_mse: 0.0746 - output_1_mse: 0.0479 - output_2_mse: 0.0711 - output_3_mse: 0.0772 - output_4_mse: 0.0519 - output_5_mse: 0.0470 - output_6_mse: 0.0790 - output_7_mse: 0.0700 - output_8_mse: 0.0438 - output_9_mse: 0.0710\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","k: 7 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.9587 - output_0_mse: 0.0702 - output_10_mse: 0.0324 - output_11_mse: 0.0709 - output_12_mse: 0.0499 - output_13_mse: 0.0479 - output_14_mse: 0.0946 - output_15_mse: 0.0537 - output_1_mse: 0.0543 - output_2_mse: 0.0747 - output_3_mse: 0.0655 - output_4_mse: 0.0573 - output_5_mse: 0.0451 - output_6_mse: 0.0732 - output_7_mse: 0.0709 - output_8_mse: 0.0474 - output_9_mse: 0.0506\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","k: 8 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.9424 - output_0_mse: 0.0534 - output_10_mse: 0.0397 - output_11_mse: 0.0840 - output_12_mse: 0.0509 - output_13_mse: 0.0368 - output_14_mse: 0.0823 - output_15_mse: 0.0616 - output_1_mse: 0.0603 - output_2_mse: 0.0605 - output_3_mse: 0.0612 - output_4_mse: 0.0515 - output_5_mse: 0.0427 - output_6_mse: 0.0803 - output_7_mse: 0.0739 - output_8_mse: 0.0516 - output_9_mse: 0.0520\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 9 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.9412 - output_0_mse: 0.0530 - output_10_mse: 0.0437 - output_11_mse: 0.0840 - output_12_mse: 0.0420 - output_13_mse: 0.0402 - output_14_mse: 0.0695 - output_15_mse: 0.0479 - output_1_mse: 0.0704 - output_2_mse: 0.0687 - output_3_mse: 0.0470 - output_4_mse: 0.0585 - output_5_mse: 0.0455 - output_6_mse: 0.0769 - output_7_mse: 0.0726 - output_8_mse: 0.0555 - output_9_mse: 0.0658\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 10 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.9301 - output_0_mse: 0.0689 - output_10_mse: 0.0375 - output_11_mse: 0.0825 - output_12_mse: 0.0476 - output_13_mse: 0.0478 - output_14_mse: 0.0603 - output_15_mse: 0.0689 - output_1_mse: 0.0497 - output_2_mse: 0.0504 - output_3_mse: 0.0609 - output_4_mse: 0.0511 - output_5_mse: 0.0359 - output_6_mse: 0.0825 - output_7_mse: 0.0669 - output_8_mse: 0.0447 - output_9_mse: 0.0744\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 11 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.8606 - output_0_mse: 0.0594 - output_10_mse: 0.0288 - output_11_mse: 0.0752 - output_12_mse: 0.0320 - output_13_mse: 0.0467 - output_14_mse: 0.0610 - output_15_mse: 0.0517 - output_1_mse: 0.0601 - output_2_mse: 0.0603 - output_3_mse: 0.0543 - output_4_mse: 0.0348 - output_5_mse: 0.0437 - output_6_mse: 0.0816 - output_7_mse: 0.0654 - output_8_mse: 0.0432 - output_9_mse: 0.0622\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 12 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.7941 - output_0_mse: 0.0501 - output_10_mse: 0.0340 - output_11_mse: 0.0790 - output_12_mse: 0.0374 - output_13_mse: 0.0434 - output_14_mse: 0.0639 - output_15_mse: 0.0580 - output_1_mse: 0.0400 - output_2_mse: 0.0453 - output_3_mse: 0.0459 - output_4_mse: 0.0445 - output_5_mse: 0.0376 - output_6_mse: 0.0596 - output_7_mse: 0.0648 - output_8_mse: 0.0388 - output_9_mse: 0.0519\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","k: 13 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.8073 - output_0_mse: 0.0574 - output_10_mse: 0.0325 - output_11_mse: 0.0792 - output_12_mse: 0.0379 - output_13_mse: 0.0295 - output_14_mse: 0.0562 - output_15_mse: 0.0526 - output_1_mse: 0.0517 - output_2_mse: 0.0535 - output_3_mse: 0.0507 - output_4_mse: 0.0455 - output_5_mse: 0.0306 - output_6_mse: 0.0710 - output_7_mse: 0.0603 - output_8_mse: 0.0349 - output_9_mse: 0.0639\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 14 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8353 - output_0_mse: 0.0422 - output_10_mse: 0.0278 - output_11_mse: 0.0958 - output_12_mse: 0.0536 - output_13_mse: 0.0406 - output_14_mse: 0.0572 - output_15_mse: 0.0456 - output_1_mse: 0.0576 - output_2_mse: 0.0485 - output_3_mse: 0.0597 - output_4_mse: 0.0533 - output_5_mse: 0.0478 - output_6_mse: 0.0581 - output_7_mse: 0.0590 - output_8_mse: 0.0289 - output_9_mse: 0.0596\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n","k: 15 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - loss: 0.6754 - output_0_mse: 0.0435 - output_10_mse: 0.0136 - output_11_mse: 0.0666 - output_12_mse: 0.0231 - output_13_mse: 0.0259 - output_14_mse: 0.0572 - output_15_mse: 0.0442 - output_1_mse: 0.0364 - output_2_mse: 0.0422 - output_3_mse: 0.0625 - output_4_mse: 0.0358 - output_5_mse: 0.0367 - output_6_mse: 0.0559 - output_7_mse: 0.0598 - output_8_mse: 0.0253 - output_9_mse: 0.0466\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","k: 16 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 190ms/step - loss: 0.6834 - output_0_mse: 0.0376 - output_10_mse: 0.0204 - output_11_mse: 0.0745 - output_12_mse: 0.0324 - output_13_mse: 0.0284 - output_14_mse: 0.0381 - output_15_mse: 0.0453 - output_1_mse: 0.0410 - output_2_mse: 0.0584 - output_3_mse: 0.0658 - output_4_mse: 0.0387 - output_5_mse: 0.0235 - output_6_mse: 0.0424 - output_7_mse: 0.0604 - output_8_mse: 0.0293 - output_9_mse: 0.0471\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n","k: 17 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - loss: 0.7785 - output_0_mse: 0.0471 - output_10_mse: 0.0252 - output_11_mse: 0.0603 - output_12_mse: 0.0377 - output_13_mse: 0.0239 - output_14_mse: 0.0433 - output_15_mse: 0.0643 - output_1_mse: 0.0511 - output_2_mse: 0.0398 - output_3_mse: 0.0803 - output_4_mse: 0.0465 - output_5_mse: 0.0349 - output_6_mse: 0.0606 - output_7_mse: 0.0562 - output_8_mse: 0.0449 - output_9_mse: 0.0622\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 18 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.6345 - output_0_mse: 0.0399 - output_10_mse: 0.0152 - output_11_mse: 0.0705 - output_12_mse: 0.0294 - output_13_mse: 0.0253 - output_14_mse: 0.0307 - output_15_mse: 0.0308 - output_1_mse: 0.0433 - output_2_mse: 0.0613 - output_3_mse: 0.0581 - output_4_mse: 0.0515 - output_5_mse: 0.0276 - output_6_mse: 0.0322 - output_7_mse: 0.0344 - output_8_mse: 0.0278 - output_9_mse: 0.0564\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 19 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.5986 - output_0_mse: 0.0402 - output_10_mse: 0.0175 - output_11_mse: 0.0506 - output_12_mse: 0.0243 - output_13_mse: 0.0266 - output_14_mse: 0.0326 - output_15_mse: 0.0354 - output_1_mse: 0.0460 - output_2_mse: 0.0511 - output_3_mse: 0.0567 - output_4_mse: 0.0337 - output_5_mse: 0.0246 - output_6_mse: 0.0527 - output_7_mse: 0.0417 - output_8_mse: 0.0304 - output_9_mse: 0.0347\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 20 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.6241 - output_0_mse: 0.0373 - output_10_mse: 0.0219 - output_11_mse: 0.0653 - output_12_mse: 0.0314 - output_13_mse: 0.0410 - output_14_mse: 0.0411 - output_15_mse: 0.0371 - output_1_mse: 0.0357 - output_2_mse: 0.0520 - output_3_mse: 0.0502 - output_4_mse: 0.0436 - output_5_mse: 0.0151 - output_6_mse: 0.0399 - output_7_mse: 0.0317 - output_8_mse: 0.0246 - output_9_mse: 0.0562\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 21 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.5966 - output_0_mse: 0.0386 - output_10_mse: 0.0163 - output_11_mse: 0.0591 - output_12_mse: 0.0321 - output_13_mse: 0.0185 - output_14_mse: 0.0313 - output_15_mse: 0.0344 - output_1_mse: 0.0313 - output_2_mse: 0.0554 - output_3_mse: 0.0515 - output_4_mse: 0.0398 - output_5_mse: 0.0216 - output_6_mse: 0.0414 - output_7_mse: 0.0421 - output_8_mse: 0.0259 - output_9_mse: 0.0574\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n","k: 22 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.5878 - output_0_mse: 0.0435 - output_10_mse: 0.0120 - output_11_mse: 0.0541 - output_12_mse: 0.0321 - output_13_mse: 0.0216 - output_14_mse: 0.0398 - output_15_mse: 0.0319 - output_1_mse: 0.0485 - output_2_mse: 0.0542 - output_3_mse: 0.0462 - output_4_mse: 0.0348 - output_5_mse: 0.0238 - output_6_mse: 0.0348 - output_7_mse: 0.0363 - output_8_mse: 0.0222 - output_9_mse: 0.0516\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 23 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.4971 - output_0_mse: 0.0308 - output_10_mse: 0.0058 - output_11_mse: 0.0545 - output_12_mse: 0.0243 - output_13_mse: 0.0098 - output_14_mse: 0.0277 - output_15_mse: 0.0422 - output_1_mse: 0.0279 - output_2_mse: 0.0377 - output_3_mse: 0.0430 - output_4_mse: 0.0257 - output_5_mse: 0.0226 - output_6_mse: 0.0439 - output_7_mse: 0.0234 - output_8_mse: 0.0302 - output_9_mse: 0.0477\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","k: 24 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.6372 - output_0_mse: 0.0386 - output_10_mse: 0.0196 - output_11_mse: 0.0579 - output_12_mse: 0.0235 - output_13_mse: 0.0366 - output_14_mse: 0.0571 - output_15_mse: 0.0312 - output_1_mse: 0.0502 - output_2_mse: 0.0413 - output_3_mse: 0.0316 - output_4_mse: 0.0559 - output_5_mse: 0.0361 - output_6_mse: 0.0522 - output_7_mse: 0.0290 - output_8_mse: 0.0229 - output_9_mse: 0.0535\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","k: 25 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.4692 - output_0_mse: 0.0226 - output_10_mse: 0.0167 - output_11_mse: 0.0442 - output_12_mse: 0.0186 - output_13_mse: 0.0205 - output_14_mse: 0.0252 - output_15_mse: 0.0303 - output_1_mse: 0.0339 - output_2_mse: 0.0338 - output_3_mse: 0.0427 - output_4_mse: 0.0353 - output_5_mse: 0.0143 - output_6_mse: 0.0336 - output_7_mse: 0.0242 - output_8_mse: 0.0292 - output_9_mse: 0.0440\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 26 patience: 10\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.5131 - output_0_mse: 0.0363 - output_10_mse: 0.0126 - output_11_mse: 0.0473 - output_12_mse: 0.0173 - output_13_mse: 0.0267 - output_14_mse: 0.0294 - output_15_mse: 0.0275 - output_1_mse: 0.0371 - output_2_mse: 0.0394 - output_3_mse: 0.0435 - output_4_mse: 0.0346 - output_5_mse: 0.0147 - output_6_mse: 0.0461 - output_7_mse: 0.0308 - output_8_mse: 0.0285 - output_9_mse: 0.0411\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","k: 27 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.5233 - output_0_mse: 0.0300 - output_10_mse: 0.0128 - output_11_mse: 0.0733 - output_12_mse: 0.0184 - output_13_mse: 0.0123 - output_14_mse: 0.0284 - output_15_mse: 0.0312 - output_1_mse: 0.0396 - output_2_mse: 0.0433 - output_3_mse: 0.0453 - output_4_mse: 0.0354 - output_5_mse: 0.0155 - output_6_mse: 0.0339 - output_7_mse: 0.0294 - output_8_mse: 0.0266 - output_9_mse: 0.0480\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n","k: 28 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.3840 - output_0_mse: 0.0189 - output_10_mse: 0.0086 - output_11_mse: 0.0386 - output_12_mse: 0.0187 - output_13_mse: 0.0103 - output_14_mse: 0.0257 - output_15_mse: 0.0279 - output_1_mse: 0.0312 - output_2_mse: 0.0361 - output_3_mse: 0.0359 - output_4_mse: 0.0248 - output_5_mse: 0.0122 - output_6_mse: 0.0259 - output_7_mse: 0.0209 - output_8_mse: 0.0153 - output_9_mse: 0.0330\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 29 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - loss: 0.5174 - output_0_mse: 0.0274 - output_10_mse: 0.0103 - output_11_mse: 0.0560 - output_12_mse: 0.0316 - output_13_mse: 0.0145 - output_14_mse: 0.0321 - output_15_mse: 0.0284 - output_1_mse: 0.0459 - output_2_mse: 0.0362 - output_3_mse: 0.0414 - output_4_mse: 0.0365 - output_5_mse: 0.0264 - output_6_mse: 0.0338 - output_7_mse: 0.0267 - output_8_mse: 0.0252 - output_9_mse: 0.0450\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n","k: 30 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step - loss: 0.4301 - output_0_mse: 0.0228 - output_10_mse: 0.0077 - output_11_mse: 0.0394 - output_12_mse: 0.0204 - output_13_mse: 0.0154 - output_14_mse: 0.0326 - output_15_mse: 0.0270 - output_1_mse: 0.0354 - output_2_mse: 0.0467 - output_3_mse: 0.0378 - output_4_mse: 0.0359 - output_5_mse: 0.0122 - output_6_mse: 0.0235 - output_7_mse: 0.0175 - output_8_mse: 0.0168 - output_9_mse: 0.0389\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n","k: 31 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - loss: 0.3984 - output_0_mse: 0.0220 - output_10_mse: 0.0102 - output_11_mse: 0.0346 - output_12_mse: 0.0191 - output_13_mse: 0.0147 - output_14_mse: 0.0314 - output_15_mse: 0.0177 - output_1_mse: 0.0296 - output_2_mse: 0.0370 - output_3_mse: 0.0285 - output_4_mse: 0.0320 - output_5_mse: 0.0188 - output_6_mse: 0.0260 - output_7_mse: 0.0197 - output_8_mse: 0.0213 - output_9_mse: 0.0357\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n","k: 32 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - loss: 0.4158 - output_0_mse: 0.0243 - output_10_mse: 0.0085 - output_11_mse: 0.0504 - output_12_mse: 0.0202 - output_13_mse: 0.0110 - output_14_mse: 0.0352 - output_15_mse: 0.0234 - output_1_mse: 0.0269 - output_2_mse: 0.0402 - output_3_mse: 0.0257 - output_4_mse: 0.0240 - output_5_mse: 0.0175 - output_6_mse: 0.0219 - output_7_mse: 0.0337 - output_8_mse: 0.0195 - output_9_mse: 0.0334\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n","k: 33 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - loss: 0.4052 - output_0_mse: 0.0194 - output_10_mse: 0.0085 - output_11_mse: 0.0554 - output_12_mse: 0.0171 - output_13_mse: 0.0077 - output_14_mse: 0.0292 - output_15_mse: 0.0192 - output_1_mse: 0.0288 - output_2_mse: 0.0304 - output_3_mse: 0.0333 - output_4_mse: 0.0265 - output_5_mse: 0.0158 - output_6_mse: 0.0268 - output_7_mse: 0.0227 - output_8_mse: 0.0171 - output_9_mse: 0.0473\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n","k: 34 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.4208 - output_0_mse: 0.0219 - output_10_mse: 0.0104 - output_11_mse: 0.0515 - output_12_mse: 0.0182 - output_13_mse: 0.0151 - output_14_mse: 0.0223 - output_15_mse: 0.0225 - output_1_mse: 0.0200 - output_2_mse: 0.0481 - output_3_mse: 0.0377 - output_4_mse: 0.0276 - output_5_mse: 0.0101 - output_6_mse: 0.0323 - output_7_mse: 0.0267 - output_8_mse: 0.0151 - output_9_mse: 0.0415\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n","k: 35 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.3424 - output_0_mse: 0.0166 - output_10_mse: 0.0071 - output_11_mse: 0.0355 - output_12_mse: 0.0222 - output_13_mse: 0.0076 - output_14_mse: 0.0207 - output_15_mse: 0.0236 - output_1_mse: 0.0179 - output_2_mse: 0.0331 - output_3_mse: 0.0251 - output_4_mse: 0.0269 - output_5_mse: 0.0147 - output_6_mse: 0.0306 - output_7_mse: 0.0227 - output_8_mse: 0.0144 - output_9_mse: 0.0236\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 36 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.3820 - output_0_mse: 0.0214 - output_10_mse: 0.0068 - output_11_mse: 0.0436 - output_12_mse: 0.0233 - output_13_mse: 0.0107 - output_14_mse: 0.0307 - output_15_mse: 0.0211 - output_1_mse: 0.0228 - output_2_mse: 0.0314 - output_3_mse: 0.0248 - output_4_mse: 0.0277 - output_5_mse: 0.0136 - output_6_mse: 0.0293 - output_7_mse: 0.0355 - output_8_mse: 0.0152 - output_9_mse: 0.0242\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n","k: 37 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692ms/step\n","Test Loss: 27.15555816277691\n","Iteration 4\n","global_indices [[0, 9, 3, 13, 8, 10, 1, 4, 7], [7, 9, 11, 13, 1, 6, 4, 2, 8], [11, 4, 6, 0, 3, 7, 2, 8, 1], [5, 3, 2, 6, 4, 9], [0, 14, 10, 13, 9, 3, 11, 2, 5]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (13, 120, 47)\n","output_test : (13, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 142ms/step - loss: 3.4137 - output_0_mse: 0.7103 - output_10_mse: 0.0682 - output_11_mse: 0.1398 - output_12_mse: 0.0761 - output_13_mse: 0.1215 - output_14_mse: 0.1334 - output_15_mse: 0.1998 - output_1_mse: 0.5236 - output_2_mse: 0.1112 - output_3_mse: 0.1890 - output_4_mse: 0.2086 - output_5_mse: 0.1143 - output_6_mse: 0.1562 - output_7_mse: 0.3360 - output_8_mse: 0.2649 - output_9_mse: 0.0608\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 1.6487 - output_0_mse: 0.0936 - output_10_mse: 0.0601 - output_11_mse: 0.1046 - output_12_mse: 0.0914 - output_13_mse: 0.0608 - output_14_mse: 0.1379 - output_15_mse: 0.1645 - output_1_mse: 0.1211 - output_2_mse: 0.1536 - output_3_mse: 0.1357 - output_4_mse: 0.0587 - output_5_mse: 0.0582 - output_6_mse: 0.1025 - output_7_mse: 0.1753 - output_8_mse: 0.0539 - output_9_mse: 0.0767\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 1.6102 - output_0_mse: 0.1022 - output_10_mse: 0.0679 - output_11_mse: 0.1220 - output_12_mse: 0.0755 - output_13_mse: 0.0816 - output_14_mse: 0.1240 - output_15_mse: 0.1055 - output_1_mse: 0.1017 - output_2_mse: 0.1101 - output_3_mse: 0.1128 - output_4_mse: 0.0699 - output_5_mse: 0.0871 - output_6_mse: 0.1256 - output_7_mse: 0.1139 - output_8_mse: 0.0551 - output_9_mse: 0.1554\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","k: 2 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 1.4624 - output_0_mse: 0.0914 - output_10_mse: 0.0652 - output_11_mse: 0.0885 - output_12_mse: 0.0639 - output_13_mse: 0.0716 - output_14_mse: 0.1333 - output_15_mse: 0.0997 - output_1_mse: 0.1168 - output_2_mse: 0.0938 - output_3_mse: 0.0977 - output_4_mse: 0.0615 - output_5_mse: 0.0678 - output_6_mse: 0.0990 - output_7_mse: 0.1480 - output_8_mse: 0.0609 - output_9_mse: 0.1033\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201ms/step - loss: 1.3434 - output_0_mse: 0.1051 - output_10_mse: 0.0514 - output_11_mse: 0.0915 - output_12_mse: 0.0453 - output_13_mse: 0.0848 - output_14_mse: 0.0985 - output_15_mse: 0.0782 - output_1_mse: 0.1129 - output_2_mse: 0.0673 - output_3_mse: 0.1228 - output_4_mse: 0.0623 - output_5_mse: 0.0579 - output_6_mse: 0.1231 - output_7_mse: 0.1325 - output_8_mse: 0.0562 - output_9_mse: 0.0537\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n","k: 4 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 1.2335 - output_0_mse: 0.0858 - output_10_mse: 0.0408 - output_11_mse: 0.1004 - output_12_mse: 0.0570 - output_13_mse: 0.0705 - output_14_mse: 0.0796 - output_15_mse: 0.0683 - output_1_mse: 0.1394 - output_2_mse: 0.0588 - output_3_mse: 0.1157 - output_4_mse: 0.0442 - output_5_mse: 0.0646 - output_6_mse: 0.1104 - output_7_mse: 0.0919 - output_8_mse: 0.0507 - output_9_mse: 0.0553\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n","k: 5 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - loss: 1.2040 - output_0_mse: 0.0753 - output_10_mse: 0.0489 - output_11_mse: 0.0989 - output_12_mse: 0.0528 - output_13_mse: 0.0604 - output_14_mse: 0.0947 - output_15_mse: 0.0706 - output_1_mse: 0.0952 - output_2_mse: 0.0559 - output_3_mse: 0.1243 - output_4_mse: 0.0657 - output_5_mse: 0.0595 - output_6_mse: 0.0988 - output_7_mse: 0.1086 - output_8_mse: 0.0416 - output_9_mse: 0.0529\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n","k: 6 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - loss: 1.1947 - output_0_mse: 0.0864 - output_10_mse: 0.0449 - output_11_mse: 0.0861 - output_12_mse: 0.0440 - output_13_mse: 0.0537 - output_14_mse: 0.0970 - output_15_mse: 0.0842 - output_1_mse: 0.0969 - output_2_mse: 0.0713 - output_3_mse: 0.1046 - output_4_mse: 0.0635 - output_5_mse: 0.0667 - output_6_mse: 0.0975 - output_7_mse: 0.0903 - output_8_mse: 0.0494 - output_9_mse: 0.0582\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 7 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 1.1383 - output_0_mse: 0.0778 - output_10_mse: 0.0447 - output_11_mse: 0.0913 - output_12_mse: 0.0536 - output_13_mse: 0.0752 - output_14_mse: 0.1003 - output_15_mse: 0.0583 - output_1_mse: 0.0770 - output_2_mse: 0.0682 - output_3_mse: 0.0865 - output_4_mse: 0.0577 - output_5_mse: 0.0752 - output_6_mse: 0.0844 - output_7_mse: 0.0816 - output_8_mse: 0.0414 - output_9_mse: 0.0649\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n","k: 8 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - loss: 1.0641 - output_0_mse: 0.0794 - output_10_mse: 0.0386 - output_11_mse: 0.0729 - output_12_mse: 0.0511 - output_13_mse: 0.0658 - output_14_mse: 0.0986 - output_15_mse: 0.0620 - output_1_mse: 0.0800 - output_2_mse: 0.0557 - output_3_mse: 0.0677 - output_4_mse: 0.0516 - output_5_mse: 0.0635 - output_6_mse: 0.0864 - output_7_mse: 0.0839 - output_8_mse: 0.0423 - output_9_mse: 0.0646\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n","k: 9 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - loss: 1.0312 - output_0_mse: 0.0749 - output_10_mse: 0.0358 - output_11_mse: 0.0809 - output_12_mse: 0.0505 - output_13_mse: 0.0489 - output_14_mse: 0.0914 - output_15_mse: 0.0717 - output_1_mse: 0.0793 - output_2_mse: 0.0608 - output_3_mse: 0.0701 - output_4_mse: 0.0462 - output_5_mse: 0.0592 - output_6_mse: 0.0824 - output_7_mse: 0.0638 - output_8_mse: 0.0447 - output_9_mse: 0.0703\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n","k: 10 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 202ms/step - loss: 0.9869 - output_0_mse: 0.0812 - output_10_mse: 0.0331 - output_11_mse: 0.0806 - output_12_mse: 0.0380 - output_13_mse: 0.0539 - output_14_mse: 0.0775 - output_15_mse: 0.0614 - output_1_mse: 0.0747 - output_2_mse: 0.0507 - output_3_mse: 0.0758 - output_4_mse: 0.0516 - output_5_mse: 0.0426 - output_6_mse: 0.0934 - output_7_mse: 0.0763 - output_8_mse: 0.0424 - output_9_mse: 0.0539\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n","k: 11 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.9265 - output_0_mse: 0.0755 - output_10_mse: 0.0389 - output_11_mse: 0.0694 - output_12_mse: 0.0399 - output_13_mse: 0.0494 - output_14_mse: 0.0765 - output_15_mse: 0.0496 - output_1_mse: 0.0674 - output_2_mse: 0.0568 - output_3_mse: 0.0656 - output_4_mse: 0.0581 - output_5_mse: 0.0502 - output_6_mse: 0.0651 - output_7_mse: 0.0789 - output_8_mse: 0.0333 - output_9_mse: 0.0520\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 12 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.9908 - output_0_mse: 0.0565 - output_10_mse: 0.0412 - output_11_mse: 0.0763 - output_12_mse: 0.0486 - output_13_mse: 0.0442 - output_14_mse: 0.0673 - output_15_mse: 0.0569 - output_1_mse: 0.0747 - output_2_mse: 0.0597 - output_3_mse: 0.0784 - output_4_mse: 0.0569 - output_5_mse: 0.0736 - output_6_mse: 0.0762 - output_7_mse: 0.0881 - output_8_mse: 0.0369 - output_9_mse: 0.0552\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","k: 13 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.8235 - output_0_mse: 0.0500 - output_10_mse: 0.0302 - output_11_mse: 0.0678 - output_12_mse: 0.0275 - output_13_mse: 0.0517 - output_14_mse: 0.0673 - output_15_mse: 0.0514 - output_1_mse: 0.0587 - output_2_mse: 0.0480 - output_3_mse: 0.0670 - output_4_mse: 0.0382 - output_5_mse: 0.0556 - output_6_mse: 0.0624 - output_7_mse: 0.0539 - output_8_mse: 0.0352 - output_9_mse: 0.0587\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 14 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.8072 - output_0_mse: 0.0437 - output_10_mse: 0.0238 - output_11_mse: 0.0773 - output_12_mse: 0.0354 - output_13_mse: 0.0486 - output_14_mse: 0.0678 - output_15_mse: 0.0482 - output_1_mse: 0.0512 - output_2_mse: 0.0500 - output_3_mse: 0.0843 - output_4_mse: 0.0363 - output_5_mse: 0.0515 - output_6_mse: 0.0626 - output_7_mse: 0.0497 - output_8_mse: 0.0274 - output_9_mse: 0.0493\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","k: 15 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.8334 - output_0_mse: 0.0454 - output_10_mse: 0.0327 - output_11_mse: 0.0706 - output_12_mse: 0.0368 - output_13_mse: 0.0543 - output_14_mse: 0.0627 - output_15_mse: 0.0507 - output_1_mse: 0.0662 - output_2_mse: 0.0499 - output_3_mse: 0.0648 - output_4_mse: 0.0383 - output_5_mse: 0.0514 - output_6_mse: 0.0569 - output_7_mse: 0.0503 - output_8_mse: 0.0352 - output_9_mse: 0.0672\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","k: 16 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step\n","Test Loss: 23.767116991639313\n","Iteration 5\n","global_indices [[0, 9, 3, 13, 8, 10, 1, 4, 7, 5, 2, 6], [7, 9, 11, 13, 1, 6, 4, 2, 8, 3, 5, 10], [11, 4, 6, 0, 3, 7, 2, 8, 1, 5, 9], [5, 3, 2, 6, 4, 9, 8, 1], [0, 14, 10, 13, 9, 3, 11, 2, 5, 15, 12, 1]]\n","input_train : (41, 120, 47)\n","output_train : (41, 16)\n","input_val : (14, 120, 47)\n","output_val : (14, 16)\n","input_test : (13, 120, 47)\n","output_test : (13, 16)\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 112ms/step - loss: 2.9145 - output_0_mse: 0.0791 - output_10_mse: 0.1292 - output_11_mse: 0.5085 - output_12_mse: 0.1092 - output_13_mse: 0.1156 - output_14_mse: 0.2158 - output_15_mse: 0.0945 - output_1_mse: 0.1560 - output_2_mse: 0.0600 - output_3_mse: 0.1146 - output_4_mse: 0.2441 - output_5_mse: 0.2896 - output_6_mse: 0.1991 - output_7_mse: 0.1810 - output_8_mse: 0.2251 - output_9_mse: 0.1931\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n","k: 0 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 2.0621 - output_0_mse: 0.1165 - output_10_mse: 0.1052 - output_11_mse: 0.1736 - output_12_mse: 0.0709 - output_13_mse: 0.1005 - output_14_mse: 0.1128 - output_15_mse: 0.0866 - output_1_mse: 0.0949 - output_2_mse: 0.0391 - output_3_mse: 0.0623 - output_4_mse: 0.2628 - output_5_mse: 0.0580 - output_6_mse: 0.1119 - output_7_mse: 0.0985 - output_8_mse: 0.4248 - output_9_mse: 0.1437\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n","k: 1 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.8677 - output_0_mse: 0.0791 - output_10_mse: 0.1173 - output_11_mse: 0.1712 - output_12_mse: 0.1021 - output_13_mse: 0.1249 - output_14_mse: 0.1215 - output_15_mse: 0.0424 - output_1_mse: 0.1004 - output_2_mse: 0.1170 - output_3_mse: 0.1021 - output_4_mse: 0.1999 - output_5_mse: 0.0648 - output_6_mse: 0.1122 - output_7_mse: 0.0900 - output_8_mse: 0.2005 - output_9_mse: 0.1224\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n","k: 2 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.5993 - output_0_mse: 0.0839 - output_10_mse: 0.0896 - output_11_mse: 0.1780 - output_12_mse: 0.1055 - output_13_mse: 0.0784 - output_14_mse: 0.1095 - output_15_mse: 0.0455 - output_1_mse: 0.0685 - output_2_mse: 0.0241 - output_3_mse: 0.0679 - output_4_mse: 0.1848 - output_5_mse: 0.0503 - output_6_mse: 0.0888 - output_7_mse: 0.1021 - output_8_mse: 0.2265 - output_9_mse: 0.0957\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 3 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.4607 - output_0_mse: 0.0714 - output_10_mse: 0.1009 - output_11_mse: 0.1689 - output_12_mse: 0.0622 - output_13_mse: 0.0738 - output_14_mse: 0.0879 - output_15_mse: 0.0437 - output_1_mse: 0.0599 - output_2_mse: 0.0342 - output_3_mse: 0.0696 - output_4_mse: 0.1856 - output_5_mse: 0.0374 - output_6_mse: 0.0949 - output_7_mse: 0.0615 - output_8_mse: 0.2089 - output_9_mse: 0.1000\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n","k: 4 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 1.5244 - output_0_mse: 0.0780 - output_10_mse: 0.1135 - output_11_mse: 0.1539 - output_12_mse: 0.0816 - output_13_mse: 0.0866 - output_14_mse: 0.0899 - output_15_mse: 0.0459 - output_1_mse: 0.0725 - output_2_mse: 0.0291 - output_3_mse: 0.0668 - output_4_mse: 0.1713 - output_5_mse: 0.0416 - output_6_mse: 0.1070 - output_7_mse: 0.1171 - output_8_mse: 0.1803 - output_9_mse: 0.0893\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n","k: 5 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.5439 - output_0_mse: 0.0755 - output_10_mse: 0.0927 - output_11_mse: 0.1694 - output_12_mse: 0.0713 - output_13_mse: 0.0966 - output_14_mse: 0.0950 - output_15_mse: 0.0586 - output_1_mse: 0.0458 - output_2_mse: 0.0263 - output_3_mse: 0.0690 - output_4_mse: 0.1847 - output_5_mse: 0.0506 - output_6_mse: 0.1037 - output_7_mse: 0.0887 - output_8_mse: 0.2048 - output_9_mse: 0.1112\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","k: 6 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - loss: 1.3859 - output_0_mse: 0.0587 - output_10_mse: 0.0766 - output_11_mse: 0.1740 - output_12_mse: 0.0817 - output_13_mse: 0.0892 - output_14_mse: 0.0763 - output_15_mse: 0.0484 - output_1_mse: 0.0364 - output_2_mse: 0.0267 - output_3_mse: 0.0651 - output_4_mse: 0.1547 - output_5_mse: 0.0380 - output_6_mse: 0.0875 - output_7_mse: 0.0808 - output_8_mse: 0.1760 - output_9_mse: 0.1158\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n","k: 7 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - loss: 1.3275 - output_0_mse: 0.0622 - output_10_mse: 0.0675 - output_11_mse: 0.1281 - output_12_mse: 0.0612 - output_13_mse: 0.0786 - output_14_mse: 0.0930 - output_15_mse: 0.0382 - output_1_mse: 0.0398 - output_2_mse: 0.0243 - output_3_mse: 0.0581 - output_4_mse: 0.1756 - output_5_mse: 0.0277 - output_6_mse: 0.0999 - output_7_mse: 0.1162 - output_8_mse: 0.1663 - output_9_mse: 0.0908\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n","k: 8 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - loss: 1.3559 - output_0_mse: 0.0864 - output_10_mse: 0.0866 - output_11_mse: 0.1094 - output_12_mse: 0.0536 - output_13_mse: 0.0757 - output_14_mse: 0.0788 - output_15_mse: 0.0519 - output_1_mse: 0.0602 - output_2_mse: 0.0192 - output_3_mse: 0.0712 - output_4_mse: 0.1638 - output_5_mse: 0.0324 - output_6_mse: 0.0960 - output_7_mse: 0.0932 - output_8_mse: 0.1851 - output_9_mse: 0.0926\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n","k: 9 patience: 0\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - loss: 1.2353 - output_0_mse: 0.0691 - output_10_mse: 0.0550 - output_11_mse: 0.1416 - output_12_mse: 0.0410 - output_13_mse: 0.0790 - output_14_mse: 0.0840 - output_15_mse: 0.0312 - output_1_mse: 0.0481 - output_2_mse: 0.0173 - output_3_mse: 0.0594 - output_4_mse: 0.1807 - output_5_mse: 0.0315 - output_6_mse: 0.0861 - output_7_mse: 0.0686 - output_8_mse: 0.1622 - output_9_mse: 0.0804\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","k: 10 patience: 1\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 1.1315 - output_0_mse: 0.0644 - output_10_mse: 0.0433 - output_11_mse: 0.1355 - output_12_mse: 0.0521 - output_13_mse: 0.0740 - output_14_mse: 0.0693 - output_15_mse: 0.0366 - output_1_mse: 0.0290 - output_2_mse: 0.0179 - output_3_mse: 0.0479 - output_4_mse: 0.1457 - output_5_mse: 0.0143 - output_6_mse: 0.0783 - output_7_mse: 0.0615 - output_8_mse: 0.1581 - output_9_mse: 0.1034\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n","k: 11 patience: 2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.1388 - output_0_mse: 0.0697 - output_10_mse: 0.0505 - output_11_mse: 0.1217 - output_12_mse: 0.0402 - output_13_mse: 0.0665 - output_14_mse: 0.0963 - output_15_mse: 0.0380 - output_1_mse: 0.0455 - output_2_mse: 0.0141 - output_3_mse: 0.0525 - output_4_mse: 0.1470 - output_5_mse: 0.0314 - output_6_mse: 0.0706 - output_7_mse: 0.0591 - output_8_mse: 0.1469 - output_9_mse: 0.0886\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 12 patience: 3\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1193 - output_0_mse: 0.0615 - output_10_mse: 0.0714 - output_11_mse: 0.1215 - output_12_mse: 0.0480 - output_13_mse: 0.0536 - output_14_mse: 0.0873 - output_15_mse: 0.0391 - output_1_mse: 0.0297 - output_2_mse: 0.0155 - output_3_mse: 0.0506 - output_4_mse: 0.1372 - output_5_mse: 0.0296 - output_6_mse: 0.0771 - output_7_mse: 0.0595 - output_8_mse: 0.1361 - output_9_mse: 0.1017\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n","k: 13 patience: 4\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 1.0886 - output_0_mse: 0.0538 - output_10_mse: 0.0324 - output_11_mse: 0.1186 - output_12_mse: 0.0376 - output_13_mse: 0.0550 - output_14_mse: 0.0719 - output_15_mse: 0.0427 - output_1_mse: 0.0362 - output_2_mse: 0.0241 - output_3_mse: 0.0603 - output_4_mse: 0.1448 - output_5_mse: 0.0308 - output_6_mse: 0.0899 - output_7_mse: 0.0687 - output_8_mse: 0.1271 - output_9_mse: 0.0944\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n","k: 14 patience: 5\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 1.0567 - output_0_mse: 0.0598 - output_10_mse: 0.0410 - output_11_mse: 0.1119 - output_12_mse: 0.0455 - output_13_mse: 0.0499 - output_14_mse: 0.0925 - output_15_mse: 0.0329 - output_1_mse: 0.0337 - output_2_mse: 0.0180 - output_3_mse: 0.0519 - output_4_mse: 0.1547 - output_5_mse: 0.0280 - output_6_mse: 0.0759 - output_7_mse: 0.0372 - output_8_mse: 0.1353 - output_9_mse: 0.0886\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n","k: 15 patience: 6\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.9849 - output_0_mse: 0.0398 - output_10_mse: 0.0533 - output_11_mse: 0.1237 - output_12_mse: 0.0299 - output_13_mse: 0.0482 - output_14_mse: 0.0676 - output_15_mse: 0.0380 - output_1_mse: 0.0278 - output_2_mse: 0.0144 - output_3_mse: 0.0444 - output_4_mse: 0.1365 - output_5_mse: 0.0260 - output_6_mse: 0.0724 - output_7_mse: 0.0493 - output_8_mse: 0.1229 - output_9_mse: 0.0906\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n","k: 16 patience: 7\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.9161 - output_0_mse: 0.0407 - output_10_mse: 0.0404 - output_11_mse: 0.0977 - output_12_mse: 0.0293 - output_13_mse: 0.0491 - output_14_mse: 0.0593 - output_15_mse: 0.0476 - output_1_mse: 0.0328 - output_2_mse: 0.0085 - output_3_mse: 0.0542 - output_4_mse: 0.1404 - output_5_mse: 0.0208 - output_6_mse: 0.0560 - output_7_mse: 0.0387 - output_8_mse: 0.1061 - output_9_mse: 0.0945\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n","k: 17 patience: 8\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.8789 - output_0_mse: 0.0376 - output_10_mse: 0.0429 - output_11_mse: 0.0947 - output_12_mse: 0.0267 - output_13_mse: 0.0499 - output_14_mse: 0.0505 - output_15_mse: 0.0313 - output_1_mse: 0.0276 - output_2_mse: 0.0143 - output_3_mse: 0.0577 - output_4_mse: 0.1213 - output_5_mse: 0.0211 - output_6_mse: 0.0540 - output_7_mse: 0.0419 - output_8_mse: 0.1300 - output_9_mse: 0.0775\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n","k: 18 patience: 9\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.7818 - output_0_mse: 0.0343 - output_10_mse: 0.0322 - output_11_mse: 0.1010 - output_12_mse: 0.0218 - output_13_mse: 0.0360 - output_14_mse: 0.0642 - output_15_mse: 0.0163 - output_1_mse: 0.0348 - output_2_mse: 0.0098 - output_3_mse: 0.0547 - output_4_mse: 0.1048 - output_5_mse: 0.0147 - output_6_mse: 0.0426 - output_7_mse: 0.0414 - output_8_mse: 0.1125 - output_9_mse: 0.0606\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n","k: 19 patience: 10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688ms/step\n","Test Loss: 33.33576880425335\n","average_loss: 30.30810745979298\n"]}],"source":["from keras.models import Model\n","from keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n","from keras.optimizers import Adam\n","import numpy as np\n","import sklearn\n","\n","total_losses = []\n","\n","def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def transformer_decoder(inputs, enc_outputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Self attention\n","    x = LayerNormalization(epsilon=1e-6)(inputs)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    x = Dropout(dropout)(x)\n","    res = x + inputs\n","\n","    # Cross attention\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, enc_outputs)\n","    x = Dropout(dropout)(x)\n","    res = x + res\n","\n","    # Feed forward\n","    x = LayerNormalization(epsilon=1e-6)(res)\n","    x = Dense(ff_dim, activation=\"relu\")(x)\n","    x = Dropout(dropout)(x)\n","    x = Dense(inputs.shape[-1])(x)\n","    return x + res\n","\n","def get_hard_shared_model(input_shape1, input_shape2, output_shape):\n","    # Encoder input\n","    enc_inputs = Input(shape=(input_shape1, input_shape2))\n","\n","    # Encoder\n","    enc_outputs = transformer_encoder(enc_inputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Decoder input\n","    dec_inputs = Input(shape=(output_shape[1], input_shape2))\n","\n","    # Decoder\n","    dec_outputs = transformer_decoder(dec_inputs, enc_outputs, head_size=64, num_heads=4, ff_dim=256, dropout=0.2)\n","\n","    # Global pooling\n","    x = GlobalAveragePooling1D()(dec_outputs)\n","\n","    # Shared dense layer\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","\n","    # Task-specific output layers\n","    outputs = []\n","    for i in range(output_shape[1]):\n","        output = Dense(1, name=f'output_{i}')(x)\n","        outputs.append(output)\n","\n","    return Model([enc_inputs, dec_inputs], outputs)\n","\n","input_groups = [input_group_1, input_group_2, input_group_3, input_group_4, input_group_5]\n","output_groups = [output_group_1, output_group_2, output_group_3, output_group_4, output_group_5]\n","ssq_groups = [output_total_ssq_group_1, output_total_ssq_group_2, output_total_ssq_group_3, output_total_ssq_group_4, output_total_ssq_group_5]\n","\n","\n","# Specify the number of samples to select for each group in each iteration\n","samples_per_iteration = [\n","    [3, 3, 3, 3, 2],  # For input_group_1\n","    [3, 3, 3, 3, 2],  # For input_group_2\n","    [3, 3, 3, 2, 2],  # For input_group_3\n","    [2, 2, 2, 2, 3],  # For input_group_4\n","    [3, 3, 3, 3, 4]   # For input_group_5\n","]\n","\n","# Initialize a list of global indices arrays, one for each group\n","global_indices = [[] for _ in range(len(input_groups))]\n","print(\"global_indices\",global_indices)\n","\n","# Outer loop to repeat the sampling process for 5 iterations\n","for iteration in range(5):\n","  X_train, X_val, X_test = [], [], []\n","  y_train, y_val, y_test = [], [], []\n","  ssq_train, ssq_val, ssq_test = [], [], []\n","  print(f\"Iteration {iteration + 1}\")\n","  print(\"global_indices\",global_indices)\n","  # Loop over each group\n","  for i, (input_group, output_group, ssq_group) in enumerate(zip(input_groups, output_groups, ssq_groups)):\n","      num_samples = samples_per_iteration[i][iteration]  # Number of samples to select for the current group and iteration\n","\n","      # Create a set of available indices that haven't been selected yet for the current group\n","      available_indices = list(set(range(len(input_group))) - set(global_indices[i]))\n","\n","      # Check if there are fewer available indices than needed\n","      if len(available_indices) < num_samples:\n","          print(f\"Not enough indices left in group {i + 1} to select {num_samples} new samples.\")\n","          num_samples = len(available_indices)  # Adjust to take whatever is left\n","\n","      # Select the required number of samples from the available indices for the current group\n","      selected_indices = np.random.choice(available_indices, num_samples, replace=False)\n","      global_indices[i].extend(selected_indices)  # Add these indices to the group's global list\n","\n","      # Remove these selected samples from the input, output, and SSQ groups\n","      X_test_temp = input_group[selected_indices]\n","      y_test_temp = output_group[selected_indices]\n","      ssq_test_temp = ssq_group[selected_indices]\n","\n","      X_temp = np.delete(input_group, selected_indices, axis=0)\n","      y_temp = np.delete(output_group, selected_indices, axis=0)\n","      ssq_temp = np.delete(ssq_group, selected_indices, axis=0)\n","\n","      # Split the remaining data into a training set (60%) and a validation set (40%)\n","      X_train_temp, X_val_temp, y_train_temp, y_val_temp, ssq_train_temp, ssq_val_temp = train_test_split(\n","          X_temp, y_temp, ssq_temp, test_size=0.2)\n","\n","      # Append the results to the corresponding lists\n","      X_train.append(X_train_temp)\n","      X_val.append(X_val_temp)\n","      X_test.append(X_test_temp)\n","\n","      y_train.append(y_train_temp)\n","      y_val.append(y_val_temp)\n","      y_test.append(y_test_temp)\n","\n","      ssq_train.append(ssq_train_temp)\n","      ssq_val.append(ssq_val_temp)\n","      ssq_test.append(ssq_test_temp)\n","\n","  # After the loop, concatenate the data for all groups if needed\n","  input_train = np.concatenate(X_train, axis=0)\n","  input_val = np.concatenate(X_val, axis=0)\n","  input_test = np.concatenate(X_test, axis=0)\n","\n","  output_train = np.concatenate(y_train, axis=0)\n","  output_val = np.concatenate(y_val, axis=0)\n","  output_test = np.concatenate(y_test, axis=0)\n","\n","  output_test_total_ssq = np.concatenate(ssq_test, axis=0)\n","\n","\n","  #  this section for scaling both train and validation set simultaniously\n","  # Step 1: Combine the training and validation sets\n","  combined_input = np.concatenate([input_train, input_val], axis=0)\n","  combined_output = np.concatenate([output_train, output_val], axis=0)\n","\n","  # Step 2: Scale the combined input data\n","  # Assuming scale_input_data scales the data based on the combined dataset\n","  combined_input, input_test = scale_input_data(\n","      combined_input[:, (60-sample_size):(180-sample_size), :],\n","      input_test[:, (60-sample_size):(180-sample_size), :]\n","  )\n","\n","  # Step 3: Scale the combined output data\n","  # Assuming scale_target_var scales the data and returns min_val, max_val\n","  combined_output, min_val, max_val = scale_target_var(combined_output)\n","\n","  # Step 4: Split the combined data back into training and validation sets\n","  # Use the original shapes of input_train and input_val to slice the combined arrays\n","  input_train = combined_input[:input_train.shape[0], :, :]\n","  input_val = combined_input[input_train.shape[0]:, :, :]\n","\n","  output_train = combined_output[:output_train.shape[0], :]\n","  output_val = combined_output[output_train.shape[0]:, :]\n","\n","\n","\n","  print(\"input_train :\", input_train.shape)\n","  print(\"output_train :\", output_train.shape)\n","  print(\"input_val :\", input_val.shape)\n","  print(\"output_val :\", output_val.shape)\n","  print(\"input_test :\", input_test.shape)\n","  print(\"output_test :\", output_test.shape)\n","\n","\n","  # Reshape inputs\n","  train_input_reshaped = input_train.reshape((input_train.shape[0], input_train.shape[1], input_train.shape[2]))\n","  test_input_reshaped = input_test.reshape((input_test.shape[0], input_test.shape[1], input_test.shape[2]))\n","  val_input_reshaped = input_val.reshape((input_val.shape[0], input_val.shape[1], input_val.shape[2]))\n","\n","  # Create decoder inputs\n","  train_dec_input = np.zeros((train_input_reshaped.shape[0], output_train.shape[1], train_input_reshaped.shape[2]))\n","  val_dec_input = np.zeros((val_input_reshaped.shape[0], output_train.shape[1], val_input_reshaped.shape[2]))\n","  test_dec_input = np.zeros((test_input_reshaped.shape[0], output_test.shape[1], test_input_reshaped.shape[2]))\n","\n","  # Create the hard parameter sharing model\n","  model = get_hard_shared_model(input_train.shape[1], input_train.shape[2], output_train.shape)\n","\n","  # Compile and train the model\n","  model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=[['mse'] for _ in range(output_train.shape[1])])\n","  best_val = 1000000\n","  patience = 0\n","  best_model = None\n","\n","  for k in range(200):\n","      # Train the model\n","      model.fit([train_input_reshaped, train_dec_input],\n","                [output_train[:, i] for i in range(output_train.shape[1])],\n","                epochs=1, batch_size=32, verbose=1)\n","\n","      # Predict validation data\n","      pred_val = np.array(model.predict([val_input_reshaped, val_dec_input]))\n","      pred_val = np.transpose(pred_val, (1, 0, 2)).squeeze()\n","      print(\"k:\", k, \"patience:\", patience)\n","\n","      # Evaluate the model\n","      losses = []\n","      for i in range(pred_val.shape[0]):\n","        total_ssq=0\n","        for j in [0,5,6,7,8,14,15]:\n","          total_ssq=np.sum(pred_val[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [0,1,2,3,4,8,10]:\n","          total_ssq=np.sum(pred_val[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [4,7,9,10,11,12,13]:\n","          total_ssq=np.sum(pred_val[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","        total_ssq=total_ssq*3.74\n","        output_val_ssq= output_val[i,0]\n","        #print(\"total_ssq\",total_ssq)\n","        #print(\"output_val_ssq\",output_val_ssq)\n","        loss = sklearn.metrics.mean_squared_error([total_ssq], [output_val_ssq], squared=False)\n","        losses.append(loss)\n","      tmp_val_loss = np.mean(losses)\n","      if tmp_val_loss <= best_val:\n","          best_val = tmp_val_loss\n","          patience = 0\n","          best_model = model\n","      else:\n","          patience +=1\n","          if patience > 10:\n","            break\n","\n","  # Predict test data\n","  pred_test = np.array(best_model.predict([test_input_reshaped, test_dec_input]))\n","  pred_test = np.transpose(pred_test, (1, 0, 2)).squeeze()\n","\n","  # Evaluate the model\n","  pred_total_ssq = []\n","  for i in range(pred_test.shape[0]):\n","        total_ssq=0\n","        for j in [0,5,6,7,8,14,15]:\n","          total_ssq=np.sum(pred_test[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [0,1,2,3,4,8,10]:\n","          total_ssq=np.sum(pred_test[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","\n","        for j in [4,7,9,10,11,12,13]:\n","          total_ssq=np.sum(pred_test[i,j]*(max_val[j]-min_val[j]) + min_val[j])+total_ssq\n","        total_ssq=total_ssq*3.74\n","\n","        pred_total_ssq.append(total_ssq)\n","  # Overall Test Loss\n","  loss = sklearn.metrics.mean_squared_error(pred_total_ssq, output_test_total_ssq, squared=False)\n","  print(\"Test Loss:\", loss)\n","  total_losses.append(loss)\n","\n","average_loss = sum(total_losses) / len(total_losses)\n","total_losses.append(average_loss)\n","print(\"average_loss:\", average_loss)"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1Ur3TMQCq7AgUnHJ2tjkY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}